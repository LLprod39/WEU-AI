"""
Views for Agent Hub: profiles, runs, and AI config assistant.
"""
import json
import queue
import threading
import time
from pathlib import Path
import subprocess
import os
import shutil
import sys
from datetime import datetime
from typing import Dict, Any
from django.shortcuts import render, get_object_or_404
from django.http import JsonResponse, HttpResponseForbidden
from django.views.decorators.csrf import csrf_exempt
from django.contrib.auth.decorators import login_required
from django.views.decorators.http import require_http_methods
from django.db import transaction
from django.db.models import Q
from django.utils import timezone
from django.conf import settings
from asgiref.sync import async_to_sync
from loguru import logger

from .models import AgentProfile, AgentRun, AgentPreset, AgentWorkflow, AgentWorkflowRun, CustomAgent
from app.agents.manager import get_agent_manager
from core_ui.decorators import require_feature
from core_ui.middleware import get_template_name
from app.core.llm import LLMProvider
from app.tools.manager import get_tool_manager

ALLOWED_RUNTIMES = {"cursor", "claude", "gemini", "grok", "ralph"}  # CLI –∞–≥–µ–Ω—Ç—ã + Ralph orchestrator
ALLOWED_RALPH_BACKENDS = {"cursor", "claude", "gemini", "grok"}  # Backends –¥–ª—è Ralph


def _get_project_folders(include_files_count: bool = False) -> list:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø–∞–ø–æ–∫ –ø—Ä–æ–µ–∫—Ç–æ–≤. include_files_count=False –Ω–∞ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã ‚Äî –Ω–µ –¥–µ–ª–∞–µ—Ç —Ç—è–∂—ë–ª—ã–π glob."""
    projects_dir = settings.AGENT_PROJECTS_DIR
    folders = []
    if projects_dir.exists():
        for item in sorted(projects_dir.iterdir()):
            if item.is_dir():
                rec = {"name": item.name, "path": item.name, "full_path": str(item)}
                if include_files_count:
                    try:
                        rec["files_count"] = sum(1 for _ in item.iterdir())
                    except OSError:
                        rec["files_count"] = 0
                folders.append(rec)
    return folders


def _create_project_folder(name: str) -> str:
    """–°–æ–∑–¥–∞–µ—Ç –ø–∞–ø–∫—É –ø—Ä–æ–µ–∫—Ç–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å"""
    import re
    # –û—á–∏—Å—Ç–∫–∞ –∏–º–µ–Ω–∏ –æ—Ç –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
    safe_name = re.sub(r'[^\w\-_. ]', '', name).strip().replace(' ', '_')
    if not safe_name:
        safe_name = f"project_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    project_path = settings.AGENT_PROJECTS_DIR / safe_name
    project_path.mkdir(parents=True, exist_ok=True)
    return safe_name


def _get_workspace_path(workflow: AgentWorkflow, is_server_task: bool = False) -> str:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ workspace –¥–ª—è workflow.

    –î–ª—è SERVER_TASK: –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø–∞–ø–∫–∞ –ë–ï–ó –¥–æ—Å—Ç—É–ø–∞ –∫ –∫–æ–¥—É –ø—Ä–æ–µ–∫—Ç–∞.
    –î–ª—è CODE_TASK: –ø–∞–ø–∫–∞ –≤ agent_projects/ –¥–ª—è –Ω–∞–ø–∏—Å–∞–Ω–∏—è –∫–æ–¥–∞.
    """
    # –î–ª—è —Å–µ—Ä–≤–µ—Ä–Ω—ã—Ö –∑–∞–¥–∞—á - —Å–æ–∑–¥–∞—ë–º –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—É—é –ø–∞–ø–∫—É (–±–µ–∑ –∫–æ–¥–∞ –ø—Ä–æ–µ–∫—Ç–∞!)
    if is_server_task or workflow.target_server_id:
        # –ü–∞–ø–∫–∞ –¥–ª—è —Å–µ—Ä–≤–µ—Ä–Ω—ã—Ö –∑–∞–¥–∞—á - –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è, —Ç–æ–ª—å–∫–æ –¥–ª—è MCP
        safe_name = (workflow.name or "server_task").replace(" ", "_")[:50]
        isolated_path = settings.AGENT_PROJECTS_DIR / safe_name
        isolated_path.mkdir(parents=True, exist_ok=True)
        return str(isolated_path)

    # –î–ª—è –∫–æ–¥–æ–≤—ã—Ö –∑–∞–¥–∞—á - project_path –∏–ª–∏ default
    path = (workflow.project_path or "").strip()
    if not path:
        try:
            from app.core.model_config import model_manager
            path = (getattr(model_manager.config, "default_agent_output_path", None) or "").strip()
        except Exception as e:
            logger.debug(f"Failed to load default_agent_output_path: {e}")
            path = ""
    if path:
        full_path = settings.AGENT_PROJECTS_DIR / path
        full_path.mkdir(parents=True, exist_ok=True)
        return str(full_path)

    # Fallback: –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø–∞–ø–∫–∞ (–ù–ï BASE_DIR —á—Ç–æ–±—ã –Ω–µ –≤–∏–¥–µ—Ç—å –∫–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞)
    safe_name = (workflow.name or "code_task").replace(" ", "_")[:50]
    fallback_path = settings.AGENT_PROJECTS_DIR / safe_name
    fallback_path.mkdir(parents=True, exist_ok=True)
    return str(fallback_path)


def _admin_required(request) -> bool:
    return bool(getattr(request, "user", None) and request.user.is_authenticated and request.user.is_staff)


def _redact_sensitive(value):
    if isinstance(value, dict):
        redacted = {}
        for k, v in value.items():
            key_lower = str(k).lower()
            if any(word in key_lower for word in ["password", "secret", "token", "api_key", "apikey", "key"]):
                redacted[k] = "***"
            else:
                redacted[k] = _redact_sensitive(v)
        return redacted
    if isinstance(value, list):
        return [_redact_sensitive(v) for v in value]
    return value


def _sanitize_command(cmd: list) -> list:
    sanitized = []
    redact_next = False
    for part in cmd:
        if redact_next:
            sanitized.append("***")
            redact_next = False
            continue
        part_lower = str(part).lower()
        if any(flag in part_lower for flag in ["--api-key", "--apikey", "--token", "--secret", "--password"]):
            sanitized.append(part)
            redact_next = True
            continue
        sanitized.append(part)
    return sanitized


def _parse_json_request(request) -> Dict[str, Any]:
    try:
        return json.loads(request.body or "{}")
    except json.JSONDecodeError:
        return {}


def _agent_name_from_type(agent_type: str) -> str:
    return {
        "simple": "Simple Agent",
        "complex": "Complex Agent",
        "react": "ReAct Agent",
        "ralph": "Ralph Wiggum Agent",
    }.get(agent_type, "ReAct Agent")


def _parse_llm_json(response_text: str) -> Dict[str, Any]:
    try:
        return json.loads(response_text)
    except json.JSONDecodeError:
        import re

        match = re.search(r"\{.*\}", response_text, re.DOTALL)
        if match:
            try:
                return json.loads(match.group())
            except json.JSONDecodeError:
                return {}
        return {}


def _generate_profile_config(task: str) -> Dict[str, Any]:
    llm = LLMProvider()
    from app.core.model_config import model_manager

    model_preference = model_manager.config.default_provider
    prompt = f"""You are an AI assistant helping configure agent profiles.
Return ONLY JSON with fields:
{{
  "name": "Profile name",
  "description": "Short description",
  "agent_type": "simple|complex|react|ralph",
  "runtime": "cursor|ralph",
  "mode": "simple|advanced",
  "questions": ["Question 1", "Question 2"],
  "assumptions": ["Assumption 1", "Assumption 2"],
  "config": {{
    "model": "gpt-5|sonnet-4|sonnet-4-thinking",
    "specific_model": null,
    "use_rag": true,
    "max_iterations": 10,
    "completion_promise": "DONE",
    "ralph_backend": "cursor",
    "initial_prompt": "",
    "loop_include_previous": true,
    "ask_on_missing": true,
    "safety_level": "safe"
  }}
}}

Task description:
{task}

Rules:
- Use ralph for multi-step tasks, cursor for direct execution.
- If using ralph runtime, set ralph_backend to "cursor".
- If requirements are unclear, add 1-2 concise questions in "questions".
- Keep config minimal but correct.
"""

    async def _consume():
        chunks = []
        async for chunk in llm.stream_chat(prompt, model=model_preference):
            chunks.append(chunk)
        return "".join(chunks)

    response_text = async_to_sync(_consume)()
    parsed = _parse_llm_json(response_text)
    if not parsed:
        parsed = {
            "name": "New Agent Profile",
            "description": "Auto-generated profile",
            "agent_type": "ralph",
            "runtime": "ralph",
            "mode": "simple",
            "questions": [],
            "assumptions": [],
            "config": {
                "model": "gpt-5",
                "use_rag": True,
                "ralph_backend": "cursor",
                "loop_include_previous": True,
                "ask_on_missing": True,
                "safety_level": "safe",
            },
        }
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º default_provider –∫–∞–∫ fallback –≤–º–µ—Å—Ç–æ –∂–µ—Å—Ç–∫–æ –∑–∞–¥–∞–Ω–Ω–æ–≥–æ "ralph"
    from app.core.model_config import model_manager
    default_runtime = model_manager.config.default_provider or "cursor"
    parsed["runtime"] = parsed.get("runtime") if parsed.get("runtime") in ALLOWED_RUNTIMES else default_runtime
    cfg = parsed.get("config", {})
    if parsed["runtime"] == "ralph":
        cfg["ralph_backend"] = default_runtime
    # –ú–æ–¥–µ–ª—å —Ç–µ–ø–µ—Ä—å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –¥–ª—è cursor - –≤–∞–ª–∏–¥–∏—Ä—É–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ
    if parsed["runtime"] == "cursor" and cfg.get("model"):
        from django.conf import settings
        valid_models = [m["id"] for m in getattr(settings, "CURSOR_AVAILABLE_MODELS", [])]
        if cfg["model"] not in valid_models:
            cfg["model"] = "auto"  # fallback –Ω–∞ auto –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ–≤–∞–ª–∏–¥–Ω–∞—è
    parsed["config"] = cfg
    return parsed


def _generate_workflow_script(task: str, runtime: str, from_task: bool = False, user_id: int = None, target_server_id: int = None, target_server_name: str = None) -> Dict[str, Any]:
    llm = LLMProvider()
    from app.core.model_config import model_manager

    model_preference = model_manager.config.default_provider

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∑–∞–¥–∞—á–∏: SERVER_TASK –∏–ª–∏ CODE_TASK
    is_server_task = target_server_id is not None

    if is_server_task:
        # –°–ï–†–í–ï–†–ù–´–ï –ó–ê–î–ê–ß–ò: –ø—Ä–æ—Å—Ç—ã–µ SSH –∫–æ–º–∞–Ω–¥—ã, –±–µ–∑ –∫–æ–¥–∞ –ø—Ä–æ–µ–∫—Ç–∞
        prompt = f"""Generate a simple workflow for SERVER administration task.
Return ONLY JSON:
{{
  "name": "Task name",
  "description": "Short description",
  "runtime": "{runtime}",
  "task_type": "server",
  "steps": [
    {{
      "title": "Step title",
      "prompt": "Execute SSH command on server",
      "completion_promise": "STEP_DONE",
      "max_iterations": 3
    }}
  ]
}}

CRITICAL RULES FOR SERVER TASKS:
- Target server: ¬´{target_server_name}¬ª
- Use ONLY server_execute MCP tool with server_name_or_id="{target_server_name}"
- Generate SIMPLE shell commands: df -h, free -m, systemctl status, apt install, etc.
- DO NOT mention any code, functions, APIs, or application logic
- DO NOT reference get_disk_usage_report, django, python functions
- Agent should ONLY run SSH commands via server_execute tool
- Each step = one simple server command
- When done, output <promise>STEP_DONE</promise>

Example for "check disk space":
  prompt: "–í—ã–ø–æ–ª–Ω–∏ –∫–æ–º–∞–Ω–¥—É df -h –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ —á–µ—Ä–µ–∑ server_execute. –í—ã–≤–µ–¥–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç. –ö–æ–≥–¥–∞ –≥–æ—Ç–æ–≤–æ –≤—ã–≤–µ–¥–∏ <promise>STEP_DONE</promise>"

Task: {task}
"""
    else:
        # –ö–û–î–û–í–´–ï –ó–ê–î–ê–ß–ò: –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞ —Å –∫–æ–¥–æ–º
        prompt = f"""You generate workflow scripts for CLI agents (CODE tasks).
Return ONLY JSON:
{{
  "name": "Workflow name",
  "description": "Short description",
  "runtime": "{runtime}",
  "task_type": "code",
  "prompt": "High-level goal summary",
  "questions": ["Clarifying question 1", "Clarifying question 2"],
  "assumptions": ["Assumption 1", "Assumption 2"],
  "quality_checks": ["Tests to run", "Lint to run"],
  "steps": [
    {{
      "title": "Step title",
      "prompt": "Task for the agent to perform",
      "completion_promise": "STEP_DONE",
      "max_iterations": 5,
      "verify_prompt": "Verify work and run tests if needed. Output <promise>PASS</promise> when ok.",
      "verify_promise": "PASS"
    }}
  ]
}}

RULES FOR CODE TASKS:
- Agent works in ISOLATED directory (agent_projects/task_name/)
- Agent should NOT access main project code
- Keep steps short and actionable
- Each step must include completion_promise
- Include verify_prompt and verify_promise for testing steps
- Ralph workflow: —à–∞–≥–∏ –ø–æ –ø–æ—Ä—è–¥–∫—É, completion_promise –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è

Task description:
{task}
"""

    async def _consume():
        chunks = []
        async for chunk in llm.stream_chat(prompt, model=model_preference):
            chunks.append(chunk)
        return "".join(chunks)

    response_text = async_to_sync(_consume)()
    parsed = _parse_llm_json(response_text)
    if not parsed:
        return {}

    if "steps" not in parsed:
        parsed["steps"] = []

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º runtime –¥–ª—è workflow (CLI –∞–≥–µ–Ω—Ç: cursor, claude, etc)
    parsed["runtime"] = runtime
    
    # Ralph —Ä–µ–∂–∏–º –±–æ–ª—å—à–µ –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —á–µ—Ä–µ–∑ —ç—Ç–æ—Ç –ø—É—Ç—å
    # Ralph —ç—Ç–æ orchestrator_mode, –∞ –Ω–µ runtime
    # runtime –≤—Å–µ–≥–¥–∞ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π CLI: cursor, claude, gemini, grok

    return parsed


@login_required
@require_feature('agents', redirect_on_forbidden=True)
def agents_page(request):
    from servers.models import Server
    profiles = AgentProfile.objects.filter(owner=request.user, is_active=True)
    presets = AgentPreset.objects.all()
    recent_runs = AgentRun.objects.filter(initiated_by=request.user)[:10]
    workflows = AgentWorkflow.objects.filter(owner=request.user).select_related("target_server")[:10]
    workflow_runs = AgentWorkflowRun.objects.filter(initiated_by=request.user)[:10]
    workflow_runs_data = []
    for run in workflow_runs:
        steps = (run.workflow.script or {}).get("steps", [])
        total_steps = len(steps)
        progress_pct = 0
        current_step_title = ""
        if total_steps:
            progress_pct = min(int((run.current_step / total_steps) * 100), 100)
            if run.current_step > 0 and run.current_step <= total_steps:
                current_step_title = steps[run.current_step - 1].get("title", "")
        workflow_runs_data.append(
            {
                "run": run,
                "total_steps": total_steps,
                "progress_pct": progress_pct,
                "current_step_title": current_step_title,
            }
        )
    presets_data = [
        {
            "name": preset.name,
            "description": preset.description,
            "agent_type": preset.agent_type,
            "runtime": preset.runtime,
            "config": preset.config,
        }
        for preset in presets
    ]
    workflows_data = [
        {
            "id": workflow.id,
            "name": workflow.name,
            "script": workflow.script,
            "project_path": workflow.project_path,
            "target_server_id": workflow.target_server_id,
            "target_server_name": workflow.target_server.name if workflow.target_server else None,
        }
        for workflow in workflows
    ]
    projects_data = _get_project_folders(include_files_count=False)
    # –°–µ—Ä–≤–µ—Ä—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –≤—ã–±–æ—Ä–∞ —Ü–µ–ª–µ–≤–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞
    servers_data = [
        {"id": s.id, "name": s.name, "host": s.host}
        for s in Server.objects.filter(user=request.user).only("id", "name", "host")
    ]
    # Mobile or desktop template
    if getattr(request, 'is_mobile', False):
        template = "agent_hub/mobile/agents.html"
    else:
        template = "agent_hub/agents.html"
    
    return render(
        request,
        template,
        {
            "profiles": profiles,
            "presets": presets,
            "recent_runs": recent_runs,
            "workflows": workflows,
            "workflow_runs": workflow_runs_data,
            "presets_data": presets_data,
            "workflows_data": workflows_data,
            "projects_data": projects_data,
            "servers_data": servers_data,
        },
    )


@login_required
@require_feature('agents', redirect_on_forbidden=True)
@require_http_methods(["GET"])
def logs_page(request):
    run_type = (request.GET.get("type") or "workflow").strip()
    run_id = (request.GET.get("run_id") or "").strip()
    return render(
        request,
        "agent_hub/logs.html",
        {
            "run_type": run_type,
            "run_id": run_id,
        },
    )


@login_required
@require_feature('agents', redirect_on_forbidden=True)
@require_http_methods(["GET"])
def admin_logs_page(request):
    if not _admin_required(request):
        return HttpResponseForbidden("Forbidden")
    return render(request, "agent_hub/admin_logs.html", {})


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["GET"])
def api_profiles_list(request):
    profiles = AgentProfile.objects.filter(owner=request.user).order_by("-updated_at")
    data = [
        {
            "id": p.id,
            "name": p.name,
            "description": p.description,
            "agent_type": p.agent_type,
            "runtime": p.runtime,
            "mode": p.mode,
            "config": p.config,
            "is_default": p.is_default,
            "is_active": p.is_active,
            "updated_at": p.updated_at.isoformat(),
        }
        for p in profiles
    ]
    return JsonResponse({"profiles": data})


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["POST"])
def api_profiles_create(request):
    data = _parse_json_request(request)
    name = data.get("name", "").strip()
    if not name:
        return JsonResponse({"error": "Name is required"}, status=400)

    agent_type = data.get("agent_type", "react")
    runtime = data.get("runtime", "ralph")
    mode = data.get("mode", "simple")
    config = data.get("config", {})
    is_default = bool(data.get("is_default", False))

    if is_default:
        AgentProfile.objects.filter(owner=request.user, is_default=True).update(is_default=False)

    if runtime not in ALLOWED_RUNTIMES:
        return JsonResponse({"error": f"Runtime '{runtime}' –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è"}, status=400)

    # –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –¥–ª—è cursor
    if runtime == "cursor" and config.get("model"):
        valid_models = [m["id"] for m in getattr(settings, "CURSOR_AVAILABLE_MODELS", [])]
        if config["model"] not in valid_models:
            config["model"] = "auto"

    profile = AgentProfile.objects.create(
        owner=request.user,
        name=name,
        description=data.get("description", ""),
        agent_type=agent_type,
        runtime=runtime,
        mode=mode,
        config=config,
        is_default=is_default,
    )

    return JsonResponse({"success": True, "profile_id": profile.id})


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["POST"])
def api_profiles_update(request, profile_id: int):
    profile = get_object_or_404(AgentProfile, id=profile_id, owner=request.user)
    data = _parse_json_request(request)

    profile.name = data.get("name", profile.name)
    profile.description = data.get("description", profile.description)
    profile.agent_type = data.get("agent_type", profile.agent_type)
    if "runtime" in data:
        new_runtime = data.get("runtime")
        if new_runtime not in ALLOWED_RUNTIMES:
            return JsonResponse({"error": f"Runtime '{new_runtime}' –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è"}, status=400)
        profile.runtime = new_runtime
    else:
        profile.runtime = data.get("runtime", profile.runtime)
    profile.mode = data.get("mode", profile.mode)
    config = data.get("config", profile.config or {})
    # –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –¥–ª—è cursor
    if profile.runtime == "cursor" and config.get("model"):
        valid_models = [m["id"] for m in getattr(settings, "CURSOR_AVAILABLE_MODELS", [])]
        if config["model"] not in valid_models:
            config["model"] = "auto"
    profile.config = config

    if "is_active" in data:
        profile.is_active = bool(data.get("is_active"))
    if "is_default" in data:
        is_default = bool(data.get("is_default"))
        if is_default:
            AgentProfile.objects.filter(owner=request.user, is_default=True).exclude(id=profile.id).update(
                is_default=False
            )
        profile.is_default = is_default

    profile.save()
    return JsonResponse({"success": True})


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["POST"])
def api_profiles_delete(request, profile_id: int):
    profile = get_object_or_404(AgentProfile, id=profile_id, owner=request.user)
    profile.is_active = False
    profile.save(update_fields=["is_active"])
    return JsonResponse({"success": True})


def _start_agent_run(
    user,
    agent_type: str,
    runtime: str,
    task: str,
    config: Dict[str, Any],
    profile: AgentProfile = None,
) -> AgentRun:
    run = AgentRun.objects.create(
        profile=profile,
        initiated_by=user,
        runtime=runtime,
        status="queued",
        input_task=task,
        started_at=None,
        meta={
            "agent_type": agent_type,
            "runtime": runtime,
            "config": config or {},
            "profile_id": profile.id if profile else None,
        },
    )
    thread = threading.Thread(
        target=_execute_agent_run,
        args=(run.id, agent_type, runtime, task, config),
        daemon=True,
    )
    thread.start()
    return run


def _execute_agent_run(run_id: int, agent_type: str, runtime: str, task: str, config: Dict[str, Any]):
    run_obj = AgentRun.objects.get(id=run_id)
    run_obj.status = "running"
    run_obj.started_at = timezone.now()
    _append_log_event(
        run_obj,
        {
            "type": "run",
            "subtype": "start",
            "title": "–°—Ç–∞—Ä—Ç –∑–∞–ø—É—Å–∫–∞",
            "message": f"Runtime: {runtime}",
        },
    )
    _append_log_event(
        run_obj,
        {
            "type": "prompt",
            "title": "–í—Ö–æ–¥–Ω–∞—è –∑–∞–¥–∞—á–∞",
            "message": task[:4000],
        },
    )
    meta = run_obj.meta or {}
    meta.update(
        {
            "agent_type": agent_type,
            "runtime": runtime,
            "config": config or {},
        }
    )
    run_obj.meta = meta
    run_obj.save(update_fields=["status", "started_at", "log_events", "meta"])

    try:
        if getattr(settings, "ANALYZE_TASK_BEFORE_RUN", True) and runtime in ("ralph", "cursor"):
            workspace = config.get("workspace") or ""
            if not workspace:
                try:
                    from app.core.model_config import model_manager
                    path = (getattr(model_manager.config, "default_agent_output_path", None) or "").strip()
                    if path:
                        workspace = str(settings.AGENT_PROJECTS_DIR / path)
                    else:
                        # Create isolated workspace, NEVER use BASE_DIR (platform code)
                        from datetime import datetime
                        safe_name = f"agent_run_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                        isolated_path = settings.AGENT_PROJECTS_DIR / safe_name
                        isolated_path.mkdir(parents=True, exist_ok=True)
                        workspace = str(isolated_path)
                except Exception:
                    # Fallback to isolated folder
                    from datetime import datetime
                    safe_name = f"agent_run_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                    isolated_path = settings.AGENT_PROJECTS_DIR / safe_name
                    isolated_path.mkdir(parents=True, exist_ok=True)
                    workspace = str(isolated_path)
            run_obj.logs = (run_obj.logs or "") + "\n[Phase: Cursor analyze task]\n"
            _append_log_event(
                run_obj,
                {
                    "type": "phase",
                    "subtype": "start",
                    "title": "Cursor analyze",
                    "message": "–ê–Ω–∞–ª–∏–∑ –∑–∞–¥–∞—á–∏ –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º",
                },
            )
            run_obj.save(update_fields=["logs", "log_events", "meta"])
            analyze_result = _run_cursor_ask_analyze(workspace, task[:6000], timeout_sec=90)
            run_obj.logs = (run_obj.logs or "") + (analyze_result.get("output", "") or "")[:3000] + "\n"
            run_obj.logs = (run_obj.logs or "") + "[Cursor analyze done ‚Äî –∑–∞–ø—É—Å–∫ –∞–≥–µ–Ω—Ç–∞]\n"
            _append_log_event(
                run_obj,
                {
                    "type": "phase",
                    "subtype": "done",
                    "title": "Cursor analyze",
                    "status": "ready" if analyze_result.get("ready") else "review",
                },
            )
            run_obj.save(update_fields=["logs", "log_events", "meta"])
        if runtime == "internal":
            agent_manager = get_agent_manager()
            agent_name = _agent_name_from_type(agent_type)
            result = async_to_sync(agent_manager.execute_agent)(agent_name, task, config)
            run_obj.output_text = result.get("result") or ""
            run_obj.logs = json.dumps(result.get("metadata") or {}, ensure_ascii=False)
            run_obj.status = "succeeded" if result.get("success") else "failed"
        else:
            workspace = config.get("workspace") or ""
            if not workspace:
                try:
                    from app.core.model_config import model_manager
                    path = (getattr(model_manager.config, "default_agent_output_path", None) or "").strip()
                    if path:
                        workspace = str(settings.AGENT_PROJECTS_DIR / path)
                    else:
                        # Create isolated workspace, NEVER use BASE_DIR (platform code)
                        from datetime import datetime
                        safe_name = f"agent_run_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                        isolated_path = settings.AGENT_PROJECTS_DIR / safe_name
                        isolated_path.mkdir(parents=True, exist_ok=True)
                        workspace = str(isolated_path)
                except Exception:
                    # Fallback to isolated folder
                    from datetime import datetime
                    safe_name = f"agent_run_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                    isolated_path = settings.AGENT_PROJECTS_DIR / safe_name
                    isolated_path.mkdir(parents=True, exist_ok=True)
                    workspace = str(isolated_path)
            cmd = _build_cli_command(runtime, task, config, workspace=workspace)
            meta = run_obj.meta or {}
            meta["cli_command"] = _sanitize_command(cmd)
            meta["cli_command_full"] = cmd
            meta["workspace"] = workspace
            meta["runtime"] = runtime
            meta["input_prompt"] = task
            meta["config"] = _redact_sensitive(config)
            run_obj.meta = meta
            run_obj.logs = (run_obj.logs or "") + f"\n{'='*60}\n"
            run_obj.logs = (run_obj.logs or "") + f"üîß –ó–ê–ü–£–°–ö CLI –ê–ì–ï–ù–¢–ê\n"
            run_obj.logs = (run_obj.logs or "") + f"Runtime: {runtime}\n"
            run_obj.logs = (run_obj.logs or "") + f"Workspace: {workspace}\n"
            run_obj.logs = (run_obj.logs or "") + f"{'='*60}\n"
            run_obj.logs = (run_obj.logs or "") + f"[CMD] {' '.join(_sanitize_command(cmd))}\n"
            run_obj.logs = (run_obj.logs or "") + f"{'='*60}\n\n"
            _append_log_event(
                run_obj,
                {
                    "type": "cmd",
                    "subtype": "start",
                    "title": "–ó–∞–ø—É—Å–∫ –∫–æ–º–∞–Ω–¥—ã",
                    "command": " ".join(_sanitize_command(cmd)),
                },
            )
            run_obj.save(update_fields=["logs", "log_events", "meta"])
            result = _run_cli_stream(
                cmd,
                run_obj,
                step_label="agent-run",
                extra_env=_get_cursor_cli_extra_env(),
                add_output_events=True,
            )
            run_obj.output_text = result.get("output", "")
            run_obj.status = "succeeded" if result.get("success") else "failed"
            run_obj.meta = {**(run_obj.meta or {}), "exit_code": result.get("exit_code")}
    except Exception as exc:
        logger.error(f"Agent run failed: {exc}")
        run_obj.status = "failed"
        run_obj.logs = str(exc)
    run_obj.finished_at = timezone.now()
    _append_log_event(
        run_obj,
        {
            "type": "run",
            "subtype": "finish",
            "title": "–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ",
            "status": run_obj.status,
        },
    )
    run_obj.save()


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["POST"])
def api_profile_run(request, profile_id: int):
    """
    Wrapper for api_agent_run with profile_id in URL path (for backward compatibility)
    """
    data = _parse_json_request(request)
    data['profile_id'] = profile_id  # Inject profile_id from URL
    
    # Get task from 'prompt' or 'task' field
    task = data.get("task") or data.get("prompt", "").strip()
    if not task:
        return JsonResponse({"error": "Task is required"}, status=400)
    data['task'] = task
    
    # Call the main api_agent_run logic
    profile = get_object_or_404(AgentProfile, id=profile_id, owner=request.user)
    
    from app.core.model_config import model_manager
    default_runtime = model_manager.config.default_provider or "cursor"
    
    agent_type = data.get("agent_type") or profile.agent_type
    runtime = data.get("runtime") or profile.runtime
    config = data.get("config") or profile.config or {}
    
    if runtime not in ALLOWED_RUNTIMES:
        return JsonResponse({"error": f"Runtime '{runtime}' –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è"}, status=400)
    
    if runtime == "cursor":
        if not config.get("model"):
            config["model"] = "auto"
        else:
            valid_models = [m["id"] for m in getattr(settings, "CURSOR_AVAILABLE_MODELS", [])]
            if config["model"] not in valid_models:
                config["model"] = "auto"
    
    if agent_type == "ralph" and runtime not in ["internal", "ralph"]:
        config = {**config, "use_ralph_loop": True}
        if not config.get("completion_promise"):
            config["completion_promise"] = "COMPLETE"
    
    run = _start_agent_run(request.user, agent_type, runtime, task, config, profile=profile)
    return JsonResponse({"success": True, "run_id": run.id, "status": "queued"})


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["POST"])
def api_agent_run(request):
    data = _parse_json_request(request)
    task = data.get("task", "").strip()
    if not task:
        return JsonResponse({"error": "Task is required"}, status=400)

    profile_id = data.get("profile_id")
    profile = None
    if profile_id:
        profile = get_object_or_404(AgentProfile, id=profile_id, owner=request.user)

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º default_provider –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫
    from app.core.model_config import model_manager
    default_runtime = model_manager.config.default_provider or "cursor"
    
    agent_type = data.get("agent_type") or (profile.agent_type if profile else "react")
    runtime = data.get("runtime") or (profile.runtime if profile else default_runtime)
    config = data.get("config") or (profile.config if profile else {})
    if runtime not in ALLOWED_RUNTIMES:
        return JsonResponse({"error": f"Runtime '{runtime}' –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è"}, status=400)
    # –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –¥–ª—è cursor (–µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–∞ - –±—É–¥–µ—Ç auto –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
    if runtime == "cursor":
        if not config.get("model"):
            config["model"] = "auto"
        else:
            valid_models = [m["id"] for m in getattr(settings, "CURSOR_AVAILABLE_MODELS", [])]
            if config["model"] not in valid_models:
                config["model"] = "auto"
    if agent_type == "ralph" and runtime not in ["internal", "ralph"]:
        config = {**config, "use_ralph_loop": True}
        if not config.get("completion_promise"):
            config["completion_promise"] = "COMPLETE"

    run = _start_agent_run(request.user, agent_type, runtime, task, config, profile=profile)
    return JsonResponse({"success": True, "run_id": run.id, "status": "queued"})


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["GET"])
def api_runs_list(request):
    runs = AgentRun.objects.filter(initiated_by=request.user).order_by("-created_at")[:50]
    data = [
        {
            "id": r.id,
            "runtime": r.runtime,
            "status": r.status,
            "input_task": r.input_task,
            "output_text": r.output_text[:500],
            "created_at": r.created_at.isoformat(),
        }
        for r in runs
    ]
    return JsonResponse({"runs": data})


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["GET"])
def admin_api_runs_list(request):
    if not _admin_required(request):
        return JsonResponse({"error": "Forbidden"}, status=403)
    q = (request.GET.get("q") or "").strip()
    type_filter = (request.GET.get("type") or "all").strip().lower()
    status_filter = (request.GET.get("status") or "all").strip().lower()
    runtime_filter = (request.GET.get("runtime") or "all").strip().lower()

    items = []
    if type_filter in ("all", "run"):
        runs = AgentRun.objects.select_related("initiated_by", "profile")
        if status_filter != "all":
            runs = runs.filter(status=status_filter)
        if runtime_filter != "all":
            runs = runs.filter(runtime=runtime_filter)
        if q:
            runs = runs.filter(Q(input_task__icontains=q) | Q(profile__name__icontains=q))
        runs = runs.order_by("-created_at")[:200]
        for r in runs:
            items.append(
                {
                    "id": r.id,
                    "type": "run",
                    "status": r.status,
                    "runtime": r.runtime,
                    "created_at": r.created_at.isoformat(),
                    "title": (r.input_task or "")[:120],
                    "user": r.initiated_by.username if r.initiated_by else "",
                }
            )
    if type_filter in ("all", "workflow"):
        runs = AgentWorkflowRun.objects.select_related("initiated_by", "workflow")
        if status_filter != "all":
            runs = runs.filter(status=status_filter)
        if runtime_filter != "all":
            runs = runs.filter(workflow__runtime=runtime_filter)
        if q:
            runs = runs.filter(Q(workflow__name__icontains=q) | Q(workflow__description__icontains=q))
        runs = runs.order_by("-created_at")[:200]
        for r in runs:
            items.append(
                {
                    "id": r.id,
                    "type": "workflow",
                    "status": r.status,
                    "runtime": r.workflow.runtime if r.workflow else "",
                    "created_at": r.created_at.isoformat(),
                    "title": r.workflow.name if r.workflow else "",
                    "user": r.initiated_by.username if r.initiated_by else "",
                }
            )
    items.sort(key=lambda x: x.get("created_at") or "", reverse=True)
    return JsonResponse({"items": items})


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["GET"])
def admin_api_run_status(request, run_id: int):
    if not _admin_required(request):
        return JsonResponse({"error": "Forbidden"}, status=403)
    run = get_object_or_404(AgentRun, id=run_id)
    after_id = request.GET.get("after_id")
    events = list(run.log_events or [])
    if after_id:
        try:
            after_id_int = int(after_id)
            events = [e for e in events if int(e.get("id", 0)) > after_id_int]
        except ValueError:
            events = events[-400:]
    else:
        events = events[-400:]
    last_event_id = events[-1]["id"] if events else (run.log_events or [])[-1]["id"] if run.log_events else 0
    meta = run.meta or {}
    config = meta.get("config") or {}
    cli_command = meta.get("cli_command") or []
    workspace = meta.get("workspace") or ""
    input_prompt = meta.get("input_prompt") or run.input_task or ""
    
    # –°–æ–±–∏—Ä–∞–µ–º –ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
    runtime_cfg = settings.CLI_RUNTIME_CONFIG.get(run.runtime, {})
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ settings
    analyze_enabled = getattr(settings, "ANALYZE_TASK_BEFORE_RUN", True)
    cli_timeout = getattr(settings, "CLI_RUNTIME_TIMEOUT_SECONDS", 600)
    cli_first_output_timeout = getattr(settings, "CLI_FIRST_OUTPUT_TIMEOUT_SECONDS", 120)
    
    # –°–∏—Å—Ç–µ–º–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç
    system_instructions = []
    if run.runtime in ["cursor", "claude"]:
        system_instructions.append(f"Pre-analyze: {'enabled' if analyze_enabled else 'disabled'}")
        system_instructions.append(f"Timeout: {cli_timeout}s (first output: {cli_first_output_timeout}s)")
    
    # ENV –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏/–±—É–¥—É—Ç –ø–µ—Ä–µ–¥–∞–Ω—ã
    env_vars = {}
    if run.runtime == "cursor":
        cursor_extra = getattr(settings, "CURSOR_CLI_EXTRA_ENV", {})
        if cursor_extra:
            env_vars = _redact_sensitive(cursor_extra)
    
    details = {
        "id": run.id,
        "type": "run",
        "runtime": run.runtime,
        "status": run.status,
        "created_at": run.created_at.isoformat(),
        "started_at": run.started_at.isoformat() if run.started_at else None,
        "finished_at": run.finished_at.isoformat() if run.finished_at else None,
        "user": run.initiated_by.username if run.initiated_by else None,
        "profile": run.profile.name if run.profile else None,
        "meta": meta,
        "cli_command": cli_command,
        "cli_command_full": meta.get("cli_command_full") or [],
        "workspace": workspace,
        "runtime_config": {
            "command": runtime_cfg.get("command"),
            "args": runtime_cfg.get("args", []),
            "allowed_args": runtime_cfg.get("allowed_args", []),
            "timeout_seconds": runtime_cfg.get("timeout_seconds"),
            "prompt_style": runtime_cfg.get("prompt_style", "flag"),
        },
        "input_prompt_full": input_prompt,
        "config": config,
        "system_instructions": system_instructions,
        "env_vars": env_vars,
    }
    meta_line = " ‚Ä¢ ".join(
        [f"Runtime: {run.runtime}", f"Status: {run.status}", f"User: {details.get('user') or '‚Äî'}"]
    )
    return JsonResponse(
        {
            "type": "run",
            "title": f"Run #{run.id}",
            "meta": meta_line,
            "prompt": input_prompt,
            "config_json": json.dumps(config, ensure_ascii=False, indent=2),
            "script_json": "",
            "logs": (run.logs or "")[-20000:],
            "output": (run.output_text or "")[-8000:],
            "events": events,
            "last_event_id": last_event_id,
            "details": details,
        }
    )


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["POST"])
def admin_api_run_update(request, run_id: int):
    if not _admin_required(request):
        return JsonResponse({"error": "Forbidden"}, status=403)
    run = get_object_or_404(AgentRun, id=run_id)
    data = _parse_json_request(request)
    updated_fields = []
    if "input_task" in data:
        run.input_task = data.get("input_task") or ""
        updated_fields.append("input_task")
    if "config" in data:
        meta = run.meta or {}
        meta["config"] = data.get("config") or {}
        run.meta = meta
        updated_fields.append("meta")
    if updated_fields:
        _append_log_event(
            run,
            {
                "type": "edit",
                "title": "–ò–∑–º–µ–Ω–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤",
                "message": "–û–±–Ω–æ–≤–ª–µ–Ω—ã –ø–æ–ª—è: " + ", ".join(updated_fields),
            },
        )
        run.save()
    return JsonResponse({"success": True})


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["POST"])
def admin_api_run_restart(request, run_id: int):
    if not _admin_required(request):
        return JsonResponse({"error": "Forbidden"}, status=403)
    run = get_object_or_404(AgentRun, id=run_id)
    data = _parse_json_request(request)
    task = (data.get("input_task") or run.input_task or "").strip()
    meta = run.meta or {}
    config = data.get("config") or meta.get("config") or (run.profile.config if run.profile else {})
    agent_type = meta.get("agent_type") or (run.profile.agent_type if run.profile else "react")
    runtime = run.runtime
    new_run = _start_agent_run(run.initiated_by or request.user, agent_type, runtime, task, config, profile=run.profile)
    return JsonResponse({"success": True, "run_id": new_run.id})


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["GET"])
def admin_api_workflow_run_status(request, run_id: int):
    if not _admin_required(request):
        return JsonResponse({"error": "Forbidden"}, status=403)
    run = get_object_or_404(AgentWorkflowRun.objects.select_related("workflow"), id=run_id)
    after_id = request.GET.get("after_id")
    events = list(run.log_events or [])
    if after_id:
        try:
            after_id_int = int(after_id)
            events = [e for e in events if int(e.get("id", 0)) > after_id_int]
        except ValueError:
            events = events[-400:]
    else:
        events = events[-400:]
    last_event_id = events[-1]["id"] if events else (run.log_events or [])[-1]["id"] if run.log_events else 0
    script = run.workflow.script if run.workflow else {}
    steps = script.get("steps", [])
    current_step_idx = run.current_step
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —à–∞–≥–∞—Ö —Å –∫–æ–º–∞–Ω–¥–∞–º–∏
    steps_info = []
    run_meta = run.meta or {}
    for idx in range(1, len(steps) + 1):
        step = steps[idx - 1] if idx <= len(steps) else {}
        step_cmd = run_meta.get(f"step_{idx}_cmd") or []
        step_prompt = run_meta.get(f"step_{idx}_prompt") or step.get("prompt", "")
        steps_info.append({
            "idx": idx,
            "title": step.get("title", f"–®–∞–≥ {idx}"),
            "prompt": step_prompt[:200],
            "cmd": step_cmd,
            "is_current": idx == current_step_idx,
        })
    
    details = {
        "id": run.id,
        "type": "workflow",
        "status": run.status,
        "runtime": run.workflow.runtime if run.workflow else None,
        "workflow_id": run.workflow.id if run.workflow else None,
        "workflow_name": run.workflow.name if run.workflow else None,
        "created_at": run.created_at.isoformat(),
        "started_at": run.started_at.isoformat() if run.started_at else None,
        "finished_at": run.finished_at.isoformat() if run.finished_at else None,
        "user": run.initiated_by.username if run.initiated_by else None,
        "meta": run_meta,
        "steps": steps_info,
        "current_step": current_step_idx,
    }
    
    # –ü—Ä–æ–º–ø—Ç —Ç–µ–∫—É—â–µ–≥–æ —à–∞–≥–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)
    current_step_prompt = ""
    if current_step_idx > 0 and current_step_idx <= len(steps):
        current_step_prompt = run_meta.get(f"step_{current_step_idx}_prompt") or steps[current_step_idx - 1].get("prompt", "")
    
    meta_line = " ‚Ä¢ ".join(
        [
            f"Workflow: {details.get('workflow_name') or '‚Äî'}",
            f"Status: {run.status}",
            f"Step: {current_step_idx}/{len(steps)}",
            f"User: {details.get('user') or '‚Äî'}",
        ]
    )
    return JsonResponse(
        {
            "type": "workflow",
            "title": f"WorkflowRun #{run.id}",
            "meta": meta_line,
            "prompt": current_step_prompt,
            "config_json": json.dumps(run_meta, ensure_ascii=False, indent=2),
            "script_json": json.dumps(script or {}, ensure_ascii=False, indent=2),
            "logs": (run.logs or "")[-20000:] if run.logs else "",
            "events": events,
            "last_event_id": last_event_id,
            "details": details,
        }
    )


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["POST"])
def admin_api_workflow_run_update(request, run_id: int):
    if not _admin_required(request):
        return JsonResponse({"error": "Forbidden"}, status=403)
    run = get_object_or_404(AgentWorkflowRun.objects.select_related("workflow"), id=run_id)
    data = _parse_json_request(request)
    script = data.get("script")
    if not isinstance(script, dict):
        return JsonResponse({"error": "script must be JSON object"}, status=400)
    workflow = run.workflow
    workflow.script = script
    workflow.save(update_fields=["script"])
    _append_log_event(
        run,
        {
            "type": "edit",
            "title": "Workflow –æ–±–Ω–æ–≤–ª–µ–Ω",
            "message": "–û–±–Ω–æ–≤–ª–µ–Ω script workflow",
        },
    )
    run.save(update_fields=["log_events", "meta"])
    return JsonResponse({"success": True})


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["POST"])
def admin_api_workflow_run_restart(request, run_id: int):
    if not _admin_required(request):
        return JsonResponse({"error": "Forbidden"}, status=403)
    run = get_object_or_404(AgentWorkflowRun.objects.select_related("workflow"), id=run_id)
    new_run = _start_workflow_run(run.workflow, run.initiated_by or request.user)
    return JsonResponse({"success": True, "run_id": new_run.id})


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["GET"])
def api_run_status(request, run_id: int):
    run = get_object_or_404(AgentRun, id=run_id, initiated_by=request.user)
    after_id = request.GET.get("after_id")
    events = list(run.log_events or [])
    if after_id:
        try:
            after_id_int = int(after_id)
            events = [e for e in events if int(e.get("id", 0)) > after_id_int]
        except ValueError:
            events = events[-200:]
    else:
        events = events[-200:]
    last_event_id = events[-1]["id"] if events else (run.log_events or [])[-1]["id"] if run.log_events else 0
    return JsonResponse(
        {
            "status": run.status,
            "runtime": run.runtime,
            "logs": (run.logs or "")[-5000:],
            "output": (run.output_text or "")[-2000:],
            "finished_at": run.finished_at.isoformat() if run.finished_at else None,
            "events": events,
            "last_event_id": last_event_id,
        }
    )


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["POST"])
def api_run_stop(request, run_id: int):
    run = get_object_or_404(AgentRun, id=run_id, initiated_by=request.user)
    if run.status not in ["queued", "running"]:
        return JsonResponse({"error": "Run —É–∂–µ –∑–∞–≤–µ—Ä—à–µ–Ω"}, status=400)

    pid = (run.meta or {}).get("pid")
    if pid:
        try:
            if os.name == "nt":
                subprocess.Popen(["taskkill", "/PID", str(pid), "/F"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            else:
                os.kill(int(pid), 9)
        except (ProcessLookupError, OSError) as e:
            logger.debug(f"Process {pid} already terminated: {e}")

    run.status = "cancelled"
    run.logs = (run.logs or "") + "\n[Stopped by user]\n"
    run.finished_at = timezone.now()
    run.save(update_fields=["status", "logs", "finished_at"])
    return JsonResponse({"success": True})


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["POST"])
def api_run_delete(request, run_id: int):
    run = get_object_or_404(AgentRun, id=run_id, initiated_by=request.user)
    run.delete()
    return JsonResponse({"success": True})


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["POST"])
def api_workflow_run_delete(request, run_id: int):
    run = get_object_or_404(AgentWorkflowRun, id=run_id, initiated_by=request.user)
    run.delete()
    return JsonResponse({"success": True})


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["GET"])
def api_projects_list(request):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø–∞–ø–æ–∫ –ø—Ä–æ–µ–∫—Ç–æ–≤"""
    folders = _get_project_folders(include_files_count=True)
    return JsonResponse({"projects": folders})


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["POST"])
def api_projects_create(request):
    """–°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—É—é –ø–∞–ø–∫—É –ø—Ä–æ–µ–∫—Ç–∞"""
    data = _parse_json_request(request)
    name = data.get("name", "").strip()
    if not name:
        return JsonResponse({"error": "Name is required"}, status=400)
    
    project_path = _create_project_folder(name)
    return JsonResponse({
        "success": True,
        "project_path": project_path,
        "full_path": str(settings.AGENT_PROJECTS_DIR / project_path),
    })


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["GET"])
def api_workflows_list(request):
    workflows = AgentWorkflow.objects.filter(owner=request.user).order_by("-created_at")[:50]
    data = [
        {
            "id": w.id,
            "name": w.name,
            "description": w.description,
            "runtime": w.runtime,
            "script": w.script,
            "created_at": w.created_at.isoformat(),
        }
        for w in workflows
    ]
    return JsonResponse({"workflows": data})


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["POST"])
def api_workflow_delete(request, workflow_id: int):
    workflow = get_object_or_404(AgentWorkflow, id=workflow_id, owner=request.user)
    script = workflow.script or {}
    for path_key in ["script_file", "ralph_yml_path"]:
        file_path = script.get(path_key)
        if file_path:
            try:
                Path(file_path).unlink(missing_ok=True)
            except OSError as e:
                logger.debug(f"Failed to delete workflow file {file_path}: {e}")
    workflow.delete()
    return JsonResponse({"success": True})


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["POST"])
def api_workflow_generate(request):
    data = _parse_json_request(request)
    task = data.get("task", "").strip()
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º default_provider –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –≤–º–µ—Å—Ç–æ –∂–µ—Å—Ç–∫–æ –∑–∞–¥–∞–Ω–Ω–æ–≥–æ "ralph"
    from app.core.model_config import model_manager
    default_runtime = model_manager.config.default_provider or "cursor"
    runtime = data.get("runtime", default_runtime)
    
    project_path = data.get("project_path", "").strip()
    create_new_project = data.get("create_new_project", False)
    new_project_name = data.get("new_project_name", "").strip()
    
    if not task:
        return JsonResponse({"error": "Task is required"}, status=400)
    if runtime not in ALLOWED_RUNTIMES:
        return JsonResponse({"error": f"Runtime '{runtime}' –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è"}, status=400)

    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –ø–∞–ø–∫—É –ø—Ä–æ–µ–∫—Ç–∞ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if create_new_project and new_project_name:
        project_path = _create_project_folder(new_project_name)
    elif create_new_project and not new_project_name:
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–º—è –∏–∑ –∑–∞–¥–∞—á–∏
        import re
        safe_name = re.sub(r'[^\w\-_. ]', '', task[:50]).strip().replace(' ', '_')
        if not safe_name:
            safe_name = f"project_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        project_path = _create_project_folder(safe_name)
    elif not project_path:
        try:
            from app.core.model_config import model_manager
            project_path = (getattr(model_manager.config, "default_agent_output_path", None) or "").strip()
        except Exception:
            pass

    parsed = _generate_workflow_script(task, runtime)

    if not parsed:
        return JsonResponse({"error": "Failed to generate workflow"}, status=500)

    workflow = AgentWorkflow.objects.create(
        owner=request.user,
        name=parsed.get("name", "New Workflow"),
        description=parsed.get("description", ""),
        runtime=parsed.get("runtime", runtime),
        script=parsed,
        project_path=project_path,
    )

    workflows_dir = Path(settings.MEDIA_ROOT) / "workflows"
    workflows_dir.mkdir(parents=True, exist_ok=True)
    file_path = workflows_dir / f"workflow-{workflow.id}.json"
    parsed["script_file"] = str(file_path)
    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(parsed, f, ensure_ascii=False, indent=2)

    if parsed.get("ralph_yml"):
        ralph_path = workflows_dir / f"workflow-{workflow.id}.ralph.yml"
        parsed["ralph_yml_path"] = str(ralph_path)
        _write_ralph_yml(ralph_path, parsed["ralph_yml"])

    workflow.script = parsed
    workflow.save(update_fields=["script"])

    return JsonResponse({"success": True, "workflow_id": workflow.id, "workflow": parsed})


# Import from service layer - breaks circular import with tasks app
from app.services.workflow_service import create_workflow_from_task


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["POST"])
def api_workflow_from_task(request):
    """
    –°–æ–∑–¥–∞—Ç—å –≤–æ—Ä–∫—Ñ–ª–æ—É –≤ Agents –∏–∑ –∑–∞–¥–∞—á–∏ (Tasks), —Ä–∞—Å–ø–∏—Å–∞—Ç—å –ø–æ —à–∞–≥–∞–º (Ralph), –∑–∞–ø—É—Å—Ç–∏—Ç—å.
    –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ –¥–µ–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–∏ –≤ ¬´—Ñ–æ—Ä–º—É –∑–∞–¥–∞—á–∏ –∞–≥–µ–Ω—Ç–∞¬ª (delegate_ui=task_form).
    Body: { "task_id": int }. Returns: { "workflow_id", "run_id" }.
    """
    data = _parse_json_request(request)
    task_id = data.get("task_id")
    if task_id is None:
        return JsonResponse({"error": "task_id required"}, status=400)
    try:
        from tasks.models import Task
    except ImportError:
        return JsonResponse({"error": "Tasks app not available"}, status=500)
    task = Task.objects.filter(id=task_id).first()
    if not task:
        return JsonResponse({"error": "Task not found"}, status=404)
    created_by_id = getattr(task, "created_by_id", None)
    if created_by_id is not None and created_by_id != request.user.id:
        from app.services.permissions import PermissionService
        if not PermissionService.can_edit_task(request.user, task):
            return JsonResponse({"error": "No access to this task"}, status=403)
    
    workflow, run = create_workflow_from_task(task, request.user)
    if not workflow:
        return JsonResponse({"error": "Failed to create workflow"}, status=500)
    
    return JsonResponse({
        "success": True,
        "workflow_id": workflow.id,
        "run_id": run.id,
    })


def _promise_found(output: str, promise: str) -> bool:
    import re
    match = re.search(r"<promise>(.*?)</promise>", output, re.DOTALL | re.IGNORECASE)
    if not match:
        return False
    extracted = re.sub(r"\s+", " ", match.group(1).strip())
    target = re.sub(r"\s+", " ", promise.strip())
    return extracted == target


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["POST"])
def api_workflow_run(request):
    data = _parse_json_request(request)
    workflow_id = data.get("workflow_id")
    if not workflow_id:
        return JsonResponse({"error": "workflow_id required"}, status=400)

    workflow = get_object_or_404(AgentWorkflow, id=workflow_id, owner=request.user)
    # –ù–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º workflow.runtime —Ç.–∫. –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ default_provider
    run = _start_workflow_run(workflow, request.user)
    return JsonResponse({"success": True, "run_id": run.id})


def _run_cursor_ask_analyze(workspace: str, task_text: str, timeout_sec: int = 90) -> Dict[str, Any]:
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–¥–∞—á–∏ —á–µ—Ä–µ–∑ Cursor –≤ —Ä–µ–∂–∏–º–µ ask (—Ç–æ–ª—å–∫–æ –∞–Ω–∞–ª–∏–∑, –±–µ–∑ –ø—Ä–∞–≤–æ–∫).
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç {"output": str, "ready": bool}. ready=True –µ—Å–ª–∏ –≤ –≤—ã–≤–æ–¥–µ –µ—Å—Ç—å <promise>READY</promise>.
    """
    analyze_prompt = (
        "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â—É—é –∑–∞–¥–∞—á—É (–∏–ª–∏ —à–∞–≥–∏ –≤–æ—Ä–∫—Ñ–ª–æ—É). "
        "–ü—Ä–æ–≤–µ—Ä—å: –≤—Å—ë –ª–∏ —è—Å–Ω–æ, –Ω–µ –Ω—É–∂–Ω–æ –ª–∏ —á—Ç–æ-—Ç–æ —É—Ç–æ—á–Ω–∏—Ç—å –∏–ª–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç—å. "
        "–ï—Å–ª–∏ –≤—Å—ë –≤ –ø–æ—Ä—è–¥–∫–µ –∏ –∑–∞–¥–∞—á—É –º–æ–∂–Ω–æ –≤—ã–ø–æ–ª–Ω—è—Ç—å ‚Äî –æ—Ç–≤–µ—Ç—å —Ä–æ–≤–Ω–æ: <promise>READY</promise>\n\n"
        "–ï—Å–ª–∏ –Ω—É–∂–Ω–æ —á—Ç–æ-—Ç–æ —É—Ç–æ—á–Ω–∏—Ç—å –∏–ª–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç—å ‚Äî –Ω–∞–ø–∏—à–∏ –∫—Ä–∞—Ç–∫–æ —á—Ç–æ –∏–º–µ–Ω–Ω–æ.\n\n"
        "---\n"
        f"{task_text[:8000]}"
    )
    try:
        cmd_path = _resolve_cli_command("cursor")
        # NEVER use BASE_DIR for CLI agents - always use isolated workspace
        if not workspace or str(Path(workspace).resolve()) == str(settings.BASE_DIR):
            from datetime import datetime
            safe_name = f"analyze_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            isolated_path = settings.AGENT_PROJECTS_DIR / safe_name
            isolated_path.mkdir(parents=True, exist_ok=True)
            workspace = str(isolated_path)
        base_dir = str(Path(workspace).resolve())
        env = dict(os.environ)
        env.update(getattr(settings, "CURSOR_CLI_EXTRA_ENV", None) or {})
        cmd = [
            cmd_path,
            "--mode=ask",
            "-p",
            "--output-format",
            "text",
            "--workspace",
            base_dir,
            "--model",
            "auto",
            analyze_prompt,
        ]
        proc = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            encoding="utf-8",
            errors="replace",
            cwd=base_dir,
            env=env,
            timeout=timeout_sec,
        )
        output = (proc.stdout or "") + (proc.stderr or "")
        ready = _promise_found(output, "READY")
        return {"output": output.strip(), "ready": ready, "exit_code": proc.returncode}
    except subprocess.TimeoutExpired:
        return {"output": "[Timeout] Cursor ask –ø—Ä–µ–≤—ã—Å–∏–ª –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è.", "ready": False, "exit_code": -1}
    except Exception as e:
        return {"output": f"[Error] {e}", "ready": False, "exit_code": -1}


def _build_cli_command(runtime: str, prompt: str, config: Dict[str, Any], workspace: str = None) -> list:
    logger.info(f"\n{'üîß'*30}")
    logger.info(f"üîß _build_cli_command –≤—ã–∑–≤–∞–Ω")
    logger.info(f"  Runtime: {runtime}")
    logger.info(f"  Workspace: {workspace}")
    logger.info(f"  Config keys: {list(config.keys())}")
    logger.info(f"  Prompt length: {len(prompt)} —Å–∏–º–≤–æ–ª–æ–≤")
    
    # –ó–∞–º–µ–Ω—è–µ–º "auto" –Ω–∞ default_provider
    if runtime == "auto":
        from app.core.model_config import model_manager
        runtime = model_manager.config.default_provider or "cursor"
        logger.info(f"  _build_cli_command: replaced 'auto' with '{runtime}'")

    # Ralph ‚Äî —ç—Ç–æ —Ä–µ–∂–∏–º –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏–∏, –∞ –Ω–µ CLI. –ò—Å–ø–æ–ª—å–∑—É–µ–º CLI –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
    if runtime == "ralph":
        from app.core.model_config import model_manager
        actual_cli = model_manager.config.default_provider or "cursor"
        logger.info(f"  _build_cli_command: Ralph mode - using {actual_cli} CLI (from user settings)")
        # –î–ª—è DevOps —Ä–µ–∂–∏–º–∞ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã —Ç–æ–ª—å–∫–æ SSH/–∫–æ–Ω—Å–æ–ª—å—é
        if "allowedTools" not in config:
            config["allowedTools"] = "server_execute,servers_list,shell_execute"
            logger.info(f"  Ralph DevOps: allowedTools={config['allowedTools']}")
        config = {**config, "use_ralph_loop": True}
        if not config.get("completion_promise"):
            config["completion_promise"] = "COMPLETE"
        runtime = actual_cli  # –ó–∞–º–µ–Ω—è–µ–º ralph –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–π CLI
    
    runtime_cfg = settings.CLI_RUNTIME_CONFIG.get(runtime)
    if not runtime_cfg:
        logger.error(f"‚ùå Runtime '{runtime}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ CLI_RUNTIME_CONFIG!")
        logger.error(f"  –î–æ—Å—Ç—É–ø–Ω—ã–µ runtime: {list(settings.CLI_RUNTIME_CONFIG.keys())}")
        raise ValueError(f"Runtime '{runtime}' is not configured")
    
    logger.info(f"  Runtime config –Ω–∞–π–¥–µ–Ω: {runtime_cfg}")
    
    resolved_cmd = _resolve_cli_command(runtime)
    logger.info(f"  Resolved command: {resolved_cmd}")
    
    cmd = [resolved_cmd]
    
    base_args = runtime_cfg.get("args", [])
    logger.info(f"  Base args –æ—Ç config: {base_args}")

    # Claude CLI –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç --sandbox; —É–±–∏—Ä–∞–µ–º –¥–ª—è claude
    if runtime == "claude" and "--sandbox" in base_args:
        new_args = []
        skip_next = False
        for a in base_args:
            if skip_next:
                skip_next = False
                continue
            if a == "--sandbox":
                skip_next = True
                continue
            new_args.append(a)
        base_args = new_args
        logger.info(f"  Claude: —É–±—Ä–∞–Ω --sandbox –∏–∑ base_args (Claude CLI –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç)")
        logger.info(f"  Base args –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞: {base_args}")

    # –î–ª—è –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–¥–∞—á (—Å–µ—Ä–≤–µ—Ä–Ω—ã–µ/DevOps) —É–±–∏—Ä–∞–µ–º --force
    # –ê–≥–µ–Ω—Ç –Ω–µ –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –º–µ–Ω—è—Ç—å —Ñ–∞–π–ª—ã –ª–æ–∫–∞–ª—å–Ω–æ
    is_isolated = config.get("_is_isolated_task", False)
    if is_isolated and "--force" in base_args:
        base_args = [arg for arg in base_args if arg != "--force"]
        logger.info(f"  –ò–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∑–∞–¥–∞—á–∞: —É–±–∏—Ä–∞–µ–º --force –∏–∑ base_args")
        logger.info(f"  Base args –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {base_args}")
    
    # Claude CLI (-p) —Ç—Ä–µ–±—É–µ—Ç –ø—Ä–æ–º–ø—Ç —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ -p: claude -p "query" [–æ—Å—Ç–∞–ª—å–Ω—ã–µ —Ñ–ª–∞–≥–∏]
    # –°–º. https://docs.anthropic.com/en/docs/claude-code/cli-reference
    if runtime == "claude" and "-p" in base_args and prompt is not None:
        idx_p = base_args.index("-p")
        before_p = base_args[:idx_p]
        after_p = base_args[idx_p + 1:]
        formatted_before = [_format_arg(runtime_cfg, arg, workspace) for arg in before_p]
        formatted_after = [_format_arg(runtime_cfg, arg, workspace) for arg in after_p]
        cmd += formatted_before
        cmd += ["-p", (prompt.strip() if prompt.strip() else " ")]
        cmd += formatted_after
        logger.info(f"  Claude CLI: –ø—Ä–æ–º–ø—Ç –ø–µ—Ä–µ–¥–∞–Ω —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ -p (—Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏)")
    else:
        formatted_args = [_format_arg(runtime_cfg, arg, workspace) for arg in base_args]
        logger.info(f"  Formatted args: {formatted_args}")
        cmd += formatted_args
        cmd += [prompt] if prompt is not None else []

    allowed_args = runtime_cfg.get("allowed_args", [])
    logger.info(f"  Allowed args: {allowed_args}")

    cli_args = []
    for arg_name in allowed_args:
        # Claude CLI –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç --sandbox; –Ω–µ –ø–µ—Ä–µ–¥–∞—ë–º –¥–ª—è claude
        if runtime == "claude" and arg_name == "sandbox":
            continue
        value = config.get(arg_name)
        if value is None:
            underscore_key = arg_name.replace("-", "_")
            value = config.get(underscore_key)
        if value not in (None, "", []):
            if isinstance(value, bool):
                if value:
                    logger.info(f"  –î–æ–±–∞–≤–ª—è–µ–º bool arg: --{arg_name}")
                    cli_args.append(f"--{arg_name}")
            else:
                logger.info(f"  –î–æ–±–∞–≤–ª—è–µ–º arg: --{arg_name} = {str(value)[:100]}")
                cli_args.extend([f"--{arg_name}", str(value)])

    cmd += cli_args
    logger.info(f"  –§–∏–Ω–∞–ª—å–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞: {len(cmd)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
    logger.info(f"{'üîß'*30}\n")
    return cmd


# –°–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫ –ª–æ–≥–∞ –Ω–∞–∫–∞–ø–ª–∏–≤–∞—Ç—å –ø–µ—Ä–µ–¥ –∑–∞–ø–∏—Å—å—é –≤ –ë–î (—Å–Ω–∏–∂–∞–µ—Ç "database is locked" –ø—Ä–∏ SQLite)
_LOG_SAVE_BATCH_SIZE = 10


def _get_cursor_cli_extra_env() -> dict:
    """–ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è Cursor CLI (–Ω–∞–ø—Ä. HTTP/1.0)."""
    env = getattr(settings, "CURSOR_CLI_EXTRA_ENV", None)
    return env if isinstance(env, dict) and env else {}


def _ensure_mcp_servers_config(workspace: str, user_id: int) -> str:
    """–°–æ–∑–¥–∞—ë—Ç/–æ–±–Ω–æ–≤–ª—è–µ—Ç mcp_config.json –≤ workspace –¥–ª—è —Å–µ—Ä–≤–µ—Ä–∞ weu-servers.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è standalone mcp_server.py –≤–º–µ—Å—Ç–æ manage.py mcp_servers,
    —Ç.–∫. Django management command –¥–æ–ª–≥–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è –∏ –º–æ–∂–µ—Ç –∑–∞–≤–∏—Å–∞—Ç—å.
    """
    if not workspace or not user_id:
        return ""
    cfg_path = Path(workspace) / "mcp_config.json"
    cfg = {}
    if cfg_path.exists():
        try:
            cfg = json.loads(cfg_path.read_text(encoding="utf-8") or "{}")
        except Exception:
            cfg = {}
    servers = cfg.get("mcpServers") or {}
    base_dir = str(settings.BASE_DIR).replace("\\", "/")

    # –ü—É—Ç—å –∫ venv python –∏ standalone MCP —Å–µ—Ä–≤–µ—Ä—É
    if os.name != "nt":
        venv_python = f"{base_dir}/.venv/bin/python"
    else:
        venv_python = f"{base_dir}/.venv/Scripts/python.exe"
    mcp_server_script = f"{base_dir}/mcp_server.py"

    servers["weu-servers"] = {
        "type": "stdio",
        "command": venv_python,
        # -u –¥–ª—è unbuffered output
        "args": ["-u", mcp_server_script],
        "env": {"WEU_USER_ID": str(user_id)},
        "description": "WEU AI Servers: servers_list, server_execute (—Å–µ—Ä–≤–µ—Ä—ã –∏–∑ –≤–∫–ª–∞–¥–∫–∏ Servers)",
    }
    cfg["mcpServers"] = servers
    try:
        cfg_path.write_text(json.dumps(cfg, ensure_ascii=False, indent=2), encoding="utf-8")
    except Exception as exc:
        logger.warning(f"Failed to write MCP config at {cfg_path}: {exc}")
        return ""
    return str(cfg_path)


def _short_path(path: str, max_len: int = 50) -> str:
    if len(path) <= max_len:
        return path
    parts = path.replace("\\", "/").split("/")
    if len(parts) > 3:
        return f"{parts[0]}/.../{'/'.join(parts[-2:])}"
    return f"...{path[-(max_len - 3):]}"


def _append_log_event(run_obj, event: Dict[str, Any]) -> Dict[str, Any]:
    meta = run_obj.meta or {}
    next_id = int(meta.get("log_event_id", 0)) + 1
    meta["log_event_id"] = next_id
    enriched = {
        **event,
        "id": next_id,
        "ts": timezone.now().isoformat(),
    }
    run_obj.meta = meta
    run_obj.log_events = list(run_obj.log_events or []) + [enriched]
    return enriched


def _tool_call_to_event(tool_call: Dict[str, Any], subtype: str, step_label: str) -> Dict[str, Any]:
    tool_key = next((k for k in tool_call.keys() if k.endswith("ToolCall")), None)
    tool_payload = tool_call.get(tool_key or "", {}) if tool_call else {}
    args = tool_payload.get("args", {}) if isinstance(tool_payload, dict) else {}
    title = _format_tool_started(tool_call) if subtype == "started" else _format_tool_completed(tool_call)
    return {
        "type": "tool_call",
        "subtype": subtype,
        "title": title or "üîß –û–ø–µ—Ä–∞—Ü–∏—è...",
        "tool": tool_key or "tool",
        "step_label": step_label,
        "data": {
            "args": args,
        },
    }


def _stream_json_to_event(data: Dict[str, Any], step_label: str) -> Dict[str, Any]:
    msg_type = data.get("type")
    subtype = data.get("subtype")
    if msg_type == "system" and subtype == "init":
        return {
            "type": "system",
            "subtype": "init",
            "title": "–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏",
            "message": f"ü§ñ –ú–æ–¥–µ–ª—å: {data.get('model', 'unknown')}",
            "model": data.get("model"),
            "step_label": step_label,
        }
    if msg_type == "assistant":
        content = data.get("message", {}).get("content", [])
        if content and isinstance(content, list) and content[0].get("text"):
            text = content[0].get("text", "")
            return {
                "type": "assistant",
                "title": "–°–æ–æ–±—â–µ–Ω–∏–µ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞",
                "message": text,
                "step_label": step_label,
            }
    if msg_type == "tool_call":
        tool_call = data.get("tool_call", {})
        if subtype in {"started", "completed"}:
            return _tool_call_to_event(tool_call, subtype, step_label)
    if msg_type == "result":
        return {
            "type": "result",
            "title": "–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —à–∞–≥–∞",
            "duration_ms": data.get("duration_ms", 0),
            "step_label": step_label,
        }
    return None


def _format_tool_started(tool_call: Dict[str, Any]) -> str:
    if "writeToolCall" in tool_call:
        path = tool_call["writeToolCall"].get("args", {}).get("path", "?")
        return f"üìù –ó–∞–ø–∏—Å—ã–≤–∞—é: {_short_path(path)}"
    if "readToolCall" in tool_call:
        path = tool_call["readToolCall"].get("args", {}).get("path", "?")
        return f"üìñ –ß–∏—Ç–∞—é: {_short_path(path)}"
    if "strReplaceToolCall" in tool_call:
        path = tool_call["strReplaceToolCall"].get("args", {}).get("path", "?")
        return f"‚úèÔ∏è –†–µ–¥–∞–∫—Ç–∏—Ä—É—é: {_short_path(path)}"
    if "shellToolCall" in tool_call:
        cmd = tool_call["shellToolCall"].get("args", {}).get("command", "?")
        if len(cmd) > 80:
            cmd = cmd[:77] + "..."
        return f"üñ•Ô∏è –ö–æ–º–∞–Ω–¥–∞: {cmd}"
    if "globToolCall" in tool_call:
        pattern = tool_call["globToolCall"].get("args", {}).get("glob_pattern", "?")
        return f"üîç –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤: {pattern}"
    if "grepToolCall" in tool_call:
        pattern = tool_call["grepToolCall"].get("args", {}).get("pattern", "?")
        return f"üîé –ü–æ–∏—Å–∫ –≤ –∫–æ–¥–µ: {pattern}"
    if "lsToolCall" in tool_call:
        path = tool_call["lsToolCall"].get("args", {}).get("target_directory", "?")
        return f"üìÅ –õ–∏—Å—Ç–∏–Ω–≥: {_short_path(path)}"
    if "deleteToolCall" in tool_call:
        path = tool_call["deleteToolCall"].get("args", {}).get("path", "?")
        return f"üóëÔ∏è –£–¥–∞–ª—è—é: {_short_path(path)}"
    return "üîß –û–ø–µ—Ä–∞—Ü–∏—è..."


def _format_tool_completed(tool_call: Dict[str, Any]) -> str:
    if "writeToolCall" in tool_call:
        result = tool_call["writeToolCall"].get("result", {}).get("success", {})
        lines = result.get("linesCreated", 0)
        size = result.get("fileSize", 0)
        return f"   ‚úÖ –°–æ–∑–¥–∞–Ω–æ {lines} —Å—Ç—Ä–æ–∫ ({size} –±–∞–π—Ç)"
    if "readToolCall" in tool_call:
        result = tool_call["readToolCall"].get("result", {}).get("success", {})
        return f"   ‚úÖ –ü—Ä–æ—á–∏—Ç–∞–Ω–æ {result.get('totalLines', 0)} —Å—Ç—Ä–æ–∫"
    if "strReplaceToolCall" in tool_call:
        result = tool_call["strReplaceToolCall"].get("result", {})
        if result.get("success"):
            return "   ‚úÖ –ò–∑–º–µ–Ω–µ–Ω–æ"
        return f"   ‚ö†Ô∏è {(result.get('error') or {}).get('message', '–û—à–∏–±–∫–∞')[:50]}"
    if "shellToolCall" in tool_call:
        result = tool_call["shellToolCall"].get("result", {}).get("success", {})
        exit_code = result.get("exit_code", -1)
        return "   ‚úÖ –í—ã–ø–æ–ª–Ω–µ–Ω–æ" if exit_code == 0 else f"   ‚ö†Ô∏è –ö–æ–¥ –≤—ã—Ö–æ–¥–∞: {exit_code}"
    return None


def _format_stream_json_log(data: Dict[str, Any], run_obj: AgentWorkflowRun) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É –ª–æ–≥–∞ –¥–ª—è run_obj.logs. –î–ª—è assistant –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç None ‚Äî —Ç–µ–∫—Å—Ç –ø–∏—à–µ—Ç—Å—è –æ–¥–Ω–∏–º –±–ª–æ–∫–æ–º –ø—Ä–∏ flush."""
    msg_type = data.get("type")
    subtype = data.get("subtype")
    if msg_type == "system" and subtype == "init":
        return f"ü§ñ –ú–æ–¥–µ–ª—å: {data.get('model', 'unknown')}"
    if msg_type == "assistant":
        # –ù–µ –ø–∏—à–µ–º –∫–∞–∂–¥—ã–π —Å—Ç—Ä–∏–º-—Ñ—Ä–∞–≥–º–µ–Ω—Ç –æ—Ç–¥–µ–ª—å–Ω–æ; –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –≤—ã–≤–æ–¥–∏—Ç—Å—è –æ–¥–Ω–∏–º –±–ª–æ–∫–æ–º –ø—Ä–∏ flush/–∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏
        return None
    if msg_type == "tool_call":
        tool_call = data.get("tool_call", {})
        if subtype == "started":
            return _format_tool_started(tool_call)
        if subtype == "completed":
            return _format_tool_completed(tool_call)
    if msg_type == "result":
        return f"‚è±Ô∏è –ó–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {data.get('duration_ms', 0)}ms"
    return None


def _run_cli_stream(
    cmd: list,
    run_obj: Any,
    step_label: str,
    process_env: dict = None,
    extra_env: dict = None,
    add_output_events: bool = False,
) -> Dict[str, Any]:
    """–ó–∞–ø—É—Å–∫ CLI —Å –ø–∞—Ä—Å–∏–Ω–≥–æ–º stream-json –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è."""
    # –í–ê–ñ–ù–û: –≤—Å–µ–≥–¥–∞ –ø–µ—Ä–µ–¥–∞—ë–º os.environ —á—Ç–æ–±—ã CLI –∏–º–µ–ª–∏ –¥–æ—Å—Ç—É–ø –∫ HOME, PATH –∏ credentials
    spawn_env = {**os.environ}
    if process_env:
        spawn_env.update(process_env)
    if extra_env:
        spawn_env.update(extra_env)
    # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º —á—Ç–æ HOME —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω (–¥–ª—è Claude CLI credentials)
    if not spawn_env.get("HOME"):
        spawn_env["HOME"] = os.path.expanduser("~")
    
    # –ö—Ä–∞—Ç–∫–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ —à–∞–≥–∞ –≤ –ª–æ–≥–∞—Ö (–±–µ–∑ –¥–∞–º–ø–∞ –ø—Ä–æ–º–ø—Ç–∞ –∏ env)
    mcp_config_path = None
    for i, arg in enumerate(cmd):
        if arg == "--mcp-config" and i + 1 < len(cmd):
            mcp_config_path = cmd[i + 1]
            break
    workspace = next((cmd[i + 1] for i, a in enumerate(cmd) if a == "--workspace" and i + 1 < len(cmd)), "")
    debug_info = f"\n‚ñ∂ –®–∞–≥: {step_label} | –ö–æ–º–∞–Ω–¥–∞: {cmd[0]} | Workspace: {workspace[:60]}{'...' if len(workspace) > 60 else ''}\n"
    if mcp_config_path:
        debug_info += f"  MCP config: {mcp_config_path}\n"
    logger.info(debug_info.strip())
    run_obj.logs = (run_obj.logs or "") + debug_info
    _append_log_event(
        run_obj,
        {
            "type": "cmd",
            "subtype": "start",
            "title": "–ó–∞–ø—É—Å–∫ –∫–æ–º–∞–Ω–¥—ã",
            "command": " ".join(cmd),
            "step_label": step_label,
        },
    )
    run_obj.save(update_fields=["logs", "log_events", "meta"])
    popen_kw = {
        "stdout": subprocess.PIPE,
        "stderr": subprocess.STDOUT,
        "text": True,
        "bufsize": 1,
        "encoding": "utf-8",
        "errors": "replace",
    }
    if spawn_env:
        popen_kw["env"] = spawn_env
    
    logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—Å–∞: {cmd[0]}")
    logger.info(f"üîß –ü–∞—Ä–∞–º–µ—Ç—Ä—ã Popen: stdout=PIPE, stderr=STDOUT, text=True, bufsize=1")
    print(f"\n[DEBUG] üöÄ –ó–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—Å–∞: {cmd[0]}", flush=True)
    print(f"[DEBUG] üéØ –ü–æ–ª–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞: {' '.join(cmd)}", flush=True)
    
    try:
        process = subprocess.Popen(cmd, **popen_kw)
        logger.info(f"‚úÖ –ü—Ä–æ—Ü–µ—Å—Å –∑–∞–ø—É—â–µ–Ω —É—Å–ø–µ—à–Ω–æ, PID: {process.pid}")
        print(f"[DEBUG] ‚úÖ –ü—Ä–æ—Ü–µ—Å—Å –∑–∞–ø—É—â–µ–Ω —É—Å–ø–µ—à–Ω–æ, PID: {process.pid}", flush=True)
    except Exception as e:
        logger.error(f"‚ùå –û–®–ò–ë–ö–ê –∑–∞–ø—É—Å–∫–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞: {e}")
        print(f"[DEBUG] ‚ùå –û–®–ò–ë–ö–ê –∑–∞–ø—É—Å–∫–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞: {e}", flush=True)
        run_obj.logs = (run_obj.logs or "") + f"\n‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –∑–∞–ø—É—Å–∫–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞: {e}\n"
        run_obj.save(update_fields=["logs"])
        raise
    
    run_obj.meta = {**(run_obj.meta or {}), f"pid_{step_label}": process.pid, "pid": process.pid}
    run_obj.save(update_fields=["meta"])
    output_chunks = []
    accumulated_text = ""
    assistant_buffer = ""  # –Ω–∞–∫–æ–ø–ª–µ–Ω–∏–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è –≤—ã–≤–æ–¥–∞ –æ–¥–Ω–∏–º –±–ª–æ–∫–æ–º
    tool_count = 0
    pending_lines = 0
    pending_events = 0
    dirty_logs = False
    dirty_events = False
    line_number = 0

    def flush_assistant_buffer():
        nonlocal assistant_buffer, pending_lines, dirty_logs
        if not assistant_buffer.strip():
            return
        block = assistant_buffer.strip()
        if len(block) > 8000:
            block = block[:8000] + "\n... [–æ–±—Ä–µ–∑–∞–Ω–æ, –≤—Å–µ–≥–æ {} —Å–∏–º–≤–æ–ª–æ–≤]".format(len(assistant_buffer))
        run_obj.logs = (run_obj.logs or "") + "üí¨ –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏:\n" + block + "\n\n"
        pending_lines += 1
        dirty_logs = True
        assistant_buffer = ""

    def maybe_flush():
        nonlocal pending_lines, pending_events, dirty_logs, dirty_events
        if pending_lines >= _LOG_SAVE_BATCH_SIZE or pending_events >= _LOG_SAVE_BATCH_SIZE:
            fields = []
            if dirty_logs:
                fields.append("logs")
            if dirty_events:
                fields.extend(["log_events", "meta"])
            if fields:
                run_obj.save(update_fields=fields)
            pending_lines = 0
            pending_events = 0
            dirty_logs = False
            dirty_events = False

    logger.info(f"üìñ –ù–∞—á–∏–Ω–∞–µ–º —á–∏—Ç–∞—Ç—å –≤—ã–≤–æ–¥ –ø—Ä–æ—Ü–µ—Å—Å–∞ PID={process.pid}")
    print(f"[DEBUG] üìñ –ù–∞—á–∏–Ω–∞–µ–º —á–∏—Ç–∞—Ç—å –≤—ã–≤–æ–¥ –ø—Ä–æ—Ü–µ—Å—Å–∞ PID={process.pid}", flush=True)
    
    # –û—á–µ—Ä–µ–¥—å –¥–ª—è —á—Ç–µ–Ω–∏—è stdout –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ (—á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –∏ –≤–∏–¥–µ—Ç—å "—Å–µ—Ä–¥—Ü–µ–±–∏–µ–Ω–∏–µ")
    output_queue = queue.Queue()
    
    def _reader():
        try:
            for line in process.stdout:
                output_queue.put(line)
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ stdout: {e}")
            print(f"[DEBUG] ‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è stdout: {e}", flush=True)
        finally:
            output_queue.put(None)  # —Å–∏–≥–Ω–∞–ª –∫–æ–Ω—Ü–∞ –≤—ã–≤–æ–¥–∞
    
    reader_thread = threading.Thread(target=_reader, daemon=True)
    reader_thread.start()
    
    start_wait = time.time()
    first_line_seen = False
    
    while True:
        try:
            line = output_queue.get(timeout=5)
        except queue.Empty:
            elapsed = int(time.time() - start_wait)
            first_output_timeout = getattr(settings, "CLI_FIRST_OUTPUT_TIMEOUT_SECONDS", 120)
            
            if not first_line_seen and elapsed >= first_output_timeout:
                # Claude —Ç–∞–∫ –∏ –Ω–µ –≤—ã–≤–µ–ª –Ω–∏ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ ‚Äî –ø—Ä–µ—Ä—ã–≤–∞–µ–º (–≤–µ—Ä–æ—è—Ç–Ω–æ, MCP –Ω–µ –∑–∞–ø—É—Å—Ç–∏–ª—Å—è)
                logger.error(
                    f"‚ùå –¢–∞–π–º–∞—É—Ç –ø–µ—Ä–≤–æ–≥–æ –≤—ã–≤–æ–¥–∞: Claude –Ω–µ –≤—ã–≤–µ–ª –Ω–∏ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ –∑–∞ {elapsed} —Å–µ–∫. "
                    f"–ü—Ä–µ—Ä—ã–≤–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å PID={process.pid}."
                )
                print(
                    f"[DEBUG] ‚ùå –¢–∞–π–º–∞—É—Ç –ø–µ—Ä–≤–æ–≥–æ –≤—ã–≤–æ–¥–∞ ({elapsed} —Å–µ–∫). –ü—Ä–µ—Ä—ã–≤–∞–µ–º PID={process.pid}",
                    flush=True,
                )
                try:
                    process.kill()
                except Exception:
                    pass
                err_msg = (
                    f"Claude –Ω–µ –≤—ã–≤–µ–ª –Ω–∏ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ –∑–∞ {elapsed} —Å–µ–∫. –ü—Ä–æ—Ü–µ—Å—Å –ø—Ä–µ—Ä–≤–∞–Ω.\n\n"
                    f"–í–µ—Ä–æ—è—Ç–Ω–∞—è –ø—Ä–∏—á–∏–Ω–∞: Claude –∂–¥—ë—Ç –æ—Ç–≤–µ—Ç–∞ MCP-—Å–µ—Ä–≤–µ—Ä–∞, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ —É—Å–ø–µ–ª –∑–∞–ø—É—Å—Ç–∏—Ç—å—Å—è –∏–ª–∏ –∑–∞–≤–∏—Å –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ Django.\n\n"
                    f"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ MCP-—Å–µ—Ä–≤–µ—Ä –≤—Ä—É—á–Ω—É—é (–∏–∑ —Ç–æ–π –∂–µ —Å—Ä–µ–¥—ã, –æ—Ç–∫—É–¥–∞ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è workflow):\n"
                    f"  WEU_USER_ID=<id> python manage.py mcp_servers\n"
                    f"–ï—Å–ª–∏ –∫–æ–º–∞–Ω–¥–∞ –∑–∞–≤–∏—Å–∞–µ—Ç –∏–ª–∏ –ø–∞–¥–∞–µ—Ç ‚Äî –∏—Å–ø—Ä–∞–≤—å—Ç–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ/–ë–î/–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏."
                )
                run_obj.logs = (run_obj.logs or "") + f"\n[ERROR] {err_msg}\n"
                _append_log_event(
                    run_obj,
                    {
                        "type": "error",
                        "title": "–¢–∞–π–º–∞—É—Ç –ø–µ—Ä–≤–æ–≥–æ –≤—ã–≤–æ–¥–∞ (MCP?)",
                        "message": err_msg,
                        "step_label": step_label,
                    },
                )
                run_obj.save(update_fields=["logs", "log_events", "meta"])
                return {"success": False, "output": "".join(output_chunks), "exit_code": -2}
            
            msg = f"‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –≤—ã–≤–æ–¥–∞ –æ—Ç Claude (PID={process.pid}), –ø—Ä–æ—à–ª–æ {elapsed} —Å–µ–∫..."
            logger.warning(msg)
            print(f"[DEBUG] {msg}", flush=True)
            hint = ""
            if elapsed >= 10:
                hint = f" (–ï—Å–ª–∏ > {first_output_timeout} —Å–µ–∫ ‚Äî –ø—Ä–æ—Ü–µ—Å—Å –±—É–¥–µ—Ç –ø—Ä–µ—Ä–≤–∞–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ MCP: python manage.py mcp_servers)"
            run_obj.logs = (run_obj.logs or "") + f"\n[DEBUG] {msg}{hint}\n"
            run_obj.save(update_fields=["logs"])
            continue
        
        if line is None:
            # stdout –∑–∞–∫—Ä—ã—Ç ‚Äî –ø—Ä–æ—Ü–µ—Å—Å –∑–∞–≤–µ—Ä—à–∏–ª –≤—ã–≤–æ–¥
            flush_assistant_buffer()
            logger.info(f"üì≠ stdout –ø—Ä–æ—Ü–µ—Å—Å–∞ PID={process.pid} –∑–∞–∫—Ä—ã—Ç")
            print(f"[DEBUG] üì≠ stdout –∑–∞–∫—Ä—ã—Ç", flush=True)
            reader_thread.join(timeout=2)
            break
        
        line_number += 1
        output_chunks.append(line)
        line_stripped = line.strip()
        
        if not first_line_seen:
            first_line_seen = True
            elapsed = time.time() - start_wait
            logger.info(f"‚úÖ –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –æ—Ç Claude –ø–æ–ª—É—á–µ–Ω–∞ —á–µ—Ä–µ–∑ {elapsed:.1f} —Å–µ–∫")
            print(f"[DEBUG] ‚úÖ –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –æ—Ç Claude —á–µ—Ä–µ–∑ {elapsed:.1f} —Å–µ–∫", flush=True)
            run_obj.logs = (run_obj.logs or "") + f"\n[DEBUG] ‚úÖ –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –æ—Ç Claude —á–µ—Ä–µ–∑ {elapsed:.1f} —Å–µ–∫\n"
            run_obj.save(update_fields=["logs"])
        
        if line_stripped.startswith("{"):
            try:
                data = json.loads(line_stripped)
                
                json_type = data.get("type", "unknown")
                if json_type == "error":
                    error_msg = data.get("message", "unknown error")
                    logger.error(f"‚ùå Error –≤ JSON: {error_msg}")

                # –ü–µ—Ä–µ–¥ tool_call/result –≤—ã–≤–æ–¥–∏–º –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏ –æ–¥–Ω–∏–º –±–ª–æ–∫–æ–º
                if data.get("type") in ("tool_call", "result"):
                    flush_assistant_buffer()
                if data.get("type") == "assistant":
                    content = data.get("message", {}).get("content", [])
                    if content and isinstance(content, list) and content[0].get("text"):
                        t = content[0].get("text", "")
                        accumulated_text += t
                        assistant_buffer += t
                log_line = _format_stream_json_log(data, run_obj)
                if data.get("type") == "tool_call" and data.get("subtype") == "started":
                    tool_count += 1
                event = _stream_json_to_event(data, step_label)
                if event:
                    _append_log_event(run_obj, event)
                    pending_events += 1
                    dirty_events = True
                    maybe_flush()
                if log_line:
                    run_obj.logs = (run_obj.logs or "") + log_line + "\n"
                    pending_lines += 1
                    dirty_logs = True
                    maybe_flush()
            except json.JSONDecodeError as e:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –≤ —Å—Ç—Ä–æ–∫–µ #{line_number}: {e}")
                logger.warning(f"   –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç—Ä–æ–∫–∏: {line_stripped[:200]}...")
                run_obj.logs = (run_obj.logs or "") + line
                if add_output_events and line_stripped:
                    _append_log_event(
                        run_obj,
                        {
                            "type": "cmd_output",
                            "title": "–í—ã–≤–æ–¥ CLI",
                            "message": line_stripped[:2000],
                            "step_label": step_label,
                            "line": line_number,
                        },
                    )
                    pending_events += 1
                    dirty_events = True
                pending_lines += 1
                dirty_logs = True
                maybe_flush()
        else:
            # –°—ã—Ä–æ–π –≤—ã–≤–æ–¥ (–ø—Ä–æ–º–ø—Ç, —ç—Ö–æ) –Ω–µ –ø–∏—à–µ–º –≤ run_obj.logs ‚Äî —Ç–æ–ª—å–∫–æ JSON-—Å–æ–±—ã—Ç–∏—è –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
            if line_stripped and add_output_events:
                _append_log_event(
                    run_obj,
                    {
                        "type": "cmd_output",
                        "title": "–í—ã–≤–æ–¥ CLI",
                        "message": line_stripped[:2000],
                        "step_label": step_label,
                        "line": line_number,
                    },
                )
                pending_events += 1
                dirty_events = True
                maybe_flush()

    logger.info(f"‚è≥ –û–∂–∏–¥–∞–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ PID={process.pid}")
    print(f"[DEBUG] ‚è≥ –û–∂–∏–¥–∞–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ PID={process.pid}", flush=True)
    
    timeout_sec = getattr(settings, "CLI_RUNTIME_TIMEOUT_SECONDS", None)
    logger.info(f"‚è±Ô∏è Timeout –Ω–∞—Å—Ç—Ä–æ–π–∫–∞: {timeout_sec if timeout_sec else '–Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω (–∂–¥–µ–º –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ)'}")
    print(f"[DEBUG] ‚è±Ô∏è Timeout: {timeout_sec if timeout_sec else '–Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω'}", flush=True)
    
    try:
        exit_code = process.wait(timeout=timeout_sec) if timeout_sec else process.wait()
        logger.info(f"üèÅ –ü—Ä–æ—Ü–µ—Å—Å –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å exit_code={exit_code}")
        print(f"[DEBUG] üèÅ Exit code={exit_code}", flush=True)
    except subprocess.TimeoutExpired:
        logger.error(f"‚è∞ TIMEOUT! –ü—Ä–æ—Ü–µ—Å—Å PID={process.pid} –ø—Ä–µ–≤—ã—Å–∏–ª –ª–∏–º–∏—Ç {timeout_sec} —Å–µ–∫—É–Ω–¥")
        print(f"[DEBUG] ‚è∞ TIMEOUT! PID={process.pid}", flush=True)
        process.kill()
        logger.info(f"üî™ –ü—Ä–æ—Ü–µ—Å—Å PID={process.pid} –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω (kill)")
        print(f"[DEBUG] üî™ –ü—Ä–æ—Ü–µ—Å—Å —É–±–∏—Ç", flush=True)
        run_obj.logs = (run_obj.logs or "") + f"[TIMEOUT] Process killed after {timeout_sec} seconds\n"
        _append_log_event(
            run_obj,
            {
                "type": "error",
                "title": "–ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è",
                "message": f"Process killed after timeout ({timeout_sec}s)",
                "step_label": step_label,
            },
        )
        run_obj.save(update_fields=["logs", "log_events", "meta"])
        return {"success": False, "output": "".join(output_chunks), "exit_code": -1}

    output_str = "".join(output_chunks)

    # –ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏ –æ–¥–Ω–∏–º –±–ª–æ–∫–æ–º –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏ –ª–æ–≥–æ–≤
    if accumulated_text.strip():
        run_obj.logs = (run_obj.logs or "") + "\n--- –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏ ---\n" + accumulated_text.strip() + "\n---\n"

    # –ö—Ä–∞—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
    completion_info = f"\nüìä –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ: exit_code={exit_code}, —Å—Ç—Ä–æ–∫={line_number}, –≤—ã–∑–æ–≤–æ–≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤={tool_count}, —Ç–µ–∫—Å—Ç={len(accumulated_text)} —Å–∏–º–≤–æ–ª–æ–≤\n"
    
    print(f"[DEBUG] üìä –ó–ê–í–ï–†–®–ï–ù–ò–ï: exit_code={exit_code}, —Å—Ç—Ä–æ–∫={line_number}, —Ä–∞–∑–º–µ—Ä={len(output_str)}", flush=True)
    
    if exit_code != 0:
        completion_info += f"\n‚ö†Ô∏è –ü–†–û–¶–ï–°–° –ó–ê–í–ï–†–®–ò–õ–°–Ø –° –û–®–ò–ë–ö–û–ô (exit_code={exit_code})\n"
        print(f"[DEBUG] ‚ö†Ô∏è –û–®–ò–ë–ö–ê! exit_code={exit_code}", flush=True)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–∏—á–∏–Ω—É –æ—à–∏–±–∫–∏
        if exit_code == -9:
            completion_info += f"  –ü—Ä–∏—á–∏–Ω–∞: –ü—Ä–æ—Ü–µ—Å—Å –±—ã–ª —É–±–∏—Ç (SIGKILL) - –≤–æ–∑–º–æ–∂–Ω–æ –Ω–µ—Ö–≤–∞—Ç–∫–∞ –ø–∞–º—è—Ç–∏ –∏–ª–∏ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ\n"
        elif exit_code == -15:
            completion_info += f"  –ü—Ä–∏—á–∏–Ω–∞: –ü—Ä–æ—Ü–µ—Å—Å –ø–æ–ª—É—á–∏–ª SIGTERM\n"
        elif exit_code == 1:
            completion_info += f"  –ü—Ä–∏—á–∏–Ω–∞: –û–±—â–∞—è –æ—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è\n"
        elif exit_code == 127:
            completion_info += f"  –ü—Ä–∏—á–∏–Ω–∞: –ö–æ–º–∞–Ω–¥–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞\n"
        else:
            completion_info += f"  –ü—Ä–∏—á–∏–Ω–∞: –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞\n"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å—Ç—Ä–æ–∫–∏ –≤—ã–≤–æ–¥–∞
        if output_str:
            last_lines = output_str.strip().split('\n')[-10:]
            completion_info += f"\n  –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Å—Ç—Ä–æ–∫ –≤—ã–≤–æ–¥–∞:\n"
            for i, last_line in enumerate(last_lines, 1):
                completion_info += f"    [{i}] {last_line[:150]}\n"
    
    logger.info(completion_info)
    run_obj.logs = (run_obj.logs or "") + completion_info
    
    if exit_code != 0 and ("Connection stalled" in output_str or "connection stalled" in output_str.lower()):
        run_obj.logs = (run_obj.logs or "") + (
            "\n‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å Cursor API (Connection stalled). "
            "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–µ—Ç—å, –ø–æ–¥–ø–∏—Å–∫—É Cursor –∏ —Å—Ç–∞—Ç—É—Å status.cursor.com; –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ —à–∞–≥ (Retry).\n"
        )
        run_obj.save(update_fields=["logs"])
    summary = f"\n{'‚îÄ'*40}\nüìä –ò—Ç–æ–≥–æ: {tool_count} –æ–ø–µ—Ä–∞—Ü–∏–π, {len(accumulated_text)} —Å–∏–º–≤–æ–ª–æ–≤\n"
    summary += "‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ\n" if exit_code == 0 else f"‚ùå –ó–∞–≤–µ—Ä—à–µ–Ω–æ —Å –æ—à–∏–±–∫–æ–π (–∫–æ–¥ {exit_code})\n"
    summary += f"{'‚îÄ'*40}\n"
    run_obj.logs = (run_obj.logs or "") + summary
    _append_log_event(
        run_obj,
        {
            "type": "summary",
            "title": "–ò—Ç–æ–≥–∏ —à–∞–≥–∞",
            "step_label": step_label,
            "stats": {"tools": tool_count, "chars": len(accumulated_text), "exit_code": exit_code},
        },
    )
    run_obj.save(update_fields=["logs", "log_events", "meta"])
    return {"success": exit_code == 0, "output": output_str, "exit_code": exit_code}


def _resolve_cli_command(runtime: str) -> str:
    logger.info(f"\n{'üîç'*30}")
    logger.info(f"üîç _resolve_cli_command –≤—ã–∑–≤–∞–Ω –¥–ª—è runtime: {runtime}")

    # –ó–∞–º–µ–Ω—è–µ–º "auto" –Ω–∞ default_provider
    if runtime == "auto":
        from app.core.model_config import model_manager
        runtime = model_manager.config.default_provider or "cursor"
        logger.info(f"  _resolve_cli_command: replaced 'auto' with '{runtime}'")

    # Ralph ‚Äî —ç—Ç–æ —Ä–µ–∂–∏–º –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏–∏. –ò—Å–ø–æ–ª—å–∑—É–µ–º CLI –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫.
    if runtime == "ralph":
        from app.core.model_config import model_manager
        runtime = model_manager.config.default_provider or "cursor"
        logger.info(f"  _resolve_cli_command: Ralph mode - using {runtime} CLI")
    
    env_var = _cli_env_var(runtime)
    logger.info(f"  ENV –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è {runtime}: {env_var}")
    
    # –î–ª—è cursor –∏ claude –≤ Docker/–Ω–∞ —Ö–æ—Å—Ç–µ —è–≤–Ω–æ —É—á–∏—Ç—ã–≤–∞–µ–º env var –ø—Ä–∏ –∫–∞–∂–¥–æ–º –≤—ã–∑–æ–≤–µ
    if runtime in ["cursor", "claude"]:
        path_from_env = (os.getenv(env_var) or "").strip()
        logger.info(f"  –ü—Ä–æ–≤–µ—Ä–∫–∞ ENV –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π {env_var}: {path_from_env if path_from_env else '–ù–ï –£–°–¢–ê–ù–û–í–õ–ï–ù–ê'}")
        
        if path_from_env:
            if Path(path_from_env).exists():
                logger.info(f"  ‚úÖ –ù–∞–π–¥–µ–Ω CLI –ø–æ –ø—É—Ç–∏ –∏–∑ ENV: {path_from_env}")
                logger.info(f"{'üîç'*30}\n")
                return path_from_env
            logger.error(f"  ‚ùå {env_var} –∑–∞–¥–∞–Ω, –Ω–æ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path_from_env}")
            raise RuntimeError(
                f"{env_var} –∑–∞–¥–∞–Ω, –Ω–æ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path_from_env}. "
                "–ü—Ä–æ–≤–µ—Ä—å –ø—É—Ç—å –≤ .env (–≤ Docker ‚Äî –ø—É—Ç—å –≤–Ω—É—Ç—Ä–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞, –Ω–∞–ø—Ä–∏–º–µ—Ä –∫ —Å–º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É –±–∏–Ω–∞—Ä–Ω–∏–∫—É)."
            )

    runtime_cfg = settings.CLI_RUNTIME_CONFIG.get(runtime) or {}
    logger.info(f"  Runtime config: {runtime_cfg}")
    
    command = runtime_cfg.get("command", "")
    logger.info(f"  Command –∏–∑ config: {command}")
    
    if not command:
        logger.error(f"  ‚ùå CLI –¥–ª—è '{runtime}' –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
        raise RuntimeError(f"CLI –¥–ª—è '{runtime}' –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
    
    if os.path.isabs(command):
        logger.info(f"  Command —è–≤–ª—è–µ—Ç—Å—è –∞–±—Å–æ–ª—é—Ç–Ω—ã–º –ø—É—Ç–µ–º")
        if not Path(command).exists():
            logger.error(f"  ‚ùå CLI —Ñ–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {command}")
            raise RuntimeError(
                f"CLI –¥–ª—è '{runtime}' –Ω–µ –Ω–∞–π–¥–µ–Ω: {command}. "
                f"–ü—Ä–æ–≤–µ—Ä—å –ø—É—Ç—å –∏–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è {env_var}"
            )
        logger.info(f"  ‚úÖ –ù–∞–π–¥–µ–Ω CLI –ø–æ –∞–±—Å–æ–ª—é—Ç–Ω–æ–º—É –ø—É—Ç–∏: {command}")
        logger.info(f"{'üîç'*30}\n")
        return command

    logger.info(f"  –ò—â–µ–º command –≤ PATH: {command}")
    resolved = shutil.which(command)
    logger.info(f"  –†–µ–∑—É–ª—å—Ç–∞—Ç shutil.which: {resolved if resolved else '–ù–ï –ù–ê–ô–î–ï–ù'}")
    
    if not resolved:
        logger.error(f"  ‚ùå CLI –¥–ª—è '{runtime}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ PATH")
        if runtime == "cursor":
            raise RuntimeError(
                "CLI –¥–ª—è 'cursor' –Ω–µ –Ω–∞–π–¥–µ–Ω (–±–∏–Ω–∞—Ä–Ω–∏–∫ agent). "
                "–í Docker –≤ .env –∑–∞–¥–∞–π CURSOR_CLI_PATH=/–ø–æ–ª–Ω—ã–π/–ø—É—Ç—å/–∫/agent (–±–∏–Ω–∞—Ä–Ω–∏–∫ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ –æ–±—Ä–∞–∑–µ –∏–ª–∏ —Å–º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω). "
                "–ù–∞ —Ö–æ—Å—Ç–µ –¥–æ–±–∞–≤—å agent –≤ PATH –∏–ª–∏ –∑–∞–¥–∞–π CURSOR_CLI_PATH."
            )
        elif runtime == "claude":
            raise RuntimeError(
                "CLI –¥–ª—è 'claude' –Ω–µ –Ω–∞–π–¥–µ–Ω (–±–∏–Ω–∞—Ä–Ω–∏–∫ claude). "
                "–í Docker –≤ .env –∑–∞–¥–∞–π CLAUDE_CLI_PATH=/–ø–æ–ª–Ω—ã–π/–ø—É—Ç—å/–∫/claude (–±–∏–Ω–∞—Ä–Ω–∏–∫ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ –æ–±—Ä–∞–∑–µ –∏–ª–∏ —Å–º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω). "
                "–ù–∞ —Ö–æ—Å—Ç–µ –¥–æ–±–∞–≤—å claude –≤ PATH –∏–ª–∏ –∑–∞–¥–∞–π CLAUDE_CLI_PATH."
            )
        raise RuntimeError(
            f"CLI –¥–ª—è '{runtime}' –Ω–µ –Ω–∞–π–¥–µ–Ω: {command}. "
            f"–î–æ–±–∞–≤—å –≤ PATH –∏–ª–∏ –∑–∞–¥–∞–π –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è {env_var}"
        )
    
    logger.info(f"  ‚úÖ –ù–∞–π–¥–µ–Ω CLI –≤ PATH: {resolved}")
    logger.info(f"{'üîç'*30}\n")
    return resolved


def _cli_env_var(runtime: str) -> str:
    return {
        "cursor": "CURSOR_CLI_PATH",
        "claude": "CLAUDE_CLI_PATH",
        "opencode": "OPENCODE_CLI_PATH",
        "gemini": "GEMINI_CLI_PATH",
        "ralph": "RALPH_CLI_PATH",
    }.get(runtime, "CLI_PATH")


def _format_arg(runtime_cfg: Dict[str, Any], arg: str, workspace: str = None) -> str:
    logger.debug(f"  _format_arg: arg={arg}, workspace={workspace}")
    if arg != "{workspace}":
        logger.debug(f"    -> –≤–æ–∑–≤—Ä–∞—â–∞–µ–º arg –∫–∞–∫ –µ—Å—Ç—å: {arg}")
        return arg
    if workspace:
        logger.debug(f"    -> –∑–∞–º–µ–Ω—è–µ–º {{workspace}} –Ω–∞: {workspace}")
        return workspace
    base_dir = str(getattr(settings, "BASE_DIR", ""))
    logger.debug(f"    -> –∏—Å–ø–æ–ª—å–∑—É–µ–º BASE_DIR: {base_dir}")
    return base_dir


def _write_ralph_yml(path: Path, content: Dict[str, Any]) -> None:
    lines = []
    cli = content.get("cli", {})
    event_loop = content.get("event_loop", {})
    hats = content.get("hats", {})

    lines.append("cli:")
    lines.append(f"  backend: \"{cli.get('backend', 'cursor')}\"")
    lines.append("event_loop:")
    lines.append(f"  completion_promise: \"{event_loop.get('completion_promise', 'LOOP_COMPLETE')}\"")
    lines.append(f"  max_iterations: {event_loop.get('max_iterations', 50)}")
    lines.append(f"  starting_event: \"{event_loop.get('starting_event', 'task.start')}\"")
    lines.append("hats:")
    for hat_id, hat in hats.items():
        lines.append(f"  {hat_id}:")
        lines.append(f"    name: \"{hat.get('name', hat_id)}\"")
        lines.append(f"    description: \"{hat.get('description', '')}\"")
        triggers = hat.get("triggers", [])
        publishes = hat.get("publishes", [])
        lines.append(f"    triggers: {json.dumps(triggers)}")
        lines.append(f"    publishes: {json.dumps(publishes)}")
        instructions = (hat.get("instructions") or "").replace("\n", "\\n")
        lines.append(f"    instructions: \"{instructions}\"")

    path.write_text("\n".join(lines), encoding="utf-8")


def _get_user_servers_context(user_id: int, target_server_id: int = None) -> str:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ —Å–µ—Ä–≤–µ—Ä–∞—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ –≤–∫–ª–∞–¥–∫–∏ Servers –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞ –≤–æ—Ä–∫—Ñ–ª–æ—É.
    –ï—Å–ª–∏ target_server_id —É–∫–∞–∑–∞–Ω ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ª—å–∫–æ —ç—Ç–æ—Ç —Å–µ—Ä–≤–µ—Ä —Å —è–≤–Ω–æ–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–µ–π –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –µ–≥–æ.
    –ï—Å–ª–∏ —Å–µ—Ä–≤–µ—Ä—ã –µ—Å—Ç—å ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∏ —Å–ø–∏—Å–æ–∫; –∏–Ω–∞—á–µ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É.
    –ï—Å–ª–∏ –∑–∞–¥–∞–Ω MASTER_PASSWORD –≤ env ‚Äî —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤—ã–≤–∞–µ—Ç –ø–∞—Ä–æ–ª–∏ –∏ –ø–æ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –∫–æ–º–∞–Ω–¥—ã –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è.
    """
    try:
        from servers.models import Server
        from passwords.encryption import PasswordEncryption
        master_pwd = os.environ.get("MASTER_PASSWORD", "").strip()
        
        qs = Server.objects.filter(user_id=user_id)
        if target_server_id:
            qs = qs.filter(id=target_server_id)
        servers = list(qs.only(
            "id", "name", "host", "port", "username", "auth_method", "key_path", "encrypted_password", "salt"
        ))
        if not servers:
            return ""
        
        # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Å–µ—Ä–≤–µ—Ä ‚Äî –¥–∞—ë–º —è–≤–Ω—É—é –∏ —Å—Ç—Ä–æ–≥—É—é –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é
        if target_server_id and len(servers) == 1:
            target_name = servers[0].name
            target_host = servers[0].host
            lines = [
                f"\n\n{'='*60}",
                f"=== –°–ï–†–í–ï–†–ù–ê–Ø –ó–ê–î–ê–ß–ê: {target_name} ({target_host}) ===",
                f"{'='*60}",
                "",
                "!!! –≠–¢–û –°–ï–†–í–ï–†–ù–ê–Ø –ó–ê–î–ê–ß–ê - –†–ê–ë–û–¢–ê–ô –¢–û–õ–¨–ö–û –° –°–ï–†–í–ï–†–û–ú !!!",
                "",
                "–ó–ê–ü–†–ï–©–ï–ù–û:",
                "- –ù–ï —á–∏—Ç–∞–π —Ñ–∞–π–ª—ã –ø—Ä–æ–µ–∫—Ç–∞ (*.py, *.js –∏ –¥—Ä.)",
                "- –ù–ï –∏—â–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –∏–ª–∏ –∫–ª–∞—Å—Å—ã –≤ –∫–æ–¥–µ",
                "- –ù–ï –≤—ã–∑—ã–≤–∞–π python —Ñ—É–Ω–∫—Ü–∏–∏ –∏–ª–∏ API",
                "- –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π Glob, Grep, Read –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–æ–¥–∞",
                "",
                "–†–ê–ó–†–ï–®–ï–ù–û –¢–û–õ–¨–ö–û:",
                f"- –í—ã–ø–æ–ª–Ω—è—Ç—å SSH –∫–æ–º–∞–Ω–¥—ã –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ ¬´{target_name}¬ª",
                "- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å server_execute MCP tool",
                "- –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ Linux –∫–æ–º–∞–Ω–¥—ã: df, free, ps, systemctl, apt –∏ —Ç.–¥.",
                "",
                f"–¶–µ–ª–µ–≤–æ–π —Å–µ—Ä–≤–µ—Ä: {target_name}",
                f"–î–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥ –∏—Å–ø–æ–ª—å–∑—É–π:",
                f"  server_execute —Å server_name_or_id=\"{target_name}\"",
                "",
                f"–ü—Ä–∏–º–µ—Ä:",
                f"  tool server_execute {{\"server_name_or_id\": \"{target_name}\", \"command\": \"df -h\"}}",
                "",
            ]
        else:
            lines = [
                "\n\n=== –°–ï–†–í–ï–†–´ –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø (–∏–∑ –≤–∫–ª–∞–¥–∫–∏ Servers) ===",
                "–í–ê–ñ–ù–û: –î–∞–Ω–Ω—ã–µ —Å–µ—Ä–≤–µ—Ä–æ–≤ —Ö—Ä–∞–Ω—è—Ç—Å—è –≤ –ë–î. –ù–ï –∏—â–∏ –∏—Ö –≤ –∫–æ–¥–µ!",
                "–ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–π MCP-–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã servers_list / server_execute (—Å–µ—Ä–≤–µ—Ä weu-servers) ‚Äî —ç—Ç–æ –Ω–∞–¥–µ–∂–Ω–µ–µ SSH –∏–∑ shell.",
                "–ü—Ä–∏–º–µ—Ä: tool server_execute {server_name_or_id: \"WEU SERVER\", command: \"uname -a\"}",
                "–ï—Å–ª–∏ MCP –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–π SSH –Ω–∞–ø—Ä—è–º—É—é –ø–æ —É–∫–∞–∑–∞–Ω–Ω—ã–º –¥–∞–Ω–Ω—ã–º.",
                "",
            ]
        for s in servers:
            auth = s.auth_method or "password"
            key_path = s.key_path or ""
            pwd_decrypted = ""
            if auth in ("password", "key_password") and s.encrypted_password and master_pwd and s.salt:
                try:
                    pwd_decrypted = PasswordEncryption.decrypt_password(s.encrypted_password, master_pwd, bytes(s.salt))
                except Exception as e:
                    logger.debug(f"Password decryption failed for server {s.name}: {e}")
                    pwd_decrypted = ""
            # –§–æ—Ä–º–∏—Ä—É–µ–º –≥–æ—Ç–æ–≤—É—é –∫–æ–º–∞–Ω–¥—É –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
            cmd_hint = ""
            if auth == "key" and key_path:
                cmd_hint = f"ssh -i {key_path} {s.username}@{s.host} -p {s.port} '<command>'"
            elif pwd_decrypted:
                safe_pwd = pwd_decrypted.replace("'", "'\\''")
                cmd_hint = f"sshpass -p '{safe_pwd}' ssh -o StrictHostKeyChecking=no {s.username}@{s.host} -p {s.port} '<command>'"
            else:
                cmd_hint = f"ssh {s.username}@{s.host} -p {s.port} '<command>'  # –ø–∞—Ä–æ–ª—å –Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω, –∑–∞–¥–∞–π MASTER_PASSWORD –≤ env"
            lines.append(f"- {s.name}:")
            lines.append(f"    {cmd_hint}")

            # Add server knowledge context
            try:
                from servers.knowledge_service import ServerKnowledgeService
                from django.contrib.auth.models import User
                user = User.objects.get(id=user_id)
                knowledge_ctx = ServerKnowledgeService.get_full_context(s, user)
                if knowledge_ctx:
                    lines.append("")
                    lines.append(knowledge_ctx)
            except Exception as e:
                logger.debug(f"Failed to get knowledge context for {s.name}: {e}")

        lines.append("")
        lines.append("sshpass —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ü—Ä–∏ –æ—à–∏–±–∫–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è ‚Äî –ø—Ä–æ–≤–µ—Ä—å host/port/username.")
        lines.append("")
        return "\n".join(lines)
    except Exception as e:
        logger.warning(f"_get_user_servers_context error: {e}")
        return ""


def _execute_workflow_run(run_id: int):
    run_obj = AgentWorkflowRun.objects.get(id=run_id)
    workflow = run_obj.workflow
    run_obj.status = "running"
    run_obj.started_at = timezone.now()

    # –ö–æ–Ω—Ç–µ–∫—Å—Ç —Å–µ—Ä–≤–µ—Ä–æ–≤: –∑–∞–≥—Ä—É–∂–∞–µ–º –¢–û–õ–¨–ö–û –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω target_server
    # –ï—Å–ª–∏ target_server –Ω–µ —É–∫–∞–∑–∞–Ω ‚Äî workflow –Ω–µ —Å–≤—è–∑–∞–Ω —Å —Å–µ—Ä–≤–µ—Ä–∞–º–∏, –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Ö
    user_id = run_obj.initiated_by_id
    target_server_id = workflow.target_server_id
    servers_context = ""
    
    if target_server_id and user_id:
        # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ —è–≤–Ω–æ —É–∫–∞–∑–∞–Ω —Ü–µ–ª–µ–≤–æ–π —Å–µ—Ä–≤–µ—Ä ‚Äî –∑–∞–≥—Ä—É–∂–∞–µ–º –µ–≥–æ –¥–∞–Ω–Ω—ã–µ
        servers_context = _get_user_servers_context(user_id, target_server_id)

    is_server_task = target_server_id is not None

    # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ workspace –∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ—Å—Ç—É–ø (empty/whitelist)
    workspace = _get_workspace_path(workflow)
    workspace_cleanup_dir = None
    try:
        from agent_hub.views.utils import prepare_workspace_for_cli
        workspace, workspace_cleanup_dir = prepare_workspace_for_cli(workflow, workspace, is_server_task)
        if workspace_cleanup_dir:
            run_obj.logs = (run_obj.logs or "") + f"[Workspace restriction: using temp dir]\n"
    except Exception as e:
        logger.warning(f"prepare_workspace_for_cli failed: {e}")

    run_obj.logs = (run_obj.logs or "") + f"[Workflow started]\n[Workspace: {workspace}]\n"
    _append_log_event(
        run_obj,
        {
            "type": "workflow",
            "subtype": "start",
            "title": "–°—Ç–∞—Ä—Ç workflow",
            "workflow_id": workflow.id,
            "workflow_name": workflow.name,
            "workspace": workspace,
        },
    )
    if target_server_id:
        run_obj.logs = (run_obj.logs or "") + f"[Target server: {workflow.target_server.name if workflow.target_server else target_server_id}]\n"
        run_obj.logs = (run_obj.logs or "") + "[Servers context loaded from DB]\n"
    else:
        run_obj.logs = (run_obj.logs or "") + "[No target server - local/code-only workflow]\n"
    run_obj.save(update_fields=["status", "started_at", "logs", "log_events", "meta"])

    steps = (workflow.script or {}).get("steps", [])
    step_results = []

    # –§–∞–∑–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–∞–¥–∞—á–∏ —á–µ—Ä–µ–∑ Cursor (ask) –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º
    # –ü–†–û–ü–£–°–ö–ê–ï–ú –¥–ª—è —Å–µ—Ä–≤–µ—Ä–Ω—ã—Ö –∑–∞–¥–∞—á - –∏–º –Ω–µ –Ω—É–∂–µ–Ω –∞–Ω–∞–ª–∏–∑ –∫–æ–¥–∞!
    if getattr(settings, "ANALYZE_TASK_BEFORE_RUN", True) and steps and workspace and not is_server_task:
        run_obj.logs = (run_obj.logs or "") + "\n[Phase: Cursor analyze task]\n"
        _append_log_event(
            run_obj,
            {
                "type": "phase",
                "subtype": "start",
                "title": "Cursor analyze",
                "message": "–ü—Ä–æ–≤–µ—Ä–∫–∞ —à–∞–≥–æ–≤ –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º",
            },
        )
        run_obj.save(update_fields=["logs", "log_events", "meta"])
        summary_lines = [f"–í–æ—Ä–∫—Ñ–ª–æ—É: {workflow.name}. –®–∞–≥–∏ ({len(steps)}):"]
        for i, s in enumerate(steps[:20], 1):
            title = s.get("title", f"Step {i}")
            prompt_preview = (s.get("prompt") or "")[:300]
            summary_lines.append(f"\n{i}. {title}\n   {prompt_preview}")
        task_summary = "\n".join(summary_lines)
        analyze_result = _run_cursor_ask_analyze(workspace, task_summary, timeout_sec=90)
        run_obj.logs = (run_obj.logs or "") + (analyze_result.get("output", "") or "")[:4000] + "\n"
        if analyze_result.get("ready"):
            run_obj.logs = (run_obj.logs or "") + "[Cursor: READY ‚Äî –∑–∞–ø—É—Å–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è]\n"
        else:
            run_obj.logs = (run_obj.logs or "") + "[Cursor: –∞–Ω–∞–ª–∏–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω, –∑–∞–ø—É—Å–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è]\n"
        _append_log_event(
            run_obj,
            {
                "type": "phase",
                "subtype": "done",
                "title": "Cursor analyze",
                "status": "ready" if analyze_result.get("ready") else "review",
            },
        )
        run_obj.save(update_fields=["logs", "log_events", "meta"])

    try:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º CLI –∞–≥–µ–Ω—Ç–∞ –∏–∑ –≥–ª–æ–±–∞–ª—å–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫
        from app.core.model_config import model_manager
        cli_runtime = model_manager.config.default_provider or "cursor"
        
        # –ï—Å–ª–∏ default_provider = "auto" - fallback –Ω–∞ cursor
        if cli_runtime == "auto":
            cli_runtime = "cursor"
            logger.warning(f"default_provider=auto is invalid, using cursor")
        # Ralph is now a valid CLI runtime (do NOT replace)
        
        # –õ–æ–≥–∏—Ä—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        logger.info(f"Workflow {workflow.id}: CLI runtime={cli_runtime}, orchestrator_mode={model_manager.config.default_orchestrator_mode}")
        
        # –†–µ–∂–∏–º –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ö–ê–ö –≤—ã–ø–æ–ª–Ω—è—Ç—å (Ralph —Å –∏—Ç–µ—Ä–∞—Ü–∏—è–º–∏ –∏–ª–∏ –æ–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º)
        # CLI runtime –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ß–¢–û –∑–∞–ø—É—Å–∫–∞—Ç—å (cursor/claude)
        orchestrator_mode = model_manager.config.default_orchestrator_mode or "ralph_internal"
        
        # Ralph mode: –º–Ω–æ–≥–æ–∫—Ä–∞—Ç–Ω—ã–µ –≤—ã–∑–æ–≤—ã CLI –∞–≥–µ–Ω—Ç–∞ —Å –∏—Ç–µ—Ä–∞—Ü–∏—è–º–∏
        if orchestrator_mode.startswith("ralph"):
            run_obj.logs = (run_obj.logs or "") + (
                f"[Settings: CLI={cli_runtime}, orchestrator={orchestrator_mode}]\n"
                f"[Ralph mode: executing via {cli_runtime} CLI with iterations]\n"
            )
            run_obj.save(update_fields=["logs"])
            _run_steps_with_backend(
                run_obj=run_obj,
                steps=steps,
                runtime=cli_runtime,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º cursor/claude
                workflow=workflow,
                step_results=step_results,
                workspace=workspace,
                servers_context=servers_context,
                is_server_task=is_server_task,
            )
        else:
            # Direct mode: –ø—Ä—è–º–æ–π –≤—ã–∑–æ–≤ CLI –∞–≥–µ–Ω—Ç–∞ –±–µ–∑ Ralph –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏–∏
            run_obj.logs = (run_obj.logs or "") + (
                f"[Settings: CLI={cli_runtime}, orchestrator={orchestrator_mode}]\n"
                f"[Direct mode: single {cli_runtime} CLI call]\n"
            )
            run_obj.save(update_fields=["logs"])
            _run_steps_with_backend(
                run_obj=run_obj,
                steps=steps,
                runtime=cli_runtime,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º cursor/claude
                workflow=workflow,
                step_results=step_results,
                workspace=workspace,
                servers_context=servers_context,
                is_server_task=is_server_task,
            )

        run_obj.status = "succeeded"
        run_obj.output_text = json.dumps(step_results, ensure_ascii=False)
        run_obj.meta = {**(run_obj.meta or {}), "steps": len(steps), "workspace": workspace}
    except Exception as exc:
        run_obj.status = "failed"
        run_obj.logs = (run_obj.logs or "") + f"\n{exc}\n"
        run_obj.output_text = json.dumps(step_results, ensure_ascii=False)
    finally:
        if workspace_cleanup_dir:
            try:
                shutil.rmtree(workspace_cleanup_dir, ignore_errors=True)
                logger.debug(f"Cleaned up temp workspace: {workspace_cleanup_dir}")
            except Exception as e:
                logger.warning(f"Failed to cleanup temp workspace {workspace_cleanup_dir}: {e}")
        run_obj.finished_at = timezone.now()
        _append_log_event(
            run_obj,
            {
                "type": "workflow",
                "subtype": "finish",
                "title": "–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ workflow",
                "status": run_obj.status,
            },
        )
        run_obj.save()


def _run_steps_with_backend(
    run_obj: AgentWorkflowRun,
    steps: list,
    runtime: str,
    workflow: AgentWorkflow,
    step_results: list,
    workspace: str = None,
    start_from_step: int = 1,
    servers_context: str = "",
    is_server_task: bool = False,
) -> None:
    # –ó–∞–º–µ–Ω—è–µ–º "auto" –Ω–∞ default_provider –°–†–ê–ó–£
    if runtime == "auto":
        from app.core.model_config import model_manager
        runtime = model_manager.config.default_provider or "cursor"
        logger.info(f"_run_steps_with_backend: replaced 'auto' with '{runtime}'")
    
    # –õ–æ–≥–∏—Ä—É–µ–º runtime –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
    logger.info(f"_run_steps_with_backend called with runtime={runtime} for workflow {workflow.id}")
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ environment variables –¥–ª—è CLI (cursor, claude –∏ –¥—Ä—É–≥–∏–µ)
    extra_env = None
    mcp_config_file = None  # –ü—É—Ç—å –∫ MCP –∫–æ–Ω—Ñ–∏–≥—É –¥–ª—è Claude CLI (--mcp-config)
    if runtime in ["cursor", "claude"]:
        extra_env = _get_cursor_cli_extra_env() if runtime == "cursor" else {}
        extra_env = dict(extra_env or {})
        # –í–ê–ñ–ù–û: –ø–µ—Ä–µ–¥–∞—ë–º HOME –¥–ª—è Claude CLI (credentials –≤ ~/.claude/)
        extra_env.setdefault("HOME", os.path.expanduser("~"))

        if run_obj.initiated_by_id:
            mcp_path = _ensure_mcp_servers_config(workspace, run_obj.initiated_by_id)
            if mcp_path:
                extra_env["MCP_CONFIG_PATH"] = mcp_path
                mcp_config_file = mcp_path  # –î–ª—è Claude CLI --mcp-config
            extra_env.setdefault("WEU_USER_ID", str(run_obj.initiated_by_id))
        
        # –ü–µ—Ä–µ–¥–∞—ë–º —Ü–µ–ª–µ–≤–æ–π —Å–µ—Ä–≤–µ—Ä –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è MCP-–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
        if workflow.target_server_id:
            extra_env["WEU_TARGET_SERVER_ID"] = str(workflow.target_server_id)
            if workflow.target_server:
                extra_env["WEU_TARGET_SERVER_NAME"] = workflow.target_server.name
                logger.info(f"Workflow {workflow.id}: target_server={workflow.target_server.name} (id={workflow.target_server_id})")
        
        # –î–ª—è Claude –ù–ï –ø–µ—Ä–µ–¥–∞—ë–º ANTHROPIC_API_KEY - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—É—é —Å–µ—Å—Å–∏—é Pro
        # –ï—Å–ª–∏ –Ω—É–∂–µ–Ω API —Ä–µ–∂–∏–º - —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ:
        # if runtime == "claude":
        #     import os
        #     if os.getenv("ANTHROPIC_API_KEY"):
        #         extra_env["ANTHROPIC_API_KEY"] = os.getenv("ANTHROPIC_API_KEY")
    max_retries = getattr(run_obj, "max_retries", None) or 3
    step_results_existing = list(run_obj.step_results or [])

    for idx, step in enumerate(steps, start=1):
        if idx < start_from_step:
            existing = [r for r in step_results_existing if r.get("step_idx") == idx]
            if existing and existing[-1].get("status") in ("completed", "skipped"):
                continue
        run_obj.current_step = idx
        run_obj.retry_count = 0
        run_obj.save(update_fields=["current_step", "retry_count"])

        step_title = step.get("title", f"Step {idx}")
        _append_log_event(
            run_obj,
            {
                "type": "step",
                "subtype": "start",
                "title": step_title,
                "step_idx": idx,
                "prompt_preview": (step.get("prompt") or "")[:200],
            },
        )
        run_obj.save(update_fields=["log_events", "meta"])
        step_prompt = step.get("prompt", "")
        completion_promise = (step.get("completion_promise") or "STEP_DONE").strip()
        max_iterations = step.get("max_iterations", 10)
        if isinstance(max_iterations, str) and max_iterations.isdigit():
            max_iterations = int(max_iterations)
        if max_iterations <= 0:
            max_iterations = 10
        use_ralph_loop = step.get("use_ralph_loop", True)
        verify_prompt = step.get("verify_prompt")
        verify_promise = step.get("verify_promise", "PASS")
        
        # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏: step-level override > workflow-level > default (auto)
        workflow_model = (workflow.script or {}).get("model", "auto")
        step_model = step.get("model")  # step-level override (–µ—Å–ª–∏ —Ä–∞–∑—Ä–µ—à–µ–Ω–æ)
        effective_model = step_model if step_model and step_model != "auto" else workflow_model
        
        # –ó–∞–º–µ–Ω—è–µ–º "auto" –Ω–∞ default_provider –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫
        if effective_model == "auto":
            from app.core.model_config import model_manager
            effective_model = model_manager.config.default_provider or "cursor"
        # "ralph" as a model name should use actual runtime
        if effective_model == "ralph":
            effective_model = runtime if runtime not in ("ralph", "auto") else "cursor"
            logger.warning(f"Replaced model=ralph with {effective_model} (use model names, not runtimes)")
            logger.warning(f"Replaced 'ralph' model with '{effective_model}' (ralph is orchestrator, not CLI)")

        # –ù–µ –ø–µ—Ä–µ–¥–∞—ë–º --model –µ—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ —Ä–∞–≤–Ω–æ runtime –∏–ª–∏ "auto"
        # (CLI —Å–∞–º–∏ –≤—ã–±–µ—Ä—É—Ç –º–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
        cli_model = None
        if effective_model not in ("auto", runtime, "cursor", "claude", "gemini"):
            cli_model = effective_model

        config = {
            "use_ralph_loop": use_ralph_loop,
            "completion_promise": completion_promise,
            "max_iterations": max_iterations,
            "model": cli_model,  # None = CLI –≤—ã–±–µ—Ä–µ—Ç —Å–∞–º
        }

        # –ò–ó–û–õ–Ø–¶–ò–Ø –î–õ–Ø –ó–ê–î–ê–ß
        # 1. –°–µ—Ä–≤–µ—Ä–Ω—ã–µ –∑–∞–¥–∞—á–∏ (target_server_id != None)
        # 2. –ó–∞–¥–∞—á–∏ —Å workspace_mode: "empty" –≤ workflow.script
        # 3. –ó–∞–¥–∞—á–∏ —Å restrict_files: true –≤ workflow.script
        # 
        # –†–ï–®–ï–ù–ò–ï: –∏—Å–ø–æ–ª—å–∑—É–µ–º --sandbox enabled –¥–ª—è –ø–æ–ª–Ω–æ–π –∏–∑–æ–ª—è—Ü–∏–∏ filesystem
        # Sandbox –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç –∞–≥–µ–Ω—Ç–∞ —Ç–æ–ª—å–∫–æ workspace –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–µ–π –∏ –∑–∞–ø—Ä–µ—â–∞–µ—Ç:
        # - –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –∑–∞ –ø—Ä–µ–¥–µ–ª–∞–º–∏ workspace
        # - –ó–∞–ø–∏—Å—å —Ñ–∞–π–ª–æ–≤ –∑–∞ –ø—Ä–µ–¥–µ–ª–∞–º–∏ workspace
        # - –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–æ–º–∞–Ω–¥, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –≤—ã–π—Ç–∏ –∑–∞ –ø—Ä–µ–¥–µ–ª—ã workspace
        workflow_script = workflow.script or {}
        workspace_mode = (workflow_script.get("workspace_mode") or "").strip().lower()
        restrict_files = bool(workflow_script.get("restrict_files", False))
        
        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –ù–ï –ø—Ä–∏–º–µ–Ω—è–µ–º –∏–∑–æ–ª—è—Ü–∏—é, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —è–≤–Ω–æ —É–∫–∞–∑–∞–Ω–æ
        needs_isolation = is_server_task or workspace_mode == "empty" or restrict_files
        
        if needs_isolation:
            # –ü–ï–†–ï–ö–õ–Æ–ß–ê–ï–ú–°–Ø –Ω–∞ cursor_server runtime (–±–µ–∑ --force, —Å --sandbox enabled)
            # –≠—Ç–æ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π runtime –¥–ª—è DevOps-–∑–∞–¥–∞—á –ë–ï–ó –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤
            if runtime == "cursor":
                runtime = "cursor_server"
                logger.info(f"–ò–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∑–∞–¥–∞—á–∞: –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ cursor_server runtime")
            
            # –ú–∞—Ä–∫–∏—Ä—É–µ–º –∫–∞–∫ –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∑–∞–¥–∞—á—É
            config["_is_isolated_task"] = True
            
            isolation_reason = (
                "server_task" if is_server_task
                else f"workspace_mode={workspace_mode}" if workspace_mode == "empty"
                else "restrict_files=true"
            )
            logger.info(f"Task isolation ({isolation_reason}): runtime={runtime} (no --force, sandbox enabled)")
            run_obj.logs = (run_obj.logs or "") + f"[Isolation: {isolation_reason}, runtime={runtime}, read-only]\n"
            run_obj.save(update_fields=["logs"])

        # –î–ª—è Claude CLI –ø–µ—Ä–µ–¥–∞—ë–º MCP –∫–æ–Ω—Ñ–∏–≥ (server_execute –∏ –¥—Ä.)
        if runtime == "claude" and mcp_config_file:
            config["mcp-config"] = mcp_config_file

        # –õ–æ–≥–∏—Ä—É–µ–º –∏—Å–ø–æ–ª—å–∑—É–µ–º—É—é –º–æ–¥–µ–ª—å
        model_source = "step" if step_model and step_model != "auto" else "workflow"
        model_info = cli_model if cli_model else f"{runtime} default"
        run_obj.logs = (run_obj.logs or "") + f"\n[Step {idx}: {step_title}] Model: {model_info} (from {model_source})\n"
        run_obj.save(update_fields=["logs"])

        if runtime != "cursor":
            config["specific_model"] = (workflow.script or {}).get("specific_model")

        step_success = False
        last_error = None
        retry_attempt = 0
        while retry_attempt <= max_retries and not step_success:
            try:
                run_obj.retry_count = retry_attempt
                run_obj.save(update_fields=["retry_count"])
                current_prompt_base = step_prompt
                
                # –°–ò–°–¢–ï–ú–ù–´–ô –ü–†–û–ú–ü–¢ –î–õ–Ø –ò–ó–û–õ–ò–†–û–í–ê–ù–ù–´–• –ó–ê–î–ê–ß (—Å–µ—Ä–≤–µ—Ä–Ω—ã–µ, DevOps)
                # –ê–≥–µ–Ω—Ç –¥–æ–ª–∂–µ–Ω —Ä–∞–±–æ—Ç–∞—Ç—å –¢–û–õ–¨–ö–û —Å —Å–µ—Ä–≤–µ—Ä–∞–º–∏ —á–µ—Ä–µ–∑ MCP, –ë–ï–ó –ø–æ–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤
                if needs_isolation:
                    isolation_system_prompt = f"""
=== –†–ï–ñ–ò–ú DEVOPS-–ê–ì–ï–ù–¢–ê: –ò–ó–û–õ–ò–†–û–í–ê–ù–ù–ê–Ø –°–†–ï–î–ê ===

–†–ê–ë–û–ß–ê–Ø –î–ò–†–ï–ö–¢–û–†–ò–Ø: {workspace}
–≠—Ç–æ –ø—É—Å—Ç–∞—è –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è. –ó–¥–µ—Å—å –ù–ï–¢ –∫–æ–¥–∞ –ø—Ä–æ–µ–∫—Ç–∞.

–í–´ –†–ê–ë–û–¢–ê–ï–¢–ï –ö–ê–ö DEVOPS-–ê–ì–ï–ù–¢ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —É–¥–∞–ª–µ–Ω–Ω—ã–º–∏ —Å–µ—Ä–≤–µ—Ä–∞–º–∏ —á–µ—Ä–µ–∑ SSH.

–°–¢–†–û–ì–û –ó–ê–ü–†–ï–©–ï–ù–û:
‚ùå –ò—Å–∫–∞—Ç—å —Ñ–∞–π–ª—ã (Glob, Find, ls -R, find)
‚ùå –ß–∏—Ç–∞—Ç—å —Ñ–∞–π–ª—ã –ø—Ä–æ–µ–∫—Ç–∞ (Read, cat, head, tail)
‚ùå –ü–æ–¥–Ω–∏–º–∞—Ç—å—Å—è –≤–≤–µ—Ä—Ö –ø–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º (../, ../../)
‚ùå –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–æ–µ–∫—Ç–∞
‚ùå –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å SemanticSearch, Grep –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–æ–¥–∞

–î–û–°–¢–£–ü–ù–´–ï –ò–ù–°–¢–†–£–ú–ï–ù–¢–´:
‚úÖ mcp__weu-servers__server_execute - –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∫–æ–º–∞–Ω–¥—É –Ω–∞ —É–¥–∞–ª–µ–Ω–Ω–æ–º —Å–µ—Ä–≤–µ—Ä–µ
‚úÖ mcp__weu-servers__servers_list - —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö SSH —Å–µ—Ä–≤–µ—Ä–æ–≤
‚úÖ Bash - –¢–û–õ–¨–ö–û –¥–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–º–∞–Ω–¥ (–Ω–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤!)

–ö–ê–ö –†–ê–ë–û–¢–ê–¢–¨:
1. –°–Ω–∞—á–∞–ª–∞ –≤—ã–∑–æ–≤–∏ servers_list —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Å–µ—Ä–≤–µ—Ä—ã
2. –ò—Å–ø–æ–ª—å–∑—É–π server_execute –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ
3. –í—Å–µ –∫–æ–º–∞–Ω–¥—ã Docker, systemd, apt, yum - —á–µ—Ä–µ–∑ server_execute
4. –õ–æ–∫–∞–ª—å–Ω—ã–π Bash - —Ç–æ–ª—å–∫–æ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–∫—Ä–∏–ø—Ç–æ–≤, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ

–ï–°–õ–ò –ó–ê–î–ê–ß–ê –¢–†–ï–ë–£–ï–¢ –†–ê–ë–û–¢–´ –° –ö–û–î–û–ú:
–û—Ç–∫–∞–∂–∏—Å—å –∏ –æ–±—ä—è—Å–Ω–∏: "–Ø DevOps-–∞–≥–µ–Ω—Ç, —Ä–∞–±–æ—Ç–∞—é —Ç–æ–ª—å–∫–æ —Å —Å–µ—Ä–≤–µ—Ä–∞–º–∏. –î–ª—è —Ä–∞–±–æ—Ç—ã —Å –∫–æ–¥–æ–º –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∞–≥–µ–Ω—Ç–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏."

=== –ù–ê–ß–ê–õ–û –ó–ê–î–ê–ß–ò ===

"""
                    current_prompt_base = isolation_system_prompt + current_prompt_base
                
                if servers_context:
                    current_prompt_base = servers_context + "\n\n" + current_prompt_base
                if retry_attempt > 0:
                    current_prompt_base = (
                        f"Previous attempt failed with error: {last_error}\n\n"
                        f"Please fix the issue and try again.\n\nOriginal task:\n{step_prompt}"
                    )
                    if servers_context:
                        current_prompt_base = servers_context + "\n\n" + current_prompt_base
                    run_obj.logs = (run_obj.logs or "") + f"\n[Retry {retry_attempt}/{max_retries} for {step_title}]\n"
                    run_obj.save(update_fields=["logs"])

                # Ralph-—Ü–∏–∫–ª: –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏—Ç–µ—Ä–∞—Ü–∏–π –∞–≥–µ–Ω—Ç–∞ –¥–æ completion promise (–±–µ–∑–æ—Ç–∫–∞–∑–Ω–æ–µ –Ω–∞–ø–∏—Å–∞–Ω–∏–µ –∫–æ–¥–∞)
                inner_max = 1 if not use_ralph_loop else max_iterations
                ralph_iteration = 0
                last_output = ""
                result = None
                while ralph_iteration < inner_max:
                    ralph_iteration += 1
                    if ralph_iteration == 1:
                        current_prompt = current_prompt_base
                    else:
                        current_prompt = (
                            "–ü—Ä–æ–¥–æ–ª–∂–∞–π —Ä–∞–±–æ—Ç—É –ø–æ –∑–∞–¥–∞—á–µ. –ü—Ä–æ–≤–µ—Ä—å –ø—Ä–µ–¥—ã–¥—É—â–∏–π –≤—ã–≤–æ–¥ –∏ –¥–æ–≤–µ–¥–∏ –¥–æ –∫–æ–Ω—Ü–∞.\n\n"
                            f"–ò–∑–Ω–∞—á–∞–ª—å–Ω–∞—è –∑–∞–¥–∞—á–∞:\n{current_prompt_base}\n\n"
                            f"–ü—Ä–µ–¥—ã–¥—É—â–∏–π –≤—ã–≤–æ–¥ –∞–≥–µ–Ω—Ç–∞:\n{last_output}\n\n"
                            f"–ï—Å–ª–∏ –∑–∞–¥–∞—á–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é –≤—ã–ø–æ–ª–Ω–µ–Ω–∞, –≤—ã–≤–µ–¥–∏ —Ä–æ–≤–Ω–æ: <promise>{completion_promise}</promise>"
                        )
                    if completion_promise and (ralph_iteration == 1 or "promise" not in current_prompt):
                        current_prompt = f"{current_prompt}\n\nWhen complete output exactly: <promise>{completion_promise}</promise>."
                    step_label = f"{step_title}" if inner_max <= 1 else f"{step_title} (Ralph {ralph_iteration}/{inner_max})"
                    cmd = _build_cli_command(runtime, current_prompt, config, workspace)
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–º–∞–Ω–¥—É –≤ meta –¥–ª—è –∞–¥–º–∏–Ω-–ø—Ä–æ—Å–º–æ—Ç—Ä–∞
                    run_meta = run_obj.meta or {}
                    run_meta[f"step_{idx}_cmd"] = _sanitize_command(cmd)
                    run_meta[f"step_{idx}_cmd_full"] = cmd
                    run_meta[f"step_{idx}_prompt"] = current_prompt[:8000]
                    run_meta[f"step_{idx}_workspace"] = workspace
                    run_meta[f"step_{idx}_runtime"] = runtime
                    run_obj.meta = run_meta
                    run_obj.save(update_fields=["meta"])
                    
                    # –î–ï–¢–ê–õ–¨–ù–û–ï –õ–û–ì–ò–†–û–í–ê–ù–ò–ï –ü–ï–†–ï–î –ó–ê–ü–£–°–ö–û–ú
                    logger.info(f"\n{'='*70}")
                    logger.info(f"üöÄ –ü–û–î–ì–û–¢–û–í–ö–ê –ö –ó–ê–ü–£–°–ö–£ –ê–ì–ï–ù–¢–ê")
                    logger.info(f"{'='*70}")
                    logger.info(f"üìå Step: {step_title}")
                    logger.info(f"üìå Label: {step_label}")
                    logger.info(f"üìå Runtime: {runtime}")
                    logger.info(f"üìå Model: {config.get('model', 'N/A')}")
                    logger.info(f"üìå Workspace: {workspace}")
                    logger.info(f"üìå Ralph iteration: {ralph_iteration}/{inner_max}")
                    logger.info(f"üìå Retry attempt: {retry_attempt}/{max_retries}")
                    
                    # –ü–†–û–í–ï–†–ö–ê –†–ê–ë–û–¢–û–°–ü–û–°–û–ë–ù–û–°–¢–ò CLI
                    if ralph_iteration == 1 and retry_attempt == 0:  # –¢–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π —Ä–∞–∑
                        try:
                            logger.info(f"\nüß™ –¢–ï–°–¢ –†–ê–ë–û–¢–û–°–ü–û–°–û–ë–ù–û–°–¢–ò CLI")
                            test_cmd_path = _resolve_cli_command(runtime)
                            logger.info(f"  CLI –ø—É—Ç—å: {test_cmd_path}")
                            
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
                            if not Path(test_cmd_path).exists():
                                logger.error(f"  ‚ùå CLI —Ñ–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç!")
                            else:
                                logger.info(f"  ‚úÖ CLI —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
                                
                                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ñ–∞–π–ª –∏—Å–ø–æ–ª–Ω—è–µ–º—ã–π
                                if os.access(test_cmd_path, os.X_OK):
                                    logger.info(f"  ‚úÖ CLI —Ñ–∞–π–ª –∏–º–µ–µ—Ç –ø—Ä–∞–≤–∞ –Ω–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ")
                                else:
                                    logger.warning(f"  ‚ö†Ô∏è CLI —Ñ–∞–π–ª –Ω–µ –∏–º–µ–µ—Ç –ø—Ä–∞–≤ –Ω–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ!")
                                
                                # –ü—Ä–æ–±—É–µ–º –∑–∞–ø—É—Å—Ç–∏—Ç—å —Å --version
                                try:
                                    logger.info(f"  –ü—Ä–æ–±—É–µ–º –∑–∞–ø—É—Å—Ç–∏—Ç—å: {test_cmd_path} --version")
                                    version_result = subprocess.run(
                                        [test_cmd_path, "--version"],
                                        capture_output=True,
                                        text=True,
                                        timeout=5
                                    )
                                    logger.info(f"  Exit code: {version_result.returncode}")
                                    if version_result.stdout:
                                        logger.info(f"  STDOUT: {version_result.stdout.strip()}")
                                    if version_result.stderr:
                                        logger.info(f"  STDERR: {version_result.stderr.strip()}")
                                except Exception as ve:
                                    logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ CLI: {ve}")
                        except Exception as test_e:
                            logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∞ CLI: {test_e}")
                    
                    logger.info(f"\nüîß –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø:")
                    for key, value in config.items():
                        if key == 'prompt':
                            logger.info(f"  {key}: <{len(str(value))} —Å–∏–º–≤–æ–ª–æ–≤>")
                        else:
                            logger.info(f"  {key}: {value}")
                    
                    logger.info(f"\nüí¨ –ü–†–û–ú–ü–¢ (–ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤):")
                    logger.info(f"{current_prompt[:500]}...")
                    
                    # –ê–ù–ê–õ–ò–ó –ü–†–û–ú–ü–¢–ê
                    logger.info(f"\nüîé –ê–ù–ê–õ–ò–ó –ü–†–û–ú–ü–¢–ê:")
                    logger.info(f"  –î–ª–∏–Ω–∞: {len(current_prompt)} —Å–∏–º–≤–æ–ª–æ–≤")
                    if "prod server" in current_prompt or "172.25.173.251" in current_prompt:
                        logger.info(f"  ‚úÖ –°–æ–¥–µ—Ä–∂–∏—Ç —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ 'prod server' –∏–ª–∏ IP 172.25.173.251")
                    else:
                        logger.warning(f"  ‚ö†Ô∏è –ù–ï —Å–æ–¥–µ—Ä–∂–∏—Ç —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ 'prod server' –∏–ª–∏ IP 172.25.173.251")
                    
                    if "server_execute" in current_prompt:
                        logger.info(f"  ‚úÖ –°–æ–¥–µ—Ä–∂–∏—Ç –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –æ–± –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ 'server_execute'")
                    else:
                        logger.warning(f"  ‚ö†Ô∏è –ù–ï —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –æ–± –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ 'server_execute'")
                    
                    if "–°–ï–†–í–ï–†–ù–ê–Ø –ó–ê–î–ê–ß–ê" in current_prompt or "SERVER TASK" in current_prompt:
                        logger.info(f"  ‚úÖ –°–æ–¥–µ—Ä–∂–∏—Ç –º–µ—Ç–∫—É —Å–µ—Ä–≤–µ—Ä–Ω–æ–π –∑–∞–¥–∞—á–∏")
                    else:
                        logger.warning(f"  ‚ö†Ô∏è –ù–ï —Å–æ–¥–µ—Ä–∂–∏—Ç –º–µ—Ç–∫—É —Å–µ—Ä–≤–µ—Ä–Ω–æ–π –∑–∞–¥–∞—á–∏")
                    
                    logger.info(f"\nüéØ –ü–û–õ–ù–ê–Ø –ö–û–ú–ê–ù–î–ê CLI ({len(cmd)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤):")
                    cmd_full = " ".join(cmd)
                    logger.info(f"{cmd_full}")
                    
                    if extra_env:
                        logger.info(f"\nüåç –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï ENV –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ:")
                        for k, v in extra_env.items():
                            logger.info(f"  {k}: {v}")
                    
                    logger.info(f"{'='*70}\n")
                    
                    # –°—Ç–∞—Ä—ã–π –ª–æ–≥ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                    cmd_preview = " ".join(cmd[:5]) + "..." if len(cmd) > 5 else " ".join(cmd)
                    logger.info(f"Executing CLI: {cmd_preview} (runtime={runtime}, model={config.get('model', 'N/A')})")
                    
                    result = _run_cli_stream(cmd, run_obj, step_label=step_label, extra_env=extra_env)
                    last_output = result.get("output", "") or ""
                    
                    # –î–ï–¢–ê–õ–¨–ù–û–ï –õ–û–ì–ò–†–û–í–ê–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–ê
                    logger.info(f"\n{'='*70}")
                    logger.info(f"üìä –†–ï–ó–£–õ–¨–¢–ê–¢ –í–´–ü–û–õ–ù–ï–ù–ò–Ø –ê–ì–ï–ù–¢–ê")
                    logger.info(f"{'='*70}")
                    logger.info(f"‚úÖ Success: {result.get('success', False)}")
                    logger.info(f"üî¢ Exit Code: {result.get('exit_code', 'unknown')}")
                    logger.info(f"üìè Output Length: {len(last_output)} —Å–∏–º–≤–æ–ª–æ–≤")
                    
                    if last_output:
                        logger.info(f"\nüìù –í–´–í–û–î (–ø–µ—Ä–≤—ã–µ 1000 —Å–∏–º–≤–æ–ª–æ–≤):")
                        logger.info(f"{last_output[:1000]}")
                        if len(last_output) > 1000:
                            logger.info(f"... –∏ –µ—â–µ {len(last_output) - 1000} —Å–∏–º–≤–æ–ª–æ–≤")
                        
                        logger.info(f"\nüìù –í–´–í–û–î (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 500 —Å–∏–º–≤–æ–ª–æ–≤):")
                        logger.info(f"{last_output[-500:]}")
                    else:
                        logger.warning(f"‚ö†Ô∏è –í–´–í–û–î –ü–£–°–¢–û–ô!")
                    
                    logger.info(f"{'='*70}\n")
                    
                    if not result.get("success"):
                        logger.error(f"\n{'‚ùå'*35}")
                        logger.error(f"–û–®–ò–ë–ö–ê –í–´–ü–û–õ–ù–ï–ù–ò–Ø!")
                        logger.error(f"{'‚ùå'*35}")
                        
                        last_error = last_output or f"exit code {result.get('exit_code', -1)}"
                        
                        logger.error(f"üîç –ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–∫–∏:")
                        logger.error(f"  Exit code: {result.get('exit_code', -1)}")
                        logger.error(f"  –î–ª–∏–Ω–∞ –≤—ã–≤–æ–¥–∞: {len(last_output)} —Å–∏–º–≤–æ–ª–æ–≤")
                        
                        if "Connection stalled" in last_error or "connection stalled" in last_error.lower():
                            logger.error(f"  –¢–∏–ø –æ—à–∏–±–∫–∏: Connection stalled")
                            last_error = "Cursor API connection stalled. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–µ—Ç—å –∏ –ø–æ–¥–ø–∏—Å–∫—É Cursor; –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ —à–∞–≥."
                        elif result.get('exit_code') == -9:
                            logger.error(f"  –¢–∏–ø –æ—à–∏–±–∫–∏: –ü—Ä–æ—Ü–µ—Å—Å —É–±–∏—Ç (SIGKILL) - –≤–æ–∑–º–æ–∂–Ω–æ –Ω–µ—Ö–≤–∞—Ç–∫–∞ –ø–∞–º—è—Ç–∏")
                        elif result.get('exit_code') == 127:
                            logger.error(f"  –¢–∏–ø –æ—à–∏–±–∫–∏: –ö–æ–º–∞–Ω–¥–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                        elif not last_output:
                            logger.error(f"  –¢–∏–ø –æ—à–∏–±–∫–∏: –ü—É—Å—Ç–æ–π –≤—ã–≤–æ–¥ - –ø—Ä–æ—Ü–µ—Å—Å –∑–∞–≤–µ—Ä—à–∏–ª—Å—è –±–µ–∑ –≤—ã–≤–æ–¥–∞")
                        else:
                            logger.error(f"  –¢–∏–ø –æ—à–∏–±–∫–∏: –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞")
                            last_error = last_error[:500] if len(last_error) > 500 else last_error
                        
                        logger.error(f"\n  –¢–µ–∫—Å—Ç –æ—à–∏–±–∫–∏: {last_error}")
                        logger.error(f"{'‚ùå'*35}\n")
                        break
                    if completion_promise and _promise_found(last_output, completion_promise):
                        break
                if inner_max <= 1:
                    pass
                elif not result or not result.get("success"):
                    pass
                elif completion_promise and not _promise_found(last_output, completion_promise):
                    last_error = f"Ralph: promise <{completion_promise}> –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ—Å–ª–µ {inner_max} –∏—Ç–µ—Ä–∞—Ü–∏–π. –ü–æ–≤—Ç–æ—Ä–∏—Ç–µ —à–∞–≥ –∏–ª–∏ —É–≤–µ–ª–∏—á—å—Ç–µ max_iterations –≤ —à–∞–≥–µ."
                    retry_attempt += 1
                    run_obj.logs = (run_obj.logs or "") + f"\n[Step]: {last_error}\n"
                    run_obj.save(update_fields=["logs"])
                    continue

                if result and not result.get("success"):
                    retry_attempt += 1
                    run_obj.logs = (run_obj.logs or "") + f"\n[Step failed]: {last_error}\n"
                    run_obj.save(update_fields=["logs"])
                    continue
                if verify_prompt:
                    verify_text = f"{verify_prompt}\n\nWhen verified output exactly: <promise>{verify_promise}</promise>." if verify_promise else verify_prompt
                    verify_cmd = _build_cli_command(runtime, verify_text, {**config, "completion_promise": verify_promise}, workspace)
                    verify_result = _run_cli_stream(verify_cmd, run_obj, step_label=f"{step_title} - verify", extra_env=extra_env)
                    if verify_promise and not _promise_found(verify_result.get("output", ""), verify_promise):
                        last_error = f"Verification failed: expected {verify_promise}"
                        retry_attempt += 1
                        continue
                step_success = True
                sr = {"step_idx": idx, "step": step_title, "status": "completed", "retries": retry_attempt, "result": result, "ralph_iterations": ralph_iteration if inner_max > 1 else None}
                step_results.append(sr)
                step_results_existing.append(sr)
                run_obj.step_results = step_results_existing
                run_obj.save(update_fields=["step_results"])
                _append_log_event(
                    run_obj,
                    {
                        "type": "step",
                        "subtype": "completed",
                        "title": step_title,
                        "step_idx": idx,
                        "retries": retry_attempt,
                        "status": "completed",
                    },
                )
                run_obj.save(update_fields=["log_events", "meta"])
            except Exception as e:
                last_error = str(e)
                retry_attempt += 1
                run_obj.logs = (run_obj.logs or "") + f"\n[Error in {step_title}]: {last_error}\n"
                run_obj.save(update_fields=["logs"])
        if not step_success:
            sr = {"step_idx": idx, "step": step_title, "status": "failed", "retries": retry_attempt, "error": last_error}
            step_results_existing.append(sr)
            run_obj.step_results = step_results_existing
            run_obj.save(update_fields=["step_results"])
            _append_log_event(
                run_obj,
                {
                    "type": "step",
                    "subtype": "failed",
                    "title": step_title,
                    "step_idx": idx,
                    "retries": retry_attempt,
                    "status": "failed",
                    "error": last_error,
                },
            )
            run_obj.save(update_fields=["log_events", "meta"])
            raise RuntimeError(f"Step {idx} ({step_title}) failed after {max_retries} retries: {last_error}")


def _start_workflow_run(workflow: AgentWorkflow, user) -> AgentWorkflowRun:
    run = AgentWorkflowRun.objects.create(
        workflow=workflow,
        initiated_by=user,
        status="queued",
        current_step=0,
    )
    thread = threading.Thread(target=_execute_workflow_run, args=(run.id,), daemon=True)
    thread.start()
    return run


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["GET"])
def api_workflow_run_status(request, run_id: int):
    run = get_object_or_404(
        AgentWorkflowRun.objects.select_related("workflow"),
        id=run_id,
        initiated_by=request.user,
    )
    after_id = request.GET.get("after_id")
    events = list(run.log_events or [])
    if after_id:
        try:
            after_id_int = int(after_id)
            events = [e for e in events if int(e.get("id", 0)) > after_id_int]
        except ValueError:
            events = events[-200:]
    else:
        events = events[-200:]
    last_event_id = events[-1]["id"] if events else (run.log_events or [])[-1]["id"] if run.log_events else 0
    script = run.workflow.script or {}
    steps = script.get("steps", [])
    total_steps = len(steps)
    current_step_title = ""
    if steps and 0 < run.current_step <= total_steps:
        step = steps[run.current_step - 1]
        current_step_title = step.get("title") or step.get("prompt", "")[:50]
    step_results_map = {r.get("step_idx"): r for r in (run.step_results or [])}
    steps_info = []
    for idx, step in enumerate(steps, start=1):
        info = {
            "idx": idx,
            "title": step.get("title") or f"–®–∞–≥ {idx}",
            "prompt": (step.get("prompt") or "")[:200],
            "has_verify": bool(step.get("verify_prompt")),
            "status": "pending",
        }
        if idx in step_results_map:
            r = step_results_map[idx]
            info["status"] = r.get("status", "unknown")
            info["retries"] = r.get("retries", 0)
            info["error"] = r.get("error")
        elif idx == run.current_step and run.status == "running":
            info["status"] = "running"
            info["retries"] = getattr(run, "retry_count", 0)
        steps_info.append(info)
    return JsonResponse(
        {
            "status": run.status,
            "current_step": run.current_step,
            "total_steps": total_steps,
            "current_step_title": current_step_title,
            "retry_count": getattr(run, "retry_count", 0),
            "max_retries": getattr(run, "max_retries", 3),
            "steps": steps_info,
            "logs": (run.logs or "")[-8000:] if run.logs else "",
            "finished_at": run.finished_at.isoformat() if run.finished_at else None,
            "events": events,
            "last_event_id": last_event_id,
        }
    )


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["POST"])
def api_workflow_stop(request, run_id: int):
    run = get_object_or_404(AgentWorkflowRun, id=run_id, initiated_by=request.user)
    meta = run.meta or {}
    for key, value in list(meta.items()):
        if str(key).startswith("pid_"):
            try:
                if os.name == "nt":
                    subprocess.Popen(["taskkill", "/PID", str(value), "/F"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
                else:
                    os.kill(int(value), 9)
            except Exception:
                pass
    run.status = "failed"
    run.logs = (run.logs or "") + "\n[Stopped by user]\n"
    run.finished_at = timezone.now()
    run.save(update_fields=["status", "logs", "finished_at"])
    return JsonResponse({"success": True})


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["POST"])
def api_workflow_restart(request, run_id: int):
    old_run = get_object_or_404(AgentWorkflowRun, id=run_id, initiated_by=request.user)
    workflow = old_run.workflow
    new_run = _start_workflow_run(workflow, request.user)
    return JsonResponse({"success": True, "run_id": new_run.id})


def _continue_workflow_run(run_id: int, from_step: int):
    run_obj = AgentWorkflowRun.objects.get(pk=run_id)
    workflow = run_obj.workflow
    run_obj.status = "running"
    if not run_obj.started_at:
        run_obj.started_at = timezone.now()
    workspace = _get_workspace_path(workflow)
    user_id = run_obj.initiated_by_id
    target_server_id = workflow.target_server_id
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∑–∞–¥–∞—á–∏ –¥–ª—è –∏–∑–æ–ª—è—Ü–∏–∏
    is_server_task = target_server_id is not None
    
    # –ö–æ–Ω—Ç–µ–∫—Å—Ç —Å–µ—Ä–≤–µ—Ä–æ–≤: –¢–û–õ–¨–ö–û –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω target_server
    servers_context = ""
    if target_server_id and user_id:
        servers_context = _get_user_servers_context(user_id, target_server_id)
    
    run_obj.save(update_fields=["status", "started_at"])
    steps = (workflow.script or {}).get("steps", [])
    step_results = []
    try:
        if workflow.runtime == "ralph":
            backend = (
                ((workflow.script or {}).get("ralph_yml") or {}).get("cli", {}).get("backend")
                or (workflow.script or {}).get("backend")
                or "cursor"
            )
            _run_steps_with_backend(
                run_obj=run_obj, steps=steps, runtime=backend, workflow=workflow,
                step_results=step_results, workspace=workspace, start_from_step=from_step,
                servers_context=servers_context, is_server_task=is_server_task,
            )
        else:
            _run_steps_with_backend(
                run_obj=run_obj, steps=steps, runtime=workflow.runtime, workflow=workflow,
                step_results=step_results, workspace=workspace, start_from_step=from_step,
                servers_context=servers_context, is_server_task=is_server_task,
            )
        run_obj.status = "succeeded"
        run_obj.output_text = json.dumps(step_results, ensure_ascii=False)
    except Exception as exc:
        run_obj.status = "failed"
        run_obj.logs = (run_obj.logs or "") + f"\n{exc}\n"
        run_obj.output_text = json.dumps(step_results, ensure_ascii=False)
    finally:
        run_obj.finished_at = timezone.now()
        run_obj.save()


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["POST"])
def api_workflow_skip_step(request, run_id: int):
    run = get_object_or_404(AgentWorkflowRun, id=run_id, initiated_by=request.user)
    if run.status not in ("failed", "paused"):
        return JsonResponse({"error": "Can only skip steps for failed/paused workflows"}, status=400)
    current_step = run.current_step
    steps = (run.workflow.script or {}).get("steps", [])
    if current_step >= len(steps):
        return JsonResponse({"error": "No more steps to skip"}, status=400)
    step_results = run.step_results or []
    step_title = steps[current_step - 1].get("title", f"–®–∞–≥ {current_step}")
    step_results.append({"step_idx": current_step, "step": step_title, "status": "skipped", "retries": 0})
    run.step_results = step_results
    run.logs = (run.logs or "") + f"\n[–®–∞–≥ {current_step} ({step_title}) –ø—Ä–æ–ø—É—â–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º]\n"
    run.save(update_fields=["step_results", "logs"])
    next_step = current_step + 1
    if next_step > len(steps):
        run.status = "succeeded"
        run.finished_at = timezone.now()
        run.save(update_fields=["status", "finished_at"])
        return JsonResponse({"success": True, "message": "Workflow completed (last step skipped)"})
    run.status = "queued"
    run.save(update_fields=["status"])
    thread = threading.Thread(target=_continue_workflow_run, args=(run.id, next_step), daemon=True)
    thread.start()
    return JsonResponse({"success": True, "message": f"Step {current_step} skipped, continuing from step {next_step}"})


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["POST"])
def api_workflow_skip_specific_step(request, run_id: int):
    """–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —à–∞–≥ –ø–æ –∏–Ω–¥–µ–∫—Å—É"""
    run = get_object_or_404(AgentWorkflowRun, id=run_id, initiated_by=request.user)
    data = _parse_json_request(request)
    if run.status not in ("failed", "paused"):
        return JsonResponse({"error": "Can only skip steps for failed/paused workflows"}, status=400)
    step_idx = data.get("step_idx")
    if not step_idx:
        return JsonResponse({"error": "step_idx is required"}, status=400)
    steps = (run.workflow.script or {}).get("steps", [])
    if step_idx < 1 or step_idx > len(steps):
        return JsonResponse({"error": f"Invalid step index: {step_idx}"}, status=400)
    step_results = run.step_results or []
    step_results = [r for r in step_results if r.get("step_idx") != step_idx]
    step_title = steps[step_idx - 1].get("title", f"–®–∞–≥ {step_idx}")
    step_results.append({"step_idx": step_idx, "step": step_title, "status": "skipped", "retries": 0})
    run.step_results = step_results
    run.logs = (run.logs or "") + f"\n[–®–∞–≥ {step_idx} ({step_title}) –ø—Ä–æ–ø—É—â–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º]\n"
    completed_or_skipped = {r.get("step_idx") for r in step_results if r.get("status") in ("completed", "skipped")}
    next_step = None
    for i in range(1, len(steps) + 1):
        if i not in completed_or_skipped:
            next_step = i
            break
    if next_step is None:
        run.status = "succeeded"
        run.finished_at = timezone.now()
        run.save(update_fields=["step_results", "logs", "status", "finished_at"])
        return JsonResponse({"success": True, "message": "Workflow completed (all steps done or skipped)"})
    run.status = "queued"
    run.save(update_fields=["step_results", "logs", "status"])
    thread = threading.Thread(target=_continue_workflow_run, args=(run.id, next_step), daemon=True)
    thread.start()
    return JsonResponse({"success": True, "message": f"Step {step_idx} skipped, continuing from step {next_step}"})


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["POST"])
def api_workflow_continue(request, run_id: int):
    run = get_object_or_404(AgentWorkflowRun, id=run_id, initiated_by=request.user)
    data = _parse_json_request(request)
    if run.status not in ("failed", "paused"):
        return JsonResponse({"error": "Can only continue failed/paused workflows"}, status=400)
    from_step = data.get("from_step", run.current_step)
    steps = (run.workflow.script or {}).get("steps", [])
    if from_step < 1 or from_step > len(steps):
        return JsonResponse({"error": f"Invalid step number: {from_step}"}, status=400)
    run.status = "queued"
    run.logs = (run.logs or "") + f"\n[–ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å —à–∞–≥–∞ {from_step}]\n"
    run.save(update_fields=["status", "logs"])
    thread = threading.Thread(target=_continue_workflow_run, args=(run.id, from_step), daemon=True)
    thread.start()
    return JsonResponse({"success": True, "message": f"Continuing from step {from_step}"})


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["POST"])
def api_workflow_retry_step(request, run_id: int):
    run = get_object_or_404(AgentWorkflowRun, id=run_id, initiated_by=request.user)
    if run.status not in ("failed", "paused"):
        return JsonResponse({"error": "Can only retry failed/paused workflows"}, status=400)
    current_step = run.current_step
    step_results = run.step_results or []
    step_results = [r for r in step_results if r.get("step_idx") != current_step]
    run.step_results = step_results
    run.retry_count = 0
    run.status = "queued"
    run.logs = (run.logs or "") + f"\n[–ü–æ–≤—Ç–æ—Ä —à–∞–≥–∞ {current_step}]\n"
    run.save(update_fields=["step_results", "retry_count", "status", "logs"])
    thread = threading.Thread(target=_continue_workflow_run, args=(run.id, current_step), daemon=True)
    thread.start()
    return JsonResponse({"success": True, "message": f"Retrying step {current_step}"})


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["POST"])
def api_assist_config(request):
    data = _parse_json_request(request)
    task = data.get("task", "").strip()
    if not task:
        return JsonResponse({"error": "Task is required"}, status=400)

    parsed = _generate_profile_config(task)
    return JsonResponse(
        {
            "success": True,
            "config": parsed,
            "questions": parsed.get("questions") or [],
            "assumptions": parsed.get("assumptions") or [],
        }
    )


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["POST"])
def api_assist_auto(request):
    data = _parse_json_request(request)
    task = data.get("task", "").strip()
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º default_provider –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –≤–º–µ—Å—Ç–æ "ralph"
    from app.core.model_config import model_manager
    default_runtime = model_manager.config.default_provider or "cursor"
    runtime = data.get("runtime", default_runtime)
    
    action = data.get("action", "both")
    run_workflow = bool(data.get("run_workflow", True))
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞
    project_path = data.get("project_path", "").strip()
    create_new_project = data.get("create_new_project", False)
    new_project_name = data.get("new_project_name", "").strip()

    if not task:
        return JsonResponse({"error": "Task is required"}, status=400)
    if runtime not in ALLOWED_RUNTIMES:
        runtime = default_runtime

    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –ø–∞–ø–∫—É –ø—Ä–æ–µ–∫—Ç–∞ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if create_new_project:
        if new_project_name:
            project_path = _create_project_folder(new_project_name)
        else:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–º—è –∏–∑ –∑–∞–¥–∞—á–∏
            import re
            safe_name = re.sub(r'[^\w\-_. ]', '', task[:50]).strip().replace(' ', '_')
            if not safe_name:
                safe_name = f"project_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            project_path = _create_project_folder(safe_name)
    elif not project_path:
        try:
            from app.core.model_config import model_manager
            project_path = (getattr(model_manager.config, "default_agent_output_path", None) or "").strip()
        except Exception:
            pass

    # DEPRECATED: –ë–æ–ª—å—à–µ –Ω–µ —Å–æ–∑–¥–∞—ë–º AgentProfile –∏–∑ –≤–æ—Ä–∫—Ñ–ª–æ—É
    # –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ CustomAgent –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤
    profile_id = None
    workflow_id = None
    run_id = None

    # if action in ["profile", "both"]:
    #     cfg = _generate_profile_config(task)
    #     profile = AgentProfile.objects.create(
    #         owner=request.user,
    #         name=cfg.get("name", "AI Profile"),
    #         description=cfg.get("description", ""),
    #         agent_type=cfg.get("agent_type", "react"),
    #         runtime=cfg.get("runtime", default_runtime),
    #         mode=cfg.get("mode", "simple"),
    #         config=cfg.get("config", {}),
    #     )
    #     profile_id = profile.id

    # –í—Å–µ–≥–¥–∞ —Å–æ–∑–¥–∞—ë–º —Ç–æ–ª—å–∫–æ workflow (–∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º action "profile")
    script = _generate_workflow_script(task, runtime)
    if not script:
        return JsonResponse({"error": "Failed to generate workflow"}, status=500)

    workflow = AgentWorkflow.objects.create(
        owner=request.user,
        name=script.get("name", "New Workflow"),
        description=script.get("description", ""),
        runtime=script.get("runtime", runtime),
        script=script,
        project_path=project_path,
    )

    workflows_dir = Path(settings.MEDIA_ROOT) / "workflows"
    workflows_dir.mkdir(parents=True, exist_ok=True)
    file_path = workflows_dir / f"workflow-{workflow.id}.json"
    script["script_file"] = str(file_path)
    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(script, f, ensure_ascii=False, indent=2)

    if script.get("ralph_yml"):
        ralph_path = workflows_dir / f"workflow-{workflow.id}.ralph.yml"
        script["ralph_yml_path"] = str(ralph_path)
        _write_ralph_yml(ralph_path, script["ralph_yml"])

    workflow.script = script
    workflow.save(update_fields=["script"])
    workflow_id = workflow.id

    if run_workflow:
        run = _start_workflow_run(workflow, request.user)
        run_id = run.id

    return JsonResponse(
        {"success": True, "profile_id": None, "workflow_id": workflow_id, "run_id": run_id}
    )


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["GET"])
def api_mcp_servers(request):
    tool_manager = get_tool_manager()
    tool_manager.refresh_mcp_config()
    servers = list(tool_manager.get_mcp_servers().values())
    return JsonResponse({"servers": servers, "sources": tool_manager.mcp_config_sources})


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["POST"])
def api_mcp_server_connect(request):
    data = _parse_json_request(request)
    name = (data.get("name") or "").strip()
    if not name:
        return JsonResponse({"error": "name is required"}, status=400)
    tool_manager = get_tool_manager()
    try:
        status = async_to_sync(tool_manager.connect_mcp_server)(name)
        return JsonResponse({"success": True, "status": status})
    except Exception as exc:
        return JsonResponse({"error": str(exc)}, status=500)


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["POST"])
def api_mcp_server_disconnect(request):
    data = _parse_json_request(request)
    name = (data.get("name") or "").strip()
    if not name:
        return JsonResponse({"error": "name is required"}, status=400)
    tool_manager = get_tool_manager()
    ok = async_to_sync(tool_manager.disconnect_mcp_server)(name)
    return JsonResponse({"success": bool(ok)})


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["GET"])
def api_mcp_server_tools(request):
    name = (request.GET.get("name") or "").strip()
    if not name:
        return JsonResponse({"error": "name is required"}, status=400)
    tool_manager = get_tool_manager()
    tools = tool_manager.get_mcp_tools(name)
    return JsonResponse({"tools": tools})


# –ö—ç—à –¥–ª—è —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π (TTL 5 –º–∏–Ω—É—Ç)
_models_cache = {"data": None, "timestamp": 0}
_MODELS_CACHE_TTL = 300  # 5 –º–∏–Ω—É—Ç


def _get_cursor_models_from_cli() -> list:
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –∏–∑ agent --list-models."""
    import time
    now = time.time()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
    if _models_cache["data"] and (now - _models_cache["timestamp"]) < _MODELS_CACHE_TTL:
        return _models_cache["data"]
    
    try:
        cmd_path = _resolve_cli_command("cursor")
        env = dict(os.environ)
        env.update(getattr(settings, "CURSOR_CLI_EXTRA_ENV", None) or {})
        
        proc = subprocess.run(
            [cmd_path, "--list-models"],
            capture_output=True,
            text=True,
            encoding="utf-8",
            errors="replace",
            env=env,
            timeout=30,
        )
        
        if proc.returncode == 0 and proc.stdout:
            # –ü–∞—Ä—Å–∏–º –≤—ã–≤–æ–¥ CLI - –æ–∂–∏–¥–∞–µ–º —Ñ–æ—Ä–º–∞—Ç: model_id\nmodel_id2\n...
            lines = [line.strip() for line in proc.stdout.strip().split("\n") if line.strip()]
            models = []
            for line in lines:
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
                if not line or line.startswith("#") or line.startswith("Available"):
                    continue
                model_id = line.split()[0] if line.split() else line
                if model_id:
                    models.append({
                        "id": model_id,
                        "name": model_id.replace("-", " ").title(),
                        "description": f"–ú–æ–¥–µ–ª—å {model_id}",
                        "from_cli": True,
                    })
            
            if models:
                _models_cache["data"] = models
                _models_cache["timestamp"] = now
                return models
    except subprocess.TimeoutExpired:
        logger.warning("Cursor --list-models timeout")
    except Exception as e:
        logger.warning(f"Error getting models from CLI: {e}")
    
    # Fallback –Ω–∞ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫
    return list(getattr(settings, "CURSOR_AVAILABLE_MODELS", []))


@login_required
@require_feature('agents')
@require_http_methods(["GET"])
def api_list_models(request):
    """
    –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π Cursor CLI.
    –ö—ç—à–∏—Ä—É–µ—Ç—Å—è –Ω–∞ 5 –º–∏–Ω—É—Ç, fallback –Ω–∞ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫.
    """
    models = _get_cursor_models_from_cli()
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
    recommendations = getattr(settings, "MODEL_RECOMMENDATIONS", {})
    
    return JsonResponse({
        "models": models,
        "recommendations": recommendations,
        "default": "auto",
    })


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["POST"])
def api_smart_analyze(request):
    """
    –£–º–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–¥–∞—á–∏ —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–µ–π –º–æ–¥–µ–ª–∏ –∏ –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏–µ–π.
    
    Request:
    {
        "task": "–û–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏",
        "context": {  // –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
            "project_type": "django",
            "existing_files": ["models.py", "views.py"]
        },
        "use_llm": true  // –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å LLM –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é true)
    }
    
    Response:
    {
        "questions": ["–ù–∞–≤–æ–¥—è—â–∏–π –≤–æ–ø—Ä–æ—Å 1", ...],
        "recommended_model": "sonnet-4",
        "complexity": "standard",
        "task_type": "new_feature",
        "subtasks": [
            {
                "title": "–ù–∞–∑–≤–∞–Ω–∏–µ –ø–æ–¥–∑–∞–¥–∞—á–∏",
                "prompt": "–î–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ",
                "recommended_model": "sonnet-4",
                "reasoning": "–ü–æ—á–µ–º—É —ç—Ç–∞ –º–æ–¥–µ–ª—å",
                "complexity": "standard",
                "completion_promise": "STEP_DONE",
                "max_iterations": 5,
                "verify_prompt": "...",
                "verify_promise": "PASS"
            }
        ],
        "estimated_steps": 4,
        "warnings": [],
        "reasoning": "–û–±—â–µ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ"
    }
    """
    from .smart_analyzer import get_smart_analyzer
    
    data = _parse_json_request(request)
    task = data.get("task", "").strip()
    
    if not task:
        return JsonResponse({"error": "Task is required"}, status=400)
    
    context = data.get("context")
    use_llm = data.get("use_llm", True)
    
    try:
        analyzer = get_smart_analyzer()
        result = analyzer.analyze(task, context=context, use_llm=use_llm)
        return JsonResponse(result.to_dict())
    except Exception as e:
        logger.error(f"Smart analyze failed: {e}")
        return JsonResponse({
            "error": str(e),
            "questions": [],
            "recommended_model": "auto",
            "complexity": "standard",
            "subtasks": [],
            "warnings": [f"–ê–Ω–∞–ª–∏–∑ –Ω–µ —É–¥–∞–ª—Å—è: {str(e)[:100]}"],
        }, status=500)


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["POST"])
def api_tasks_generate(request):
    """AI –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–¥–∞—á –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é –ø—Ä–æ–µ–∫—Ç–∞"""
    data = _parse_json_request(request)
    description = data.get("description", "").strip()
    
    if not description:
        return JsonResponse({"error": "Description is required"}, status=400)
    
    llm = LLMProvider()
    from app.core.model_config import model_manager
    model_preference = model_manager.config.default_provider
    
    prompt = f"""You generate task lists for AI agents.
Return ONLY JSON array of tasks:
[
  {{
    "title": "Short task title",
    "prompt": "Detailed description of what the agent should do",
    "completion_promise": "STEP_DONE",
    "verify_prompt": "How to verify the task is complete (optional, can be null)",
    "verify_promise": "PASS",
    "max_iterations": 5
  }}
]

Rules:
- Each task should be specific and actionable
- Tasks should be in logical order
- Include verify_prompt for tasks that need testing
- Keep prompts clear and detailed
- Return 3-8 tasks typically
- If requirements are unclear, include an early task "Clarify requirements" with questions to ask.

Project description:
{description}
"""
    
    async def _consume():
        chunks = []
        async for chunk in llm.stream_chat(prompt, model=model_preference):
            chunks.append(chunk)
        return "".join(chunks)
    
    response_text = async_to_sync(_consume)()
    
    # Parse JSON from response
    import re
    try:
        tasks = json.loads(response_text)
    except json.JSONDecodeError:
        match = re.search(r"\[.*\]", response_text, re.DOTALL)
        if match:
            try:
                tasks = json.loads(match.group())
            except json.JSONDecodeError:
                return JsonResponse({"error": "Failed to parse AI response"}, status=500)
        else:
            return JsonResponse({"error": "Failed to parse AI response"}, status=500)
    
    if not isinstance(tasks, list):
        return JsonResponse({"error": "Invalid AI response format"}, status=500)
    
    return JsonResponse({"success": True, "tasks": tasks})


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["POST"])
def api_workflow_create_manual(request):
    """–†—É—á–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ workflow –∏–∑ —Å–ø–∏—Å–∫–∞ –∑–∞–¥–∞—á"""
    data = _parse_json_request(request)
    name = data.get("name", "").strip() or "New Workflow"
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º default_provider –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫
    from app.core.model_config import model_manager
    default_runtime = model_manager.config.default_provider or "cursor"
    runtime = data.get("runtime", default_runtime)
    
    steps = data.get("steps", [])
    run_after_save = data.get("run_after_save", False)
    target_server_id = data.get("target_server_id")
    workflow_model = data.get("model", "auto")  # –ú–æ–¥–µ–ª—å workflow-level
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞
    project_path = data.get("project_path", "").strip()
    create_new_project = data.get("create_new_project", False)
    new_project_name = data.get("new_project_name", "").strip()
    
    if not steps:
        return JsonResponse({"error": "At least one step is required"}, status=400)
    
    if runtime not in ALLOWED_RUNTIMES:
        runtime = default_runtime
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
    valid_models = [m["id"] for m in getattr(settings, "CURSOR_AVAILABLE_MODELS", [])]
    if workflow_model and workflow_model not in valid_models:
        workflow_model = "auto"
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –ø—Ä–æ–µ–∫—Ç–∞ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if create_new_project:
        if new_project_name:
            project_path = _create_project_folder(new_project_name)
        else:
            import re
            safe_name = re.sub(r'[^\w\-_. ]', '', name[:50]).strip().replace(' ', '_')
            if not safe_name:
                safe_name = f"project_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            project_path = _create_project_folder(safe_name)
    elif not project_path:
        try:
            from app.core.model_config import model_manager
            project_path = (getattr(model_manager.config, "default_agent_output_path", None) or "").strip()
        except Exception:
            pass
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º script
    script = {
        "name": name,
        "runtime": runtime,
        "model": workflow_model,  # –ú–æ–¥–µ–ª—å workflow-level
        "steps": []
    }
    
    for step in steps:
        step_data = {
            "title": step.get("title", ""),
            "prompt": step.get("prompt", ""),
            "completion_promise": step.get("completion_promise", "STEP_DONE"),
            "max_iterations": step.get("max_iterations", 5),
        }
        # Step-level –º–æ–¥–µ–ª—å (–µ—Å–ª–∏ —Ä–∞–∑—Ä–µ—à–µ–Ω–æ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö –∏ –ø–µ—Ä–µ–¥–∞–Ω–∞)
        if step.get("model") and step["model"] != "auto":
            step_model = step["model"]
            if step_model in valid_models:
                step_data["model"] = step_model
        if step.get("verify_prompt"):
            step_data["verify_prompt"] = step["verify_prompt"]
            step_data["verify_promise"] = step.get("verify_promise", "PASS")
        script["steps"].append(step_data)
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º ralph_yml –µ—Å–ª–∏ runtime == ralph
    if runtime == "ralph":
        completion = "LOOP_COMPLETE"
        max_iter = 50
        backend = "cursor"
        hats = {}
        previous_event = "task.start"
        
        for idx, step in enumerate(script["steps"], start=1):
            hat_name = f"step_{idx}"
            next_event = f"step_{idx}.done"
            hats[hat_name] = {
                "name": f"Step {idx}",
                "description": step.get("title", f"Step {idx}"),
                "triggers": [previous_event],
                "publishes": [next_event],
                "instructions": step.get("prompt", ""),
            }
            previous_event = next_event
        
        script["ralph_yml"] = {
            "cli": {"backend": backend},
            "event_loop": {
                "completion_promise": completion,
                "max_iterations": max_iter,
                "starting_event": "task.start",
            },
            "hats": hats,
        }
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –ø–æ–ª—É—á–∞–µ–º —Ü–µ–ª–µ–≤–æ–π —Å–µ—Ä–≤–µ—Ä
    target_server = None
    if target_server_id:
        from servers.models import Server
        target_server = Server.objects.filter(id=target_server_id, user=request.user).first()
    
    # –°–æ–∑–¥–∞–µ–º workflow
    workflow = AgentWorkflow.objects.create(
        owner=request.user,
        name=name,
        description=f"Created manually with {len(steps)} steps",
        runtime=runtime,
        script=script,
        project_path=project_path,
        target_server=target_server,
    )
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª—ã
    workflows_dir = Path(settings.MEDIA_ROOT) / "workflows"
    workflows_dir.mkdir(parents=True, exist_ok=True)
    file_path = workflows_dir / f"workflow-{workflow.id}.json"
    script["script_file"] = str(file_path)
    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(script, f, ensure_ascii=False, indent=2)
    
    if script.get("ralph_yml"):
        ralph_path = workflows_dir / f"workflow-{workflow.id}.ralph.yml"
        script["ralph_yml_path"] = str(ralph_path)
        _write_ralph_yml(ralph_path, script["ralph_yml"])
    
    workflow.script = script
    workflow.save(update_fields=["script"])
    
    run_id = None
    if run_after_save:
        run = _start_workflow_run(workflow, request.user)
        run_id = run.id
    
    return JsonResponse({
        "success": True,
        "workflow_id": workflow.id,
        "run_id": run_id,
        "project_path": project_path,
    })


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["POST"])
def api_workflow_import(request):
    """–ò–º–ø–æ—Ä—Ç workflow –∏–∑ JSON —Ñ–∞–π–ª–∞"""
    if "file" not in request.FILES:
        return JsonResponse({"success": False, "error": "No file uploaded"}, status=400)
    uploaded_file = request.FILES["file"]
    if not uploaded_file.name.endswith(".json"):
        return JsonResponse({"success": False, "error": "Only JSON files are supported"}, status=400)
    try:
        content = uploaded_file.read().decode("utf-8")
        script = json.loads(content)
    except (json.JSONDecodeError, UnicodeDecodeError) as e:
        return JsonResponse({"success": False, "error": f"Invalid JSON: {str(e)}"}, status=400)
    project_path = request.POST.get("project_path", "").strip()
    if project_path == "__new__":
        new_project_name = request.POST.get("new_project_name", "").strip()
        if new_project_name:
            project_path = _create_project_folder(new_project_name)
        else:
            import re
            safe_name = re.sub(r"[^\w\-_. ]", "", (script.get("name", "imported_workflow") or "")[:50]).strip().replace(" ", "_") or f"project_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            project_path = _create_project_folder(safe_name)
    name = (script.get("name") or uploaded_file.name.replace(".json", "")).strip() or "Imported Workflow"
    description = script.get("description", "") or f"Imported from {uploaded_file.name}"
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º default_provider –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫
    from app.core.model_config import model_manager
    default_runtime = model_manager.config.default_provider or "cursor"
    
    runtime = script.get("runtime", default_runtime)
    if runtime not in ALLOWED_RUNTIMES:
        runtime = default_runtime
    script["runtime"] = runtime
    script["name"] = name
    # –ï—Å–ª–∏ runtime ralph, –Ω–æ ralph_yml –Ω–µ—Ç ‚Äî –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–∑ steps (—á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ ¬´Ralph script –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç¬ª)
    if runtime == "ralph" and not script.get("ralph_yml"):
        backend = script.get("backend") or default_runtime
        steps_list = script.get("steps", [])
        hats = {}
        prev_event = "task.start"
        for idx, step in enumerate(steps_list, start=1):
            nxt_event = f"step_{idx}.done"
            hats[f"step_{idx}"] = {
                "name": step.get("title", f"Step {idx}"),
                "description": step.get("title", f"Step {idx}"),
                "triggers": [prev_event],
                "publishes": [nxt_event],
                "instructions": step.get("prompt", ""),
            }
            prev_event = nxt_event
        script["ralph_yml"] = {
            "cli": {"backend": backend},
            "event_loop": {
                "completion_promise": "LOOP_COMPLETE",
                "max_iterations": 50,
                "starting_event": "task.start",
            },
            "hats": hats,
        }
    workflow = AgentWorkflow.objects.create(
        owner=request.user,
        name=name,
        description=description,
        runtime=runtime,
        script=script,
        project_path=project_path or None,
    )
    steps = script.get("steps", [])
    return JsonResponse({"success": True, "workflow_id": workflow.id, "name": name, "steps_count": len(steps), "project_path": project_path})


@login_required
@require_feature('agents')
@require_http_methods(["GET"])
def api_workflow_get(request, workflow_id: int):
    """–ü–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª–∏ workflow –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    workflow = get_object_or_404(AgentWorkflow.objects.select_related("target_server"), id=workflow_id, owner=request.user)
    script = workflow.script or {}
    steps = script.get("steps", [])
    return JsonResponse({
        "success": True,
        "workflow": {
            "id": workflow.id,
            "name": workflow.name or "",
            "description": getattr(workflow, "description", "") or "",
            "runtime": workflow.runtime or "ralph",
            "project_path": workflow.project_path or "",
            "target_server_id": workflow.target_server_id,
            "target_server_name": workflow.target_server.name if workflow.target_server else None,
            "steps": steps,
            "created_at": workflow.created_at.isoformat() if hasattr(workflow, "created_at") else "",
        },
    })


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["POST"])
def api_workflow_update(request, workflow_id: int):
    """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ workflow (—à–∞–≥–∏, –Ω–∞–∑–≤–∞–Ω–∏–µ, –ø—Ä–æ–µ–∫—Ç)"""
    workflow = get_object_or_404(AgentWorkflow, id=workflow_id, owner=request.user)
    data = _parse_json_request(request)
    if "name" in data:
        workflow.name = (data["name"] or "").strip() or workflow.name
    if "description" in data:
        workflow.description = data.get("description", "")
    if "runtime" in data and data["runtime"] in ALLOWED_RUNTIMES:
        workflow.runtime = data["runtime"]
    if "project_path" in data:
        pp = data["project_path"]
        if pp == "__new__":
            new_name = (data.get("new_project_name") or "").strip()
            workflow.project_path = _create_project_folder(new_name or (workflow.name or "workflow")[:50].replace(" ", "_") or f"p_{datetime.now().strftime('%Y%m%d')}")
        else:
            workflow.project_path = pp or None
    if "target_server_id" in data:
        from servers.models import Server
        ts_id = data.get("target_server_id")
        if ts_id:
            workflow.target_server = Server.objects.filter(id=ts_id, user=request.user).first()
        else:
            workflow.target_server = None
    # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ workflow-level
    if "model" in data:
        script = workflow.script or {}
        workflow_model = data.get("model", "auto")
        valid_models = [m["id"] for m in getattr(settings, "CURSOR_AVAILABLE_MODELS", [])]
        if workflow_model and workflow_model in valid_models:
            script["model"] = workflow_model
        workflow.script = script
    
    if "steps" in data:
        script = workflow.script or {}
        # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –º–æ–¥–µ–ª–∏ —à–∞–≥–æ–≤ (–µ—Å–ª–∏ —Ä–∞–∑—Ä–µ—à–µ–Ω–æ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö)
        valid_models = [m["id"] for m in getattr(settings, "CURSOR_AVAILABLE_MODELS", [])]
        validated_steps = []
        for step in data["steps"]:
            step_data = dict(step)
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º step-level –º–æ–¥–µ–ª—å
            if step_data.get("model"):
                if step_data["model"] not in valid_models or step_data["model"] == "auto":
                    step_data.pop("model", None)
            validated_steps.append(step_data)
        
        script["steps"] = validated_steps
        script["name"] = workflow.name
        script["runtime"] = workflow.runtime
        if workflow.runtime == "ralph":
            completion, max_iter, backend = "LOOP_COMPLETE", 50, "cursor"
            hats = {}
            prev = "task.start"
            for idx, step in enumerate(validated_steps, start=1):
                nxt = f"step_{idx}.done"
                hats[f"step_{idx}"] = {
                    "name": f"Step {idx}",
                    "description": step.get("title", f"Step {idx}"),
                    "triggers": [prev],
                    "publishes": [nxt],
                    "instructions": step.get("prompt", ""),
                }
                prev = nxt
            script["ralph_yml"] = {"cli": {"backend": backend}, "event_loop": {"completion_promise": completion, "max_iterations": max_iter, "starting_event": "task.start"}, "hats": hats}
        workflow.script = script
    workflow.save()
    return JsonResponse({"success": True, "workflow_id": workflow.id})


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["GET"])
def api_workflow_download_project(request, workflow_id: int):
    """
    –°–∫–∞—á–∞—Ç—å –ø—Ä–æ–µ–∫—Ç –≤–æ—Ä–∫—Ñ–ª–æ—É –∫–∞–∫ ZIP –∞—Ä—Ö–∏–≤.
    –ê—Ä—Ö–∏–≤–∏—Ä—É–µ—Ç –ø–∞–ø–∫—É project_path –∏ –æ—Ç–¥–∞—ë—Ç –∫–∞–∫ attachment.
    """
    import zipfile
    import tempfile
    from django.http import FileResponse, HttpResponse
    
    workflow = get_object_or_404(AgentWorkflow, id=workflow_id, owner=request.user)
    
    project_path = workflow.get_full_project_path()
    if not project_path or not project_path.exists():
        return JsonResponse({
            "error": "–ü–∞–ø–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –í–æ–∑–º–æ–∂–Ω–æ, –≤–æ—Ä–∫—Ñ–ª–æ—É –µ—â—ë –Ω–µ –≤—ã–ø–æ–ª–Ω—è–ª—Å—è."
        }, status=404)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è
    if not project_path.is_dir():
        return JsonResponse({"error": "project_path –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–µ–π"}, status=400)
    
    # –ò–º—è –∞—Ä—Ö–∏–≤–∞
    safe_name = "".join(c if c.isalnum() or c in "-_" else "_" for c in workflow.name)[:50] or "project"
    zip_filename = f"{safe_name}.zip"
    
    # –°–æ–∑–¥–∞—ë–º zip –≤ –ø–∞–º—è—Ç–∏
    try:
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".zip")
        with zipfile.ZipFile(temp_file, 'w', zipfile.ZIP_DEFLATED) as zf:
            for root, dirs, files in os.walk(project_path):
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º .git, __pycache__, node_modules –∏ —Ç.–ø.
                dirs[:] = [d for d in dirs if d not in ('.git', '__pycache__', 'node_modules', '.venv', 'venv', '.cursor')]
                for file in files:
                    file_path = Path(root) / file
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –±–æ–ª—å—à–∏–µ —Ñ–∞–π–ª—ã (>50MB) –∏ –±–∏–Ω–∞—Ä–Ω–∏–∫–∏
                    try:
                        if file_path.stat().st_size > 50 * 1024 * 1024:
                            continue
                    except OSError:
                        continue
                    # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –¥–ª—è –∞—Ä—Ö–∏–≤–∞
                    arcname = file_path.relative_to(project_path)
                    try:
                        zf.write(file_path, arcname)
                    except Exception as e:
                        logger.warning(f"Skip file {file_path}: {e}")
        
        temp_file.close()
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∞–π–ª
        response = FileResponse(
            open(temp_file.name, 'rb'),
            as_attachment=True,
            filename=zip_filename,
            content_type='application/zip'
        )
        # –£–¥–∞–ª—è–µ–º temp —Ñ–∞–π–ª –ø–æ—Å–ª–µ –æ—Ç–ø—Ä–∞–≤–∫–∏ (—á–µ—Ä–µ–∑ callback)
        response._temp_file_path = temp_file.name
        return response
        
    except Exception as e:
        logger.error(f"Error creating zip for workflow {workflow_id}: {e}")
        return JsonResponse({"error": f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∞—Ä—Ö–∏–≤–∞: {str(e)}"}, status=500)


# ============================================
# Custom Agents Views
# ============================================

@login_required
@require_feature('agents')
def custom_agents_view(request):
    """–°—Ç—Ä–∞–Ω–∏—Ü–∞ –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤"""
    template = get_template_name(request, 'agent_hub/custom_agents.html')
    return render(request, template, {})


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["GET", "POST"])
def api_custom_agents_list(request):
    """
    GET: —Å–ø–∏—Å–æ–∫ –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    POST: —Å–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –∫–∞—Å—Ç–æ–º–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
    """
    if request.method == 'GET':
        try:
            agents = CustomAgent.objects.filter(owner=request.user, is_active=True).order_by('-updated_at')
            
            agents_data = []
            for agent in agents:
                agents_data.append({
                    'id': agent.id,
                    'name': agent.name,
                    'description': agent.description,
                    'runtime': agent.runtime,
                    'model': agent.model,
                    'orchestrator_mode': agent.orchestrator_mode,
                    'allowed_tools': agent.allowed_tools,
                    'allowed_servers': agent.allowed_servers,
                    'knowledge_base': agent.knowledge_base,
                    'usage_count': agent.usage_count,
                    'is_public': agent.is_public,
                    'created_at': agent.created_at.isoformat(),
                    'updated_at': agent.updated_at.isoformat(),
                })
            
            return JsonResponse({'success': True, 'agents': agents_data})
        
        except Exception as e:
            logger.error(f"Error listing custom agents: {e}")
            return JsonResponse({'success': False, 'error': str(e)}, status=500)
    
    elif request.method == 'POST':
        try:
            data = _parse_json_request(request)
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ allowed_servers
            allowed_servers_raw = data.get('allowed_servers')
            if allowed_servers_raw == 'all' or allowed_servers_raw is None:
                allowed_servers = None  # –í—Å–µ —Å–µ—Ä–≤–µ—Ä—ã
            elif isinstance(allowed_servers_raw, list):
                # –í–∞–ª–∏–¥–∞—Ü–∏—è: –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ –≤—Å–µ ID —Å—É—â–µ—Å—Ç–≤—É—é—Ç –∏ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
                from servers.models import Server
                valid_ids = Server.objects.filter(
                    user=request.user, 
                    is_active=True, 
                    id__in=allowed_servers_raw
                ).values_list('id', flat=True)
                allowed_servers = list(valid_ids)
            else:
                allowed_servers = None
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞
            agent = CustomAgent.objects.create(
                owner=request.user,
                name=data.get('name', 'New Agent'),
                description=data.get('description', ''),
                system_prompt=data.get('system_prompt', ''),
                instructions=data.get('instructions', ''),
                allowed_tools=data.get('allowed_tools', []),
                max_iterations=data.get('max_iterations', 5),
                temperature=data.get('temperature', 0.7),
                completion_promise=data.get('completion_promise', 'COMPLETE'),
                runtime=data.get('runtime', 'claude'),
                model=data.get('model', 'claude-4.5-sonnet'),
                orchestrator_mode=data.get('orchestrator_mode', 'ralph_internal'),
                mcp_servers=data.get('mcp_servers', {}),
                mcp_auto_approve=data.get('mcp_auto_approve', False),
                allowed_servers=allowed_servers,
                knowledge_base=data.get('knowledge_base', ''),
            )
            
            logger.info(f"Created custom agent: {agent.name} (id={agent.id})")
            
            return JsonResponse({
                'success': True,
                'message': '–ê–≥–µ–Ω—Ç —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ',
                'agent_id': agent.id
            })
        
        except Exception as e:
            logger.error(f"Error creating custom agent: {e}")
            return JsonResponse({'success': False, 'error': str(e)}, status=500)


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["GET", "PUT", "DELETE"])
def api_custom_agent_detail(request, agent_id: int):
    """
    GET: –ø–æ–ª—É—á–∏—Ç—å –∞–≥–µ–Ω—Ç–∞
    PUT: –æ–±–Ω–æ–≤–∏—Ç—å –∞–≥–µ–Ω—Ç–∞
    DELETE: —É–¥–∞–ª–∏—Ç—å –∞–≥–µ–Ω—Ç–∞
    """
    try:
        agent = CustomAgent.objects.get(id=agent_id, owner=request.user)
    except CustomAgent.DoesNotExist:
        return JsonResponse({'success': False, 'error': 'Agent not found'}, status=404)
    
    if request.method == 'GET':
        return JsonResponse({
            'success': True,
            'agent': {
                'id': agent.id,
                'name': agent.name,
                'description': agent.description,
                'system_prompt': agent.system_prompt,
                'instructions': agent.instructions,
                'allowed_tools': agent.allowed_tools,
                'max_iterations': agent.max_iterations,
                'temperature': agent.temperature,
                'completion_promise': agent.completion_promise,
                'runtime': agent.runtime,
                'model': agent.model,
                'orchestrator_mode': agent.orchestrator_mode,
                'mcp_servers': agent.mcp_servers,
                'mcp_auto_approve': agent.mcp_auto_approve,
                'allowed_servers': agent.allowed_servers,
                'knowledge_base': agent.knowledge_base,
                'usage_count': agent.usage_count,
                'is_public': agent.is_public,
                'created_at': agent.created_at.isoformat(),
                'updated_at': agent.updated_at.isoformat(),
            }
        })
    
    elif request.method == 'PUT':
        try:
            data = _parse_json_request(request)
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ–ª–µ–π
            if 'name' in data:
                agent.name = data['name']
            if 'description' in data:
                agent.description = data['description']
            if 'system_prompt' in data:
                agent.system_prompt = data['system_prompt']
            if 'instructions' in data:
                agent.instructions = data['instructions']
            if 'allowed_tools' in data:
                agent.allowed_tools = data['allowed_tools']
            if 'max_iterations' in data:
                agent.max_iterations = data['max_iterations']
            if 'temperature' in data:
                agent.temperature = data['temperature']
            if 'completion_promise' in data:
                agent.completion_promise = data['completion_promise']
            if 'runtime' in data:
                agent.runtime = data['runtime']
            if 'model' in data:
                agent.model = data['model']
            if 'orchestrator_mode' in data:
                agent.orchestrator_mode = data['orchestrator_mode']
            if 'mcp_servers' in data:
                agent.mcp_servers = data['mcp_servers']
            if 'mcp_auto_approve' in data:
                agent.mcp_auto_approve = data['mcp_auto_approve']
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ allowed_servers
            if 'allowed_servers' in data:
                allowed_servers_raw = data['allowed_servers']
                if allowed_servers_raw == 'all' or allowed_servers_raw is None:
                    agent.allowed_servers = None
                elif isinstance(allowed_servers_raw, list):
                    from servers.models import Server
                    valid_ids = Server.objects.filter(
                        user=request.user, 
                        is_active=True, 
                        id__in=allowed_servers_raw
                    ).values_list('id', flat=True)
                    agent.allowed_servers = list(valid_ids)
            
            if 'knowledge_base' in data:
                agent.knowledge_base = data['knowledge_base']
            
            agent.save()
            
            logger.info(f"Updated custom agent: {agent.name} (id={agent.id})")
            
            return JsonResponse({'success': True, 'message': '–ê–≥–µ–Ω—Ç –æ–±–Ω–æ–≤–ª—ë–Ω'})
        
        except Exception as e:
            logger.error(f"Error updating custom agent: {e}")
            return JsonResponse({'success': False, 'error': str(e)}, status=500)
    
    elif request.method == 'DELETE':
        try:
            agent.is_active = False
            agent.save()
            
            logger.info(f"Deleted custom agent: {agent.name} (id={agent.id})")
            
            return JsonResponse({'success': True, 'message': '–ê–≥–µ–Ω—Ç —É–¥–∞–ª—ë–Ω'})
        
        except Exception as e:
            logger.error(f"Error deleting custom agent: {e}")
            return JsonResponse({'success': False, 'error': str(e)}, status=500)


@csrf_exempt
@login_required
@require_feature('agents')
@require_http_methods(["GET"])
def api_custom_agent_export(request, agent_id: int):
    """–≠–∫—Å–ø–æ—Ä—Ç –∞–≥–µ–Ω—Ç–∞ –≤ JSON —Ñ–æ—Ä–º–∞—Ç (–¥–ª—è Claude Code CLI)"""
    try:
        agent = CustomAgent.objects.get(id=agent_id, owner=request.user)
        
        config = agent.to_cli_agent_config()
        
        return JsonResponse({
            'success': True,
            'config': config,
            'format': 'claude_code_agent',
            'filename': f"{agent.name.replace(' ', '_')}.agent.json"
        })
    
    except CustomAgent.DoesNotExist:
        return JsonResponse({'success': False, 'error': 'Agent not found'}, status=404)
    except Exception as e:
        logger.error(f"Error exporting custom agent: {e}")
        return JsonResponse({'success': False, 'error': str(e)}, status=500)
