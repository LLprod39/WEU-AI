# 📚 WEU AI Agent Platform — Полная документация

Подробное описание всех возможностей, архитектуры и логики работы платформы.

---

## Оглавление

1. [Обзор платформы](#обзор-платформы)
2. [Модули и функциональность](#модули-и-функциональность)
   - [Chat — Чат с AI](#chat--чат-с-ai)
   - [Orchestrator — Оркестратор](#orchestrator--оркестратор)
   - [Agent Hub — Центр агентов](#agent-hub--центр-агентов)
   - [Knowledge Base — База знаний (RAG)](#knowledge-base--база-знаний-rag)
   - [Tasks — Управление задачами](#tasks--управление-задачами)
   - [Passwords — Менеджер паролей](#passwords--менеджер-паролей)
   - [Servers — Управление серверами](#servers--управление-серверами)
   - [Tools — Инструменты и MCP](#tools--инструменты-и-mcp)
3. [Архитектура системы](#архитектура-системы)
4. [Логика работы](#логика-работы)
5. [Конфигурация](#конфигурация)
6. [Типы сборки](#типы-сборки)
7. [API Reference](#api-reference)

---

## Обзор платформы

**WEU AI Agent Platform** — это интегрированная веб-платформа, объединяющая возможности работы с большими языковыми моделями (LLM), оркестрацию AI-агентов и управление инфраструктурой в едином интерфейсе.

### Ключевые преимущества

- **Единый интерфейс** — все инструменты в одном месте
- **Гибкость** — поддержка нескольких LLM-провайдеров
- **ReAct-паттерн** — прозрачная логика принятия решений AI
- **Расширяемость** — поддержка MCP для внешних инструментов
- **Безопасность** — шифрование данных, изоляция пользователей

### Целевые пользователи

- Разработчики, работающие с AI-агентами
- DevOps-инженеры для автоматизации серверов
- Команды, использующие LLM в рабочих процессах
- Исследователи AI и prompt-инженеры

---

## Модули и функциональность

### Chat — Чат с AI

Основной интерфейс для общения с языковыми моделями.

#### Возможности

| Функция | Описание |
|---------|----------|
| **Переключение провайдеров** | Gemini или Grok на лету |
| **Выбор модели** | Конкретные версии моделей из конфигурации |
| **RAG-режим** | Поиск по базе знаний при ответе |
| **Загрузка файлов** | Drag-and-drop для добавления контекста |
| **История диалога** | Сохранение в рамках сессии |
| **Markdown-рендеринг** | Форматированные ответы с подсветкой кода |
| **Стриминг** | Ответы в реальном времени |

#### Интерфейс

- Боковая панель с переключением провайдеров
- Кнопка включения/выключения RAG
- Область ввода с поддержкой Shift+Enter для переноса строки
- Индикатор загрузки при генерации ответа

#### Технические детали

- **Endpoint:** `/api/chat/`
- **Метод:** POST (streaming response)
- **Файл:** `core_ui/views.py` → `chat_api()`

---

### Orchestrator — Оркестратор

Визуальный интерфейс для наблюдения за процессом мышления AI.

#### Концепция ReAct

Оркестратор реализует паттерн **ReAct** (Reason + Act):

```
┌─────────┐    ┌─────────┐    ┌─────────┐
│ REASON  │ → │  ACT    │ → │ OBSERVE │
│ (Думаю) │    │(Делаю)  │    │(Смотрю) │
└─────────┘    └─────────┘    └─────────┘
      ↑                            │
      └────────────────────────────┘
              (цикл до завершения)
```

#### Этапы цикла

1. **Thought (Мысль)** — AI анализирует задачу и решает, что делать
2. **Action (Действие)** — Выполнение инструмента (если нужно)
3. **Observation (Наблюдение)** — Получение результата инструмента
4. **Answer (Ответ)** — Финальный ответ пользователю

#### Визуализация

Каждый этап отображается отдельным блоком:
- 🧠 **Thought** — жёлтый фон
- ⚡ **Action** — синий фон с именем инструмента
- 👁 **Observation** — серый фон с результатом
- ✅ **Answer** — зелёный фон с финальным ответом

#### Применение

- Отладка промптов и агентов
- Демонстрация работы AI
- Понимание логики принятия решений
- Обучение работе с AI-агентами

---

### Agent Hub — Центр агентов

Управление профилями агентов, проектами и воркфлоу.

#### Агенты

Профиль агента включает:

| Параметр | Описание |
|----------|----------|
| **Имя** | Уникальное название агента |
| **Описание** | Назначение и специализация |
| **Модель** | LLM-модель для работы |
| **Провайдер** | Gemini или Grok |
| **Тип** | chat / code / assistant |
| **Системный промпт** | Инструкции для агента |
| **RAG** | Использование базы знаний |

#### Проекты

Рабочие пространства для организации работы:
- Название и описание
- Привязанные агенты
- Привязанные воркфлоу
- История запусков

#### Воркфлоу

Многошаговые сценарии автоматизации:

```yaml
name: "Deploy to production"
steps:
  - agent: "code-reviewer"
    action: "review_changes"
  - agent: "test-runner"
    action: "run_tests"
  - agent: "deployer"
    action: "deploy"
    condition: "previous_success"
```

#### CLI-агенты

Интеграция с внешними CLI-инструментами:

- **Cursor CLI** — headless режим Cursor
- **Ralph** — кастомный CLI-агент

Конфигурация в `.env`:
```env
CURSOR_CLI_PATH=/path/to/cursor
CURSOR_API_KEY=your_api_key
RALPH_CLI_PATH=/path/to/ralph
CLI_RUNTIME_TIMEOUT_SECONDS=600
```

---

### Knowledge Base — База знаний (RAG)

Retrieval-Augmented Generation для расширения контекста AI.

#### Принцип работы

```
┌──────────┐    ┌──────────────┐    ┌─────────────┐
│ Документ │ → │ Эмбеддинг    │ → │ Векторная   │
│          │    │ (embedding)  │    │ БД (Qdrant) │
└──────────┘    └──────────────┘    └─────────────┘

┌──────────┐    ┌──────────────┐    ┌─────────────┐
│ Запрос   │ → │ Семантический│ → │ Релевантные │
│          │    │ поиск        │    │ чанки       │
└──────────┘    └──────────────┘    └─────────────┘
```

#### Возможности

| Функция | Описание |
|---------|----------|
| **Загрузка файлов** | PDF, DOCX, TXT, MD и другие |
| **Загрузка текста** | Прямой ввод в интерфейсе |
| **Семантический поиск** | По смыслу, не по ключевым словам |
| **Chunking** | Автоматическая разбивка на части |
| **Изоляция** | Коллекции по пользователям |

#### Бэкенды

- **Qdrant** (Docker) — production-ready векторная БД
- **InMemory** — для разработки и тестирования

#### Настройка

```env
# Qdrant
QDRANT_HOST=localhost
QDRANT_PORT=6333

# Модель эмбеддингов
rag_model=paraphrase-multilingual-MiniLM-L12-v2
```

#### Использование

1. Перейти в **Knowledge Base**
2. Загрузить документы или ввести текст
3. Включить **RAG** в чате
4. Задавать вопросы — AI будет искать ответы в документах

---

### Tasks — Управление задачами

Полноценная система управления задачами с AI-интеграцией.

#### Основные возможности

| Функция | Описание |
|---------|----------|
| **Создание задач** | Заголовок, описание, дедлайн |
| **Приоритеты** | Низкий, средний, высокий, критический |
| **Метки** | Теги для категоризации |
| **Подзадачи** | Иерархическая структура |
| **Комментарии** | Обсуждение задачи |
| **Вложения** | Файлы к задаче |
| **Исполнители** | Назначение на пользователей или агентов |

#### AI-функции

**Smart Analyzer** (`tasks/smart_analyzer.py`):

1. **Анализ формулировки** — оценка качества описания задачи
2. **Улучшение описания** — AI переписывает для ясности
3. **Разбиение на подзадачи** — автоматическая декомпозиция
4. **Оценка сложности** — прогноз трудоёмкости
5. **Предложения** — советы по выполнению

#### Интеграция с агентами

Задачи можно назначать на AI-агентов:
- Агент получает контекст задачи
- Выполняет необходимые действия
- Обновляет статус задачи
- Добавляет комментарии с результатами

#### Интеграция с серверами

Привязка серверов к задачам:
- Быстрый доступ к нужным серверам
- Выполнение команд в контексте задачи
- Логирование действий

---

### Passwords — Менеджер паролей

Безопасное хранение учётных данных.

#### Возможности

| Функция | Описание |
|---------|----------|
| **Шифрование** | AES-256 для всех паролей |
| **Категории** | Группировка по типам |
| **Теги** | Быстрый поиск |
| **Генератор** | Создание надёжных паролей |
| **Копирование** | В буфер обмена |
| **Аудит** | Логирование доступа |

#### Структура записи

```
Название: Production DB
Категория: Database
Логин: admin
Пароль: ********** (зашифровано)
URL: db.example.com
Теги: production, postgres
Заметки: Основная база данных
```

#### Безопасность

- Пароли никогда не хранятся в открытом виде
- Шифрование на стороне сервера
- Мастер-ключ из переменной окружения
- Аудит всех операций чтения

---

### Servers — Управление серверами

SSH-доступ и управление инфраструктурой.

#### Возможности

| Функция | Описание |
|---------|----------|
| **SSH-хосты** | Добавление серверов |
| **Группы** | Организация по назначению |
| **Проверка подключения** | Тест SSH-соединения |
| **Выполнение команд** | Через веб-интерфейс |
| **Шифрование** | Паролей и ключей |
| **Интеграция** | С задачами и агентами |

#### Структура сервера

```
Название: Production Web Server
Хост: 192.168.1.100
Порт: 22
Пользователь: deploy
Аутентификация: SSH-ключ / Пароль
Группа: Production
Описание: Основной веб-сервер
```

#### Использование с агентами

Агенты могут:
1. Подключаться к серверам
2. Выполнять команды
3. Читать файлы
4. Мониторить состояние

---

### Tools — Инструменты и MCP

Расширение возможностей AI через инструменты.

#### Встроенные инструменты

| Инструмент | Описание |
|------------|----------|
| `read_file` | Чтение файлов |
| `write_file` | Запись файлов |
| `list_directory` | Список файлов в директории |
| `execute_command` | Выполнение shell-команд |
| `ssh_execute` | Команды на удалённом сервере |
| `web_request` | HTTP-запросы |
| `web_scrape` | Парсинг веб-страниц |
| `search_web` | Поиск в интернете |

#### Model Context Protocol (MCP)

Подключение внешних MCP-серверов для расширения функциональности.

**Конфигурация** (`mcp_config.json`):

```json
{
  "mcpServers": {
    "filesystem": {
      "command": "npx",
      "args": ["-y", "@anthropic-ai/mcp-filesystem-server", "/path"],
      "description": "File system access"
    },
    "github": {
      "command": "npx",
      "args": ["-y", "@anthropic-ai/mcp-github-server"],
      "env": {
        "GITHUB_TOKEN": "${GITHUB_TOKEN}"
      }
    }
  }
}
```

#### Как AI использует инструменты

1. AI анализирует запрос пользователя
2. Определяет, нужен ли инструмент
3. Формирует вызов инструмента с параметрами
4. Получает результат
5. Использует результат для ответа

---

## Архитектура системы

### Высокоуровневая схема

```
┌─────────────────────────────────────────────────────────────────┐
│                        Пользователь                             │
└─────────────────────────────┬───────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│                    Django Web Interface                         │
│  ┌──────────┐ ┌──────────┐ ┌──────────┐ ┌──────────┐           │
│  │ core_ui  │ │  tasks   │ │passwords │ │ servers  │           │
│  └──────────┘ └──────────┘ └──────────┘ └──────────┘           │
│  ┌──────────┐                                                   │
│  │agent_hub │                                                   │
│  └──────────┘                                                   │
└─────────────────────────────┬───────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│                     Application Core                            │
│  ┌────────────────┐  ┌─────────────┐  ┌─────────────┐          │
│  │  Orchestrator  │  │    RAG      │  │    Tools    │          │
│  │  (ReAct Loop)  │  │   Engine    │  │   Manager   │          │
│  └───────┬────────┘  └──────┬──────┘  └──────┬──────┘          │
│          │                  │                 │                  │
│          └──────────────────┼─────────────────┘                  │
│                             │                                    │
└─────────────────────────────┼────────────────────────────────────┘
                              │
              ┌───────────────┼───────────────┐
              ▼               ▼               ▼
       ┌───────────┐  ┌───────────┐  ┌───────────┐
       │   LLM     │  │  Qdrant   │  │   MCP     │
       │(Gemini/   │  │ (Vectors) │  │ Servers   │
       │  Grok)    │  │           │  │           │
       └───────────┘  └───────────┘  └───────────┘
```

### Компоненты

#### Django Apps

| Приложение | Путь | Назначение |
|------------|------|------------|
| `core_ui` | `/core_ui/` | Основной интерфейс, чат, настройки |
| `agent_hub` | `/agent_hub/` | Агенты, проекты, воркфлоу |
| `tasks` | `/tasks/` | Управление задачами |
| `passwords` | `/passwords/` | Менеджер паролей |
| `servers` | `/servers/` | SSH-управление |

#### Core Modules

| Модуль | Путь | Назначение |
|--------|------|------------|
| Orchestrator | `app/core/orchestrator.py` | ReAct-цикл, координация |
| LLM Provider | `app/core/llm.py` | Работа с Gemini/Grok |
| Model Config | `app/core/model_config.py` | Конфигурация моделей |
| RAG Engine | `app/rag/engine.py` | Векторный поиск |
| Tool Manager | `app/tools/manager.py` | Реестр инструментов |
| MCP Client | `app/mcp/client.py` | Подключение MCP |

---

## Логика работы

### Поток обработки сообщения

```
1. Пользователь отправляет сообщение
   ↓
2. core_ui/views.py → chat_api()
   ↓
3. Orchestrator.process_user_message()
   ↓
4. [Если RAG включён]
   │ → RAG Engine → поиск релевантных документов
   │ → Добавление контекста к сообщению
   ↓
5. ReAct Loop (до MAX_ITERATIONS или завершения):
   │
   ├─► Reason: LLM анализирует ситуацию
   │   ↓
   ├─► Act: Вызов инструмента (если нужно)
   │   ↓
   ├─► Observe: Получение результата
   │   ↓
   └─► Повторить или завершить
   ↓
6. LLM генерирует финальный ответ
   ↓
7. Стриминг ответа пользователю
```

### Пример ReAct-цикла

**Запрос:** "Какая погода в Москве?"

```
[Thought 1]
Пользователь спрашивает о погоде в Москве.
Мне нужно использовать инструмент поиска в интернете.

[Action 1]
Tool: web_search
Input: {"query": "погода Москва сегодня"}

[Observation 1]
Результат: Москва, сегодня: +5°C, облачно, 
ветер 3 м/с, влажность 75%...

[Thought 2]
Я получил информацию о погоде.
Могу сформировать ответ пользователю.

[Answer]
В Москве сейчас +5°C, облачно. 
Ветер слабый — 3 м/с, влажность 75%.
```

---

## Конфигурация

### Файлы конфигурации

| Файл | Назначение |
|------|------------|
| `.env` | Переменные окружения |
| `.model_config.json` | Настройки LLM-моделей |
| `mcp_config.json` | MCP-серверы |
| `web_ui/settings.py` | Django настройки |

### Переменные окружения

```env
# === API Keys ===
GEMINI_API_KEY=AIza...           # Google Gemini
GROK_API_KEY=xai-...             # xAI Grok

# === Database ===
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=weu_platform
POSTGRES_USER=weu
POSTGRES_PASSWORD=secret

# === Django ===
DJANGO_PORT=8000
DEBUG=False
ALLOWED_HOSTS=localhost,127.0.0.1
SECRET_KEY=your-secret-key
DJANGO_SUPERUSER_USERNAME=admin
DJANGO_SUPERUSER_PASSWORD=admin

# === RAG ===
QDRANT_HOST=localhost
QDRANT_PORT=6333

# === Encryption ===
ENCRYPTION_KEY=32-byte-key-for-aes256

# === Build Type ===
WEU_BUILD=mini                   # mini / full

# === CLI Agents ===
CURSOR_CLI_PATH=/path/to/cursor
CURSOR_API_KEY=your_key
RALPH_CLI_PATH=/path/to/ralph
CLI_RUNTIME_TIMEOUT_SECONDS=600
```

### Конфигурация моделей

```json
{
  "chat_model_gemini": "gemini-2.0-flash-exp",
  "agent_model_gemini": "gemini-2.0-flash-exp",
  "orchestrator_model_gemini": "gemini-2.0-flash-exp",
  "chat_model_grok": "grok-beta",
  "agent_model_grok": "grok-beta",
  "rag_model": "paraphrase-multilingual-MiniLM-L12-v2",
  "default_provider": "gemini"
}
```

---

## Типы сборки

### Mini Build

**Назначение:** Быстрый старт, минимальные ресурсы

**Включено:**
- Чат с AI
- Оркестратор
- Agent Hub
- Задачи
- Пароли
- Серверы
- Базовые инструменты

**Отключено:**
- RAG (база знаний)
- Локальные эмбеддинги

**Установка:**
```bash
pip install -r requirements.txt
```

### Full Build

**Назначение:** Полная функциональность с RAG

**Включено:**
- Всё из Mini +
- RAG с Qdrant
- sentence-transformers
- Расширенная обработка документов
- OCR (опционально)

**Установка:**
```bash
pip install -r requirements-full.txt
```

**Требования:**
- Больше RAM (для моделей эмбеддингов)
- Qdrant (Docker или cloud)

---

## API Reference

### Chat API

**POST** `/api/chat/`

```json
{
  "message": "Привет! Как дела?",
  "provider": "gemini",
  "model": "gemini-2.0-flash-exp",
  "rag_enabled": false,
  "session_id": "abc123"
}
```

**Response:** Server-Sent Events (streaming)

### Orchestrator API

**POST** `/api/orchestrator/`

```json
{
  "message": "Найди файлы .py в текущей директории",
  "provider": "gemini"
}
```

**Response:** Server-Sent Events с этапами ReAct

### Tasks API

**GET** `/api/tasks/` — список задач
**POST** `/api/tasks/` — создать задачу
**GET** `/api/tasks/{id}/` — получить задачу
**PUT** `/api/tasks/{id}/` — обновить задачу
**DELETE** `/api/tasks/{id}/` — удалить задачу

**POST** `/api/tasks/{id}/analyze/` — AI-анализ задачи
**POST** `/api/tasks/{id}/improve/` — улучшить описание
**POST** `/api/tasks/{id}/decompose/` — разбить на подзадачи

### Servers API

**GET** `/api/servers/` — список серверов
**POST** `/api/servers/` — добавить сервер
**POST** `/api/servers/{id}/test/` — проверить подключение
**POST** `/api/servers/{id}/execute/` — выполнить команду

### Passwords API

**GET** `/api/passwords/` — список паролей
**POST** `/api/passwords/` — создать запись
**GET** `/api/passwords/{id}/` — получить (с расшифровкой)
**POST** `/api/passwords/generate/` — сгенерировать пароль

---

## Заключение

WEU AI Agent Platform — мощный инструмент для работы с AI-агентами. Платформа объединяет чат, RAG, управление агентами, задачи и инфраструктуру в едином интерфейсе.

Для вопросов и предложений используйте GitHub Issues.
