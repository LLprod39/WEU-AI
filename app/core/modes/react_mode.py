"""
ReAct Mode - Ñ‚ÐµÐºÑƒÑ‰Ð¸Ð¹ Orchestrator Ñ ReAct loop
"""
import os
import asyncio
import re
import json
from typing import AsyncGenerator, List, Dict, Any, Optional
from loguru import logger
from app.core.modes.base import BaseMode


class ReActMode(BaseMode):
    """
    ReAct Mode (Reason + Act)
    
    Ð˜Ñ‚ÐµÑ€Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ñ†Ð¸ÐºÐ»:
    1. THOUGHT - Ñ€Ð°ÑÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ðµ
    2. ACTION - Ð²Ñ‹Ð·Ð¾Ð² Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ð°
    3. OBSERVATION - Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ð°
    4. ÐŸÐ¾Ð²Ñ‚Ð¾Ñ€ Ð¸Ð»Ð¸ Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚
    """
    
    @property
    def description(self) -> str:
        return "ReAct loop (Reason + Act) - Ð¸Ñ‚ÐµÑ€Ð°Ñ‚Ð¸Ð²Ð½Ð¾Ðµ Ñ€Ð°ÑÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ðµ Ñ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ð°Ð¼Ð¸"
    
    async def execute(
        self,
        message: str,
        model_preference: str = None,
        use_rag: bool = True,
        specific_model: str = None,
        user_id: int = None,
        initial_history: List[Dict[str, str]] = None,
        execution_context: Dict[str, Any] = None,
    ) -> AsyncGenerator[str, None]:
        """
        Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ Ð² ReAct Ñ€ÐµÐ¶Ð¸Ð¼Ðµ - ÐºÐ¾Ð¿Ð¸Ñ Ð»Ð¾Ð³Ð¸ÐºÐ¸ Ð¸Ð· Orchestrator.process_user_message
        """
        effective_history = list(initial_history) if initial_history else list(self.orchestrator.history)
        effective_history.append({"role": "user", "content": message})
        if not initial_history:
            self.orchestrator.history.append({"role": "user", "content": message})
        
        # Limit history
        if len(effective_history) > 10:
            effective_history = effective_history[-10:]
        if not initial_history and len(self.orchestrator.history) > 10:
            self.orchestrator.history = self.orchestrator.history[-10:]
        
        # RAG context
        rag_context = ""
        if use_rag and self.orchestrator.rag.available and user_id is not None:
            try:
                results = await asyncio.to_thread(
                    self.orchestrator.rag.query, message, 3, user_id
                )
                if results.get('documents') and results['documents'][0]:
                    docs = results['documents'][0]
                    if docs:
                        rag_context = "\n".join([f"ðŸ“š {doc}" for doc in docs])
                        logger.info(f"Retrieved {len(docs)} documents from RAG")
            except Exception as e:
                logger.warning(f"RAG query failed: {e}")
        
        # ReAct Loop
        iteration = 0
        final_answer = ""
        max_iterations = 5
        
        while iteration < max_iterations:
            iteration += 1
            logger.info(f"ReAct iteration {iteration}/{max_iterations}")
            
            # Build system prompt
            system_prompt = self.orchestrator._build_system_prompt(
                user_message=message,
                rag_context=rag_context,
                iteration=iteration,
                history_override=effective_history if initial_history else None,
                execution_context=execution_context,
            )
            
            # Get LLM response
            llm_response = ""
            async for chunk in self.orchestrator.llm.stream_chat(
                system_prompt, 
                model=model_preference,
                specific_model=specific_model
            ):
                llm_response += chunk
                if iteration == 1:  # Only show first iteration thinking
                    yield chunk
            
            # Parse response for actions
            action_match = self.orchestrator._parse_action(llm_response)
            
            if action_match:
                # Agent wants to use a tool
                tool_name = action_match['tool']
                tool_args = action_match['args']
                
                yield f"\n\nðŸ”§ **Using tool: {tool_name}**\n"
                
                try:
                    ctx = (execution_context or {}).copy()
                    tool_context = {"user_id": ctx.get("user_id")} if ctx.get("user_id") else None
                    if ctx.get("master_password") and tool_context:
                        tool_context["master_password"] = ctx.get("master_password")
                    if ctx.get("workspace_path") and tool_context:
                        tool_context["workspace_path"] = ctx.get("workspace_path")
                    elif ctx.get("workspace_path"):
                        tool_context = {"workspace_path": ctx.get("workspace_path")}
                    
                    result = await self.orchestrator.tool_manager.execute_tool(
                        tool_name, _context=tool_context, **tool_args
                    )
                    
                    result_str = self.orchestrator._format_tool_result(result)
                    yield f"âœ… **Result:**\n```\n{result_str}\n```\n\n"
                    
                    # IDE_FILE_CHANGED event
                    if tool_name == "write_file" and ctx.get("workspace_path"):
                        file_path = tool_args.get("path", "")
                        if file_path:
                            try:
                                from pathlib import Path
                                workspace_path_obj = Path(ctx.get("workspace_path"))
                                if os.path.isabs(file_path):
                                    try:
                                        file_path_obj = Path(file_path)
                                        if str(file_path_obj).startswith(str(workspace_path_obj)):
                                            rel_path = str(file_path_obj.relative_to(workspace_path_obj))
                                        else:
                                            rel_path = file_path
                                    except (ValueError, AttributeError):
                                        rel_path = file_path
                                else:
                                    rel_path = file_path
                                rel_path = rel_path.replace("\\", "/")
                                yield f"IDE_FILE_CHANGED:{rel_path}\n"
                            except Exception as e:
                                logger.debug(f"Could not compute relative path: {e}")
                    
                    # Add to history
                    effective_history.append({
                        "role": "assistant",
                        "content": f"ACTION: {tool_name} with {tool_args}"
                    })
                    effective_history.append({
                        "role": "system",
                        "content": f"OBSERVATION: {result_str}"
                    })
                    if not initial_history:
                        self.orchestrator.history.append({
                            "role": "assistant",
                            "content": f"ACTION: {tool_name} with {tool_args}"
                        })
                        self.orchestrator.history.append({
                            "role": "system",
                            "content": f"OBSERVATION: {result_str}"
                        })
                    
                    continue
                    
                except Exception as e:
                    error_msg = f"âŒ Tool execution failed: {str(e)}"
                    yield f"{error_msg}\n\n"
                    logger.error(error_msg)
                    
                    effective_history.append({
                        "role": "system",
                        "content": f"ERROR: {str(e)}"
                    })
                    if not initial_history:
                        self.orchestrator.history.append({
                            "role": "system",
                            "content": f"ERROR: {str(e)}"
                        })
                    
                    continue
            else:
                # No action - final answer
                final_answer = llm_response
                break
        
        # If exhausted iterations without final answer
        if not final_answer:
            final_answer = "Ð”Ð¾ÑÑ‚Ð¸Ð³Ð½ÑƒÑ‚ Ð»Ð¸Ð¼Ð¸Ñ‚ Ð¸Ñ‚ÐµÑ€Ð°Ñ†Ð¸Ð¹. Ð’Ð¾Ñ‚ Ñ‡Ñ‚Ð¾ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð²Ñ‹ÑÑÐ½Ð¸Ñ‚ÑŒ:\n\n" + llm_response
        
        # Add final answer to history
        effective_history.append({"role": "assistant", "content": final_answer})
        if not initial_history:
            self.orchestrator.history.append({"role": "assistant", "content": final_answer})
        
        # Add to RAG
        if len(final_answer) > 100 and user_id is not None:
            try:
                await asyncio.to_thread(
                    self.orchestrator.rag.add_text,
                    f"Q: {message}\nA: {final_answer}",
                    "conversation",
                    user_id,
                )
            except Exception as e:
                logger.warning(f"Failed to add to RAG: {e}")
        
        # Stream final answer if not already streamed
        if iteration > 1:
            yield f"\n\n{final_answer}"
